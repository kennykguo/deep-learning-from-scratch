<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef195e91-cf22-43c4-aec2-67216b6353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d8f8ca-66fc-4a13-8442-04e4a21ba2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d100e1c-fe7d-4718-8f90-081afa05ccfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "def plot_mnist_image(image_array):\n",
    "    image = image_array.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "plot_mnist_image(data[2, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ef5ed9-2c6a-4060-aaf1-84f5c75767ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "m, n = data.shape\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e6b5f1-e3a7-43a7-96b9-4cc371322534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 1, 4, ..., 5, 6, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data) # Shuffles all the individual rows\n",
    "data_dev = data[0:1000].T #Take the first 1000 rows, and transpose the matrix to get 1000 examples as column vectors\n",
    "data_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfc2746-5ec9-48b7-8f56-18f31dee1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev = data_dev[0] #Takes the first row, which contains all of the answers to the numbers (the Y is what we want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca04569-7231-41b8-a1a5-880d4cb8abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = data_dev[1:]\n",
    "X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bce0cb-6db8-4824-b6fa-7afdba377565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_dev = X_dev.reshape(28,28,1000)\n",
    "print(X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b59dca3-a0e1-4c4c-8897-c31be0d041d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# print(X_dev[:,:,1])\n",
    "plot_mnist_image(X_dev[:,:,6])\n",
    "print(Y_dev[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90aef05-a41a-4c59-ad00-63c93e1fffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fcae13-b528-49de-a18f-b6f9ed4cfb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= data_train[1:n] #Takes all of the data corresponding to all of the entries\n",
    "X_train = X_train.reshape(28,28,41000)\n",
    "X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7b515a33-35df-49d8-80fc-b3fb17971ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(input_data):\n",
    "    # 24, 24, 2\n",
    "    input_height, input_width, input_depth = input_data.shape\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = input_height // 2 # 12\n",
    "    output_width = input_width // 2 # 12\n",
    "    output_depth = input_depth # 2 - depth stays the same\n",
    "\n",
    "    # Initialize the output array and array to store indices\n",
    "    output_data = np.zeros((output_height, output_width, output_depth))\n",
    "    indices = np.zeros((output_height, output_width, output_depth, 2), dtype=int)\n",
    "\n",
    "    # Apply max pooling\n",
    "    for h in range(output_height):\n",
    "        for w in range(output_width):\n",
    "            for d in range(output_depth):\n",
    "                # Extract the 2x2 region of interest from the input data\n",
    "                region = input_data[h*2:(h+1)*2, w*2:(w+1)*2, d]\n",
    "                # Compute the maximum value in the region\n",
    "                max_val = np.max(region)\n",
    "                output_data[h, w, d] = max_val\n",
    "                # Find the indices of the maximum value in the region\n",
    "                max_indices = np.unravel_index(np.argmax(region), region.shape)\n",
    "                # Store the indices relative to the region and convert to global indices\n",
    "                indices[h, w, d] = [h*2 + max_indices[0], w*2 + max_indices[1]]\n",
    "\n",
    "    return output_data, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6d7b5b43-0f57-4013-ab85-80ec5b90216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_ReLU(Z):\n",
    "  return Z > 0\n",
    "\n",
    "def der_ReLU2(Z):\n",
    "  return np.where(Z > 0, 1, 0.1)\n",
    "\n",
    "def ReLU(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU2(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def sigmoid(z):\n",
    "    # Compute the sigmoid function element-wise\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def softmax(Z):\n",
    "    # Apply softmax column-wise\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0))  # Subtracting the maximum value in each column to avoid overflow\n",
    "    return exp_Z / np.sum(exp_Z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "460fd0ab-c756-4c3a-a2e9-77ad87330d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def params():\n",
    "    layer_weights = np.random.randn(5, 5, 2) * np.sqrt(2. / 5)\n",
    "    layer_bias = np.random.randn(24, 24, 2) * np.sqrt(2. / 5)\n",
    "    layer_output = np.zeros((24,24,2)) #(24,24,2)\n",
    "    fc_weights = np.random.randn(10, 288) * np.sqrt(2. / 288)\n",
    "    fc_bias = np.random.randn(10,1) #(10, 1)\n",
    "    # fc_bias *= 0\n",
    "    fc_bias = fc_bias.reshape(10, 1)\n",
    "    return layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "\n",
    "def forward_propagation(layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias):\n",
    "    # layer_input (28, 28)\n",
    "    # layer_weights (5, 5, 2)\n",
    "    # layer_bias (24, 24, 2)\n",
    "    # layer_output (24, 24, 2)\n",
    "    # layer_bias (10, 288)\n",
    "    # layer_bias (10, 1)\n",
    "    \n",
    "    # Convolution\n",
    "    for i in range(2): # 2 filters in total\n",
    "        layer_output[:,:,i] = signal.correlate2d(layer_input, layer_weights[:,:,i], mode='valid')\n",
    "    layer_output = layer_output + layer_bias   # (24, 24, 2)\n",
    "    \n",
    "    # Activation layer\n",
    "    layer_output = ReLU(layer_output)  # (24, 24, 2)\n",
    "    \n",
    "    # Pool layer\n",
    "    layer_pool, layer_indices = max_pooling(layer_output)  # (12, 12, 2)\n",
    "\n",
    "    \n",
    "    # Flattening (changed to 288,1)\n",
    "    layer_pool = layer_pool.reshape(288,1) # (288,1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    final_output = fc_weights.dot(layer_pool)  # (10, 288) (288, 1) = (10, 1)\n",
    "    final_output.reshape(10,1) \n",
    "    final_output = final_output + fc_bias # (10, 1) + (10, 1) = (10, 1)\n",
    "    final_output = softmax(final_output) # (10, 1) -> (10, 1)\n",
    "    \n",
    "    return layer_output, layer_pool, layer_indices, final_output\n",
    "\n",
    "\n",
    "def create(Y):\n",
    "  column_Y = np.zeros((10, 1))\n",
    "  column_Y[Y] = 1\n",
    "  column_Y = column_Y.T\n",
    "  return column_Y.reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "26a21241-e082-487c-a194-adb44fa414b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropogation through layers\n",
    "\n",
    "def back_prop(layer_input, layer_output, layer_pool, layer_indices, final_output, label, layer_weights, layer_bias, fc_weights, fc_bias):\n",
    "    # Initalize parameters\n",
    "    delta_conv_weights = np.zeros((5,5,2))  # (5,5,2)\n",
    "    delta_conv_bias = np.zeros((24,24,2)) # (24, 24, 2)\n",
    "    delta_fc_weights = np.zeros((10, 288)) #  (10, 288)\n",
    "    delta_fc_bias = np.zeros((10, 1)) # (10, 1)\n",
    "    delta_fc_bias.reshape(10, 1)\n",
    "    \n",
    "    # Backpropogate cost\n",
    "    x = create(label) \n",
    "    dZ = (final_output - x) # (10,1) - (10,1) = (10,1) \n",
    "    # dZ = dZ.reshape((10,1))\n",
    "    \n",
    "    #Backpropogate weights and biases\n",
    "    layer_pool = layer_pool.reshape(1,288)\n",
    "    delta_fc_weights = dZ.dot(layer_pool) # (10 x 1 ) (1 x 288) = (10 x 288)\n",
    "    delta_fc_bias = dZ\n",
    "    \n",
    "    # Backpropogate error\n",
    "    dZ_pool_output = np.dot(fc_weights.T, dZ) * der_ReLU(layer_pool.reshape(288, 1)) #(288 x 10) (10 x 1) = (288 x 1)\n",
    "    \n",
    "    # Unflattening\n",
    "    dZ_pool_output = dZ_pool_output.reshape(12,12,2)\n",
    "    \n",
    "    # Unpooling\n",
    "    dZ_pool_input = np.zeros((24,24,2))\n",
    "    for i in range(12): # height\n",
    "        for j in range(12): # width\n",
    "            for k in range(2): # depth\n",
    "                # Get the global indices from layer_indices\n",
    "                x_index, y_index = layer_indices[i, j, k]\n",
    "                # Assign the gradient from dZ_pool_output to the corresponding position in dZ_pool_input\n",
    "                dZ_pool_input[x_index, y_index, k] = dZ_pool_output[i, j, k]\n",
    "    \n",
    "    # Backpropogating convolutional layer - dZ_pool_input is the output of the convolutional layer\n",
    "    for i in range(2): # For each filter in the kernel - # of filters = 2\n",
    "        delta_conv_weights[:,:,i] = signal.correlate(layer_input, dZ_pool_input[:,:,i], mode = \"valid\") #\n",
    "    delta_conv_bias = dZ_pool_input\n",
    "\n",
    "    return delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias\n",
    "\n",
    "def update_params(layer_weights, layer_bias, fc_weights, fc_bias, delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias, learning_rate):\n",
    "    layer_weights \n",
    "    layer_weights = layer_weights - learning_rate * delta_conv_weights\n",
    "    layer_bias = layer_bias - learning_rate * delta_conv_bias\n",
    "    fc_weights = fc_weights -learning_rate * delta_fc_weights\n",
    "    fc_bias = fc_bias - learning_rate * delta_fc_bias\n",
    "    return layer_weights, layer_bias, fc_weights, fc_bias\n",
    "\n",
    "def get_prediction(A2):\n",
    "  return np.argmax(A2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "82da6438-d7ca-4ebb-bb38-7dd0e611f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, epochs, learning_rate, batch_size):\n",
    "    # Initialize parameters\n",
    "    layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "    num_examples = X_train.shape[2]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch:\", i+1)\n",
    "        \n",
    "        # Generate a random permutation of indices\n",
    "        permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "\n",
    "        # Shuffle both X_train and Y_train using the same permutation of indices\n",
    "        X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "        Y_train_shuffled = Y_train[permuted_indices]\n",
    "\n",
    "        for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, num_examples)\n",
    "            batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "            for j in range(batch_start, batch_end):\n",
    "                # print(batch_start, batch_end, j)\n",
    "                # Get a single training example\n",
    "                layer_input = X_train_shuffled[:, :, j]\n",
    "                label = Y_train_shuffled[j]\n",
    "\n",
    "                # Forward propagation\n",
    "                layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                    layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "                )\n",
    "\n",
    "                # Back propagation\n",
    "                delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                    layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "                    layer_weights, layer_bias, fc_weights, fc_bias\n",
    "                )\n",
    "\n",
    "                # Accumulate gradients\n",
    "                batch_gradients[0] += delta_conv_weights\n",
    "                batch_gradients[1] += delta_conv_bias\n",
    "                batch_gradients[2] += delta_fc_weights\n",
    "                batch_gradients[3] += delta_fc_bias\n",
    "\n",
    "            # Average gradients after processing the batch\n",
    "            batch_gradients = [grad / batch_size for grad in batch_gradients]\n",
    "\n",
    "            # Update parameters after processing the batch\n",
    "            layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "                layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "                *batch_gradients,  # Use averaged gradients\n",
    "                learning_rate\n",
    "            )\n",
    "\n",
    "        # Get the accuracy\n",
    "        counter = 0\n",
    "        for j in range(750):\n",
    "            test_input = X_dev[:, :, j]\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "            prediction = get_prediction(final_output)\n",
    "            predicted_label = prediction[0]\n",
    "            if Y_dev[j] == predicted_label:\n",
    "                counter += 1\n",
    "        print(\"Accuracy:\", counter / 750)\n",
    "\n",
    "    return layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45106863-de98-4639-8fc5-92edb75e446c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Accuracy: 0.008\n",
      "Epoch: 2\n",
      "Accuracy: 0.010666666666666666\n",
      "Epoch: 3\n",
      "Accuracy: 0.009333333333333334\n",
      "Epoch: 4\n",
      "Accuracy: 0.018666666666666668\n",
      "Epoch: 5\n"
     ]
    }
   ],
   "source": [
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, 50, 0.3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d9369295-5435-42b4-9002-14028249d962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Accuracy: 0.10266666666666667\n",
      "Epoch: 2\n",
      "Accuracy: 0.08933333333333333\n",
      "Epoch: 3\n",
      "Accuracy: 0.088\n",
      "Epoch: 4\n",
      "Accuracy: 0.08666666666666667\n",
      "Epoch: 5\n",
      "Accuracy: 0.08533333333333333\n",
      "Epoch: 6\n",
      "Accuracy: 0.08533333333333333\n",
      "Epoch: 7\n",
      "Accuracy: 0.08533333333333333\n",
      "Epoch: 8\n",
      "Accuracy: 0.084\n",
      "Epoch: 9\n",
      "Accuracy: 0.084\n",
      "Epoch: 10\n",
      "Accuracy: 0.08266666666666667\n",
      "Epoch: 11\n",
      "Accuracy: 0.08266666666666667\n",
      "Epoch: 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layer_weights, layer_bias, layer_output, fc_weights, fc_bias \u001b[38;5;241m=\u001b[39m \u001b[43mstochastic_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 54\u001b[0m, in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(X_train, X_dev, Y_train, Y_dev, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m750\u001b[39m):\n\u001b[1;32m     53\u001b[0m     test_input \u001b[38;5;241m=\u001b[39m X_dev[:, :, j]\n\u001b[0;32m---> 54\u001b[0m     layer_output, layer_pool, layer_indices, final_output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_bias\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m get_prediction(final_output)\n\u001b[1;32m     58\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[117], line 33\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias)\u001b[0m\n\u001b[1;32m     30\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m ReLU(layer_output)  \u001b[38;5;66;03m# (24, 24, 2)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Pool layer\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m layer_pool, layer_indices \u001b[38;5;241m=\u001b[39m \u001b[43mmax_pooling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (12, 12, 2)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Flattening (changed to 288,1)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m layer_pool \u001b[38;5;241m=\u001b[39m layer_pool\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m288\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (288,1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mmax_pooling\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m region \u001b[38;5;241m=\u001b[39m input_data[h\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:(h\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, w\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:(w\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, d]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute the maximum value in the region\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m max_val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m output_data[h, w, d] \u001b[38;5;241m=\u001b[39m max_val\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Find the indices of the maximum value in the region\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2692\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_max_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2688\u001b[0m                     where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m-> 2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mmaximum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[1;32m   2811\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# layer_weights, layer_bias, layer_output, fc_weights, fc_bias = stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, 10, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfa0ca-62b1-4f6d-b244-ba820e803088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "batch_size = 2000\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch:\", i+1)\n",
    "    \n",
    "    # Generate a random permutation of indices\n",
    "    permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "\n",
    "    # Shuffle both X_train and Y_train using the same permutation of indices\n",
    "    X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "    Y_train_shuffled = Y_train[permuted_indices]\n",
    "\n",
    "    for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(X_train_shuffled))\n",
    "        batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "        for j in range(batch_start, batch_end):\n",
    "            # Get a single training example\n",
    "            layer_input = X_train_shuffled[:, :, j]\n",
    "            label = Y_train_shuffled[j]\n",
    "\n",
    "            # Forward propagation\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "\n",
    "            # Back propagation\n",
    "            delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "                layer_weights, layer_bias, fc_weights, fc_bias\n",
    "            )\n",
    "\n",
    "            # Accumulate gradients\n",
    "            batch_gradients[0] += delta_conv_weights\n",
    "            batch_gradients[1] += delta_conv_bias\n",
    "            batch_gradients[2] += delta_fc_weights\n",
    "            batch_gradients[3] += delta_fc_bias\n",
    "\n",
    "        # Average gradients after processing the batch\n",
    "        batch_gradients = [grad / batch_size for grad in batch_gradients]\n",
    "\n",
    "        # Update parameters after processing the batch\n",
    "        layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "            layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "            *batch_gradients,  # Use averaged gradients\n",
    "            learning_rate\n",
    "        )\n",
    "\n",
    "    # Get the accuracy\n",
    "    counter = 0\n",
    "    for j in range(750):\n",
    "        test_input = X_dev[:, :, j]\n",
    "        layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "            test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "        )\n",
    "        prediction = get_prediction(final_output)\n",
    "        predicted_label = prediction[0]\n",
    "        if Y_dev[j] == predicted_label:\n",
    "            counter += 1\n",
    "    print(\"Accuracy:\", counter / 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fe5e4e4-2c9c-48c8-8f9a-1b506ae446fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "347324b7-1503-442c-99ae-e8454cce1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e8af405-d2e9-4aa2-8b1d-f639f8ba86e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 41000)\n",
      "(41000,)\n",
      "(28, 28, 41000)\n",
      "(41000,)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random permutation of indices\n",
    "permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "# Shuffle both X_train and Y_train using the same permutation of indices\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "Y_train_shuffled = Y_train[permuted_indices]\n",
    "print(X_train_shuffled.shape)\n",
    "print(Y_train_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00505807-682e-4d76-8a12-b0025b6de059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a training batch\n",
    "for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(X_train_shuffled))\n",
    "    batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "    for j in range(batch_start, batch_end):\n",
    "        # Get a single training example\n",
    "        layer_input = X_train_shuffled[:, :, j]\n",
    "        label = Y_train_shuffled[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66b04fb3-7b88-4034-8ba4-2bec8e1e3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "    layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "baedc9e8-e0f2-4819-a421-8de7305123dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propagation\n",
    "delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "    layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "    layer_weights, layer_bias, fc_weights, fc_bias\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93915544-9066-4247-b7c5-c681f6da4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gradients[0] += delta_conv_weights\n",
    "batch_gradients[1] += delta_conv_bias\n",
    "batch_gradients[2] += delta_fc_weights\n",
    "batch_gradients[3] += delta_fc_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ef29900-65f8-4ab9-bc87-1bcbaa5a447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average gradients after processing the batch\n",
    "batch_gradients = [grad / batch_size for grad in batch_gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1606c7e8-2917-4914-bd23-514505b21dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters after processing the batch\n",
    "layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "    layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "    *batch_gradients,  # Use averaged gradients\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "180bc097-d67e-4be3-97ff-5179fd6954b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09866666666666667\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy\n",
    "counter = 0\n",
    "for j in range(750):\n",
    "    test_input = X_dev[:, :, j]\n",
    "    layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "        test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "    )\n",
    "    prediction = get_prediction(final_output)\n",
    "    predicted_label = prediction[0]\n",
    "    if Y_dev[j] == predicted_label:\n",
    "        counter += 1\n",
    "print(\"Accuracy:\", counter / 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c6dd5001-17a6-4445-9d77-c455a4774bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer weights [[[ -12.15165541 -117.99700125]\n",
      "  [  -2.78956857  -90.79947179]\n",
      "  [ -49.9251018   -87.0235131 ]\n",
      "  [-121.19267874 -112.2672154 ]\n",
      "  [  -3.56354143 -134.38922531]]\n",
      "\n",
      " [[ -31.16769807 -100.49022435]\n",
      "  [ -14.43604203  -88.09573326]\n",
      "  [  -8.80938841 -106.12604368]\n",
      "  [ -12.19125561 -139.47435795]\n",
      "  [ -11.4896987  -146.20311685]]\n",
      "\n",
      " [[ -41.19882701  -96.86864108]\n",
      "  [ -22.50043357 -105.7431442 ]\n",
      "  [ -19.12630339 -125.59905047]\n",
      "  [ -29.55747443 -143.16556516]\n",
      "  [ -27.55740224 -145.20386678]]\n",
      "\n",
      " [[ -51.2187216   -83.82715286]\n",
      "  [ -30.26027418 -112.36828755]\n",
      "  [ -30.32715768 -130.36582386]\n",
      "  [ -46.67602994 -129.37748134]\n",
      "  [ -47.7108522  -121.28933543]]\n",
      "\n",
      " [[ -62.02701532  -62.22071897]\n",
      "  [ -41.9447678   -88.1478176 ]\n",
      "  [ -38.61864315  -94.40067715]\n",
      "  [ -58.58463115  -77.28027216]\n",
      "  [ -62.83591476  -69.37446679]]]\n",
      "layer bias [[[-1.02757576e-02  1.04961230e-02]\n",
      "  [-1.26965870e-01 -1.05489338e+00]\n",
      "  [-2.46142606e-01 -1.73268730e-01]\n",
      "  ...\n",
      "  [-8.34197263e-01 -7.02748346e-01]\n",
      "  [-4.45962531e-02 -1.21916420e-01]\n",
      "  [-1.36241557e+00 -4.20055440e-01]]\n",
      "\n",
      " [[-4.38219846e-02  5.54200836e-01]\n",
      "  [-1.20247101e+00  1.84487728e-01]\n",
      "  [-5.26884201e-01 -3.37851888e-02]\n",
      "  ...\n",
      "  [-5.51861743e+00 -6.95088855e-01]\n",
      "  [-1.38074270e+00  1.53867846e-01]\n",
      "  [-2.48688156e-01 -4.30267939e-02]]\n",
      "\n",
      " [[-4.33637897e-02 -2.96285201e-01]\n",
      "  [-6.11105673e-02 -1.30195114e-01]\n",
      "  [-3.37221675e+00 -2.25551037e-01]\n",
      "  ...\n",
      "  [-1.35793525e+01 -1.17490850e+01]\n",
      "  [-3.03330406e-01 -1.25600986e+00]\n",
      "  [-7.87366299e-01 -1.09341225e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.75371273e-02 -4.09446353e-01]\n",
      "  [-3.83249604e-01 -1.26304857e+00]\n",
      "  [-2.69020316e-01 -2.81005086e-01]\n",
      "  ...\n",
      "  [-3.91415343e-01 -2.01514747e-01]\n",
      "  [-2.83636053e-02 -6.66736032e-01]\n",
      "  [-4.34776386e-01 -4.83713285e-01]]\n",
      "\n",
      " [[-5.38476871e-01 -6.01358782e+00]\n",
      "  [ 9.12717077e-01 -8.41483909e-02]\n",
      "  [-9.94181791e-02 -1.92645632e+01]\n",
      "  ...\n",
      "  [-2.66613324e-01 -1.37628155e+00]\n",
      "  [-1.24378261e+00 -6.22726599e-01]\n",
      "  [ 6.69374156e-01 -1.49943901e+00]]\n",
      "\n",
      " [[-3.19746745e-01 -3.60045463e-01]\n",
      "  [ 3.35214858e-01 -7.40996854e+00]\n",
      "  [ 1.61195667e-02 -1.10010167e+00]\n",
      "  ...\n",
      "  [-1.55256233e-01 -4.91949950e+00]\n",
      "  [ 7.22029187e-02 -3.80815599e-01]\n",
      "  [ 8.02390781e-02 -1.17076987e-02]]]\n",
      "layer output [[[0.         0.01049612]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.55420084]\n",
      "  [0.         0.18448773]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.15386785]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.91271708 0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.66937416 0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.33521486 0.        ]\n",
      "  [0.01611957 0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.07220292 0.        ]\n",
      "  [0.08023908 0.        ]]]\n",
      "fc weights [[-0.78365048 -1.07411532  0.40648519 ...  1.18049451 -1.05516261\n",
      "  -1.61311148]\n",
      " [-0.24728409 -0.02411486 -0.39916386 ... -2.74114412  0.07809228\n",
      "  -0.4884818 ]\n",
      " [ 0.94186909  0.69588405  3.04875741 ...  8.72056183  0.09190731\n",
      "   6.16301192]\n",
      " ...\n",
      " [ 0.09574712 -0.37425917  0.22820399 ...  1.78798417 -0.31229823\n",
      "  -0.03081021]\n",
      " [ 0.12252832  0.23133784 -0.02108229 ...  2.44444617  0.28909643\n",
      "   0.74548742]\n",
      " [-0.06706137 -0.17354469 -0.16733226 ...  3.87123152 -0.12989382\n",
      "   1.01738235]]\n",
      "fc_bias [[-1.319305  ]\n",
      " [ 0.8345076 ]\n",
      " [-1.90449779]\n",
      " [ 0.33733743]\n",
      " [-0.31474554]\n",
      " [-0.50912293]\n",
      " [-0.19075376]\n",
      " [ 1.53555455]\n",
      " [ 0.16639665]\n",
      " [ 0.82103221]]\n"
     ]
    }
   ],
   "source": [
    "print(\"layer weights\", layer_weights)\n",
    "print(\"layer bias\", layer_bias)\n",
    "print(\"layer output\", layer_output)\n",
    "print(\"fc weights\", fc_weights)\n",
    "print(\"fc_bias\", fc_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f93376-fa78-4650-900f-c222b2a50e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training loop\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        Y_batch = Y_train[i:i+batch_size]\n",
    "\n",
    "        for x, y in zip(X_batch, Y_batch):\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                x, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "\n",
    "            delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                x, layer_output, layer_pool, layer_indices, final_output, y, layer_weights, layer_bias, fc_weights, fc_bias\n",
    "           \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef195e91-cf22-43c4-aec2-67216b6353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d8f8ca-66fc-4a13-8442-04e4a21ba2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d100e1c-fe7d-4718-8f90-081afa05ccfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "def plot_mnist_image(image_array):\n",
    "    image = image_array.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "plot_mnist_image(data[2, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ef5ed9-2c6a-4060-aaf1-84f5c75767ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "m, n = data.shape\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e6b5f1-e3a7-43a7-96b9-4cc371322534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 1, 4, ..., 5, 6, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data) # Shuffles all the individual rows\n",
    "data_dev = data[0:1000].T #Take the first 1000 rows, and transpose the matrix to get 1000 examples as column vectors\n",
    "data_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfc2746-5ec9-48b7-8f56-18f31dee1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev = data_dev[0] #Takes the first row, which contains all of the answers to the numbers (the Y is what we want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca04569-7231-41b8-a1a5-880d4cb8abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = data_dev[1:]\n",
    "X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bce0cb-6db8-4824-b6fa-7afdba377565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_dev = X_dev.reshape(28,28,1000)\n",
    "print(X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b59dca3-a0e1-4c4c-8897-c31be0d041d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# print(X_dev[:,:,1])\n",
    "plot_mnist_image(X_dev[:,:,6])\n",
    "print(Y_dev[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90aef05-a41a-4c59-ad00-63c93e1fffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fcae13-b528-49de-a18f-b6f9ed4cfb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= data_train[1:n] #Takes all of the data corresponding to all of the entries\n",
    "X_train = X_train.reshape(28,28,41000)\n",
    "X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7b515a33-35df-49d8-80fc-b3fb17971ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(input_data):\n",
    "    # 24, 24, 2\n",
    "    input_height, input_width, input_depth = input_data.shape\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = input_height // 2 # 12\n",
    "    output_width = input_width // 2 # 12\n",
    "    output_depth = input_depth # 2 - depth stays the same\n",
    "\n",
    "    # Initialize the output array and array to store indices\n",
    "    output_data = np.zeros((output_height, output_width, output_depth))\n",
    "    indices = np.zeros((output_height, output_width, output_depth, 2), dtype=int)\n",
    "\n",
    "    # Apply max pooling\n",
    "    for h in range(output_height):\n",
    "        for w in range(output_width):\n",
    "            for d in range(output_depth):\n",
    "                # Extract the 2x2 region of interest from the input data\n",
    "                region = input_data[h*2:(h+1)*2, w*2:(w+1)*2, d]\n",
    "                # Compute the maximum value in the region\n",
    "                max_val = np.max(region)\n",
    "                output_data[h, w, d] = max_val\n",
    "                # Find the indices of the maximum value in the region\n",
    "                max_indices = np.unravel_index(np.argmax(region), region.shape)\n",
    "                # Store the indices relative to the region and convert to global indices\n",
    "                indices[h, w, d] = [h*2 + max_indices[0], w*2 + max_indices[1]]\n",
    "\n",
    "    return output_data, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6d7b5b43-0f57-4013-ab85-80ec5b90216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_ReLU(Z):\n",
    "  return Z > 0\n",
    "\n",
    "def der_ReLU2(Z):\n",
    "  return np.where(Z > 0, 1, 0.1)\n",
    "\n",
    "def ReLU(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU2(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def sigmoid(z):\n",
    "    # Compute the sigmoid function element-wise\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def softmax(Z):\n",
    "    # Apply softmax column-wise\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0))  # Subtracting the maximum value in each column to avoid overflow\n",
    "    return exp_Z / np.sum(exp_Z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "460fd0ab-c756-4c3a-a2e9-77ad87330d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def params():\n",
    "    layer_weights = np.random.randn(5, 5, 2) * np.sqrt(2. / 5)\n",
    "    layer_bias = np.random.randn(24, 24, 2) * np.sqrt(2. / 5)\n",
    "    layer_output = np.zeros((24,24,2)) #(24,24,2)\n",
    "    fc_weights = np.random.randn(10, 288) * np.sqrt(2. / 288)\n",
    "    fc_bias = np.random.randn(10,1) #(10, 1)\n",
    "    # fc_bias *= 0\n",
    "    fc_bias = fc_bias.reshape(10, 1)\n",
    "    return layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "\n",
    "def forward_propagation(layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias):\n",
    "    # layer_input (28, 28)\n",
    "    # layer_weights (5, 5, 2)\n",
    "    # layer_bias (24, 24, 2)\n",
    "    # layer_output (24, 24, 2)\n",
    "    # layer_bias (10, 288)\n",
    "    # layer_bias (10, 1)\n",
    "    \n",
    "    # Convolution\n",
    "    for i in range(2): # 2 filters in total\n",
    "        layer_output[:,:,i] = signal.correlate2d(layer_input, layer_weights[:,:,i], mode='valid')\n",
    "    layer_output = layer_output + layer_bias   # (24, 24, 2)\n",
    "    \n",
    "    # Activation layer\n",
    "    layer_output = ReLU(layer_output)  # (24, 24, 2)\n",
    "    \n",
    "    # Pool layer\n",
    "    layer_pool, layer_indices = max_pooling(layer_output)  # (12, 12, 2)\n",
    "\n",
    "    \n",
    "    # Flattening (changed to 288,1)\n",
    "    layer_pool = layer_pool.reshape(288,1) # (288,1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    final_output = fc_weights.dot(layer_pool)  # (10, 288) (288, 1) = (10, 1)\n",
    "    final_output.reshape(10,1) \n",
    "    final_output = final_output + fc_bias # (10, 1) + (10, 1) = (10, 1)\n",
    "    final_output = softmax(final_output) # (10, 1) -> (10, 1)\n",
    "    \n",
    "    return layer_output, layer_pool, layer_indices, final_output\n",
    "\n",
    "\n",
    "def create(Y):\n",
    "  column_Y = np.zeros((10, 1))\n",
    "  column_Y[Y] = 1\n",
    "  column_Y = column_Y.T\n",
    "  return column_Y.reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "26a21241-e082-487c-a194-adb44fa414b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropogation through layers\n",
    "\n",
    "def back_prop(layer_input, layer_output, layer_pool, layer_indices, final_output, label, layer_weights, layer_bias, fc_weights, fc_bias):\n",
    "    # Initalize parameters\n",
    "    delta_conv_weights = np.zeros((5,5,2))  # (5,5,2)\n",
    "    delta_conv_bias = np.zeros((24,24,2)) # (24, 24, 2)\n",
    "    delta_fc_weights = np.zeros((10, 288)) #  (10, 288)\n",
    "    delta_fc_bias = np.zeros((10, 1)) # (10, 1)\n",
    "    delta_fc_bias.reshape(10, 1)\n",
    "    \n",
    "    # Backpropogate cost\n",
    "    x = create(label) \n",
    "    dZ = (final_output - x) # (10,1) - (10,1) = (10,1) \n",
    "    # dZ = dZ.reshape((10,1))\n",
    "    \n",
    "    #Backpropogate weights and biases\n",
    "    layer_pool = layer_pool.reshape(1,288)\n",
    "    delta_fc_weights = dZ.dot(layer_pool) # (10 x 1 ) (1 x 288) = (10 x 288)\n",
    "    delta_fc_bias = dZ\n",
    "    \n",
    "    # Backpropogate error\n",
    "    dZ_pool_output = np.dot(fc_weights.T, dZ) * der_ReLU(layer_pool.reshape(288, 1)) #(288 x 10) (10 x 1) = (288 x 1)\n",
    "    \n",
    "    # Unflattening\n",
    "    dZ_pool_output = dZ_pool_output.reshape(12,12,2)\n",
    "    \n",
    "    # Unpooling\n",
    "    dZ_pool_input = np.zeros((24,24,2))\n",
    "    for i in range(12): # height\n",
    "        for j in range(12): # width\n",
    "            for k in range(2): # depth\n",
    "                # Get the global indices from layer_indices\n",
    "                x_index, y_index = layer_indices[i, j, k]\n",
    "                # Assign the gradient from dZ_pool_output to the corresponding position in dZ_pool_input\n",
    "                dZ_pool_input[x_index, y_index, k] = dZ_pool_output[i, j, k]\n",
    "    \n",
    "    # Backpropogating convolutional layer - dZ_pool_input is the output of the convolutional layer\n",
    "    for i in range(2): # For each filter in the kernel - # of filters = 2\n",
    "        delta_conv_weights[:,:,i] = signal.correlate(layer_input, dZ_pool_input[:,:,i], mode = \"valid\") #\n",
    "    delta_conv_bias = dZ_pool_input\n",
    "\n",
    "    return delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias\n",
    "\n",
    "def update_params(layer_weights, layer_bias, fc_weights, fc_bias, delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias, learning_rate):\n",
    "    layer_weights \n",
    "    layer_weights = layer_weights - learning_rate * delta_conv_weights\n",
    "    layer_bias = layer_bias - learning_rate * delta_conv_bias\n",
    "    fc_weights = fc_weights -learning_rate * delta_fc_weights\n",
    "    fc_bias = fc_bias - learning_rate * delta_fc_bias\n",
    "    return layer_weights, layer_bias, fc_weights, fc_bias\n",
    "\n",
    "def get_prediction(A2):\n",
    "  return np.argmax(A2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "82da6438-d7ca-4ebb-bb38-7dd0e611f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, epochs, learning_rate, batch_size):\n",
    "    # Initialize parameters\n",
    "    layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "    num_examples = X_train.shape[2]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch:\", i+1)\n",
    "        \n",
    "        # Generate a random permutation of indices\n",
    "        permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "\n",
    "        # Shuffle both X_train and Y_train using the same permutation of indices\n",
    "        X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "        Y_train_shuffled = Y_train[permuted_indices]\n",
    "\n",
    "        for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, num_examples)\n",
    "            batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "            for j in range(batch_start, batch_end):\n",
    "                # print(batch_start, batch_end, j)\n",
    "                # Get a single training example\n",
    "                layer_input = X_train_shuffled[:, :, j]\n",
    "                label = Y_train_shuffled[j]\n",
    "\n",
    "                # Forward propagation\n",
    "                layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                    layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "                )\n",
    "\n",
    "                # Back propagation\n",
    "                delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                    layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "                    layer_weights, layer_bias, fc_weights, fc_bias\n",
    "                )\n",
    "\n",
    "                # Accumulate gradients\n",
    "                batch_gradients[0] += delta_conv_weights\n",
    "                batch_gradients[1] += delta_conv_bias\n",
    "                batch_gradients[2] += delta_fc_weights\n",
    "                batch_gradients[3] += delta_fc_bias\n",
    "\n",
    "            # Average gradients after processing the batch\n",
    "            batch_gradients = [grad / batch_size for grad in batch_gradients]\n",
    "\n",
    "            # Update parameters after processing the batch\n",
    "            layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "                layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "                *batch_gradients,  # Use averaged gradients\n",
    "                learning_rate\n",
    "            )\n",
    "\n",
    "        # Get the accuracy\n",
    "        counter = 0\n",
    "        for j in range(750):\n",
    "            test_input = X_dev[:, :, j]\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "            prediction = get_prediction(final_output)\n",
    "            predicted_label = prediction[0]\n",
    "            if Y_dev[j] == predicted_label:\n",
    "                counter += 1\n",
    "        print(\"Accuracy:\", counter / 750)\n",
    "\n",
    "    return layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45106863-de98-4639-8fc5-92edb75e446c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Accuracy: 0.008\n",
      "Epoch: 2\n",
      "Accuracy: 0.010666666666666666\n",
      "Epoch: 3\n",
      "Accuracy: 0.009333333333333334\n",
      "Epoch: 4\n",
      "Accuracy: 0.018666666666666668\n",
      "Epoch: 5\n"
     ]
    }
   ],
   "source": [
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, 50, 0.3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d9369295-5435-42b4-9002-14028249d962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Accuracy: 0.10266666666666667\n",
      "Epoch: 2\n",
      "Accuracy: 0.08933333333333333\n",
      "Epoch: 3\n",
      "Accuracy: 0.088\n",
      "Epoch: 4\n",
      "Accuracy: 0.08666666666666667\n",
      "Epoch: 5\n",
      "Accuracy: 0.08533333333333333\n",
      "Epoch: 6\n",
      "Accuracy: 0.08533333333333333\n",
      "Epoch: 7\n",
      "Accuracy: 0.08533333333333333\n",
      "Epoch: 8\n",
      "Accuracy: 0.084\n",
      "Epoch: 9\n",
      "Accuracy: 0.084\n",
      "Epoch: 10\n",
      "Accuracy: 0.08266666666666667\n",
      "Epoch: 11\n",
      "Accuracy: 0.08266666666666667\n",
      "Epoch: 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layer_weights, layer_bias, layer_output, fc_weights, fc_bias \u001b[38;5;241m=\u001b[39m \u001b[43mstochastic_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 54\u001b[0m, in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(X_train, X_dev, Y_train, Y_dev, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m750\u001b[39m):\n\u001b[1;32m     53\u001b[0m     test_input \u001b[38;5;241m=\u001b[39m X_dev[:, :, j]\n\u001b[0;32m---> 54\u001b[0m     layer_output, layer_pool, layer_indices, final_output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_bias\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m get_prediction(final_output)\n\u001b[1;32m     58\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[117], line 33\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias)\u001b[0m\n\u001b[1;32m     30\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m ReLU(layer_output)  \u001b[38;5;66;03m# (24, 24, 2)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Pool layer\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m layer_pool, layer_indices \u001b[38;5;241m=\u001b[39m \u001b[43mmax_pooling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (12, 12, 2)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Flattening (changed to 288,1)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m layer_pool \u001b[38;5;241m=\u001b[39m layer_pool\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m288\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (288,1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mmax_pooling\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m region \u001b[38;5;241m=\u001b[39m input_data[h\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:(h\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, w\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:(w\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, d]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute the maximum value in the region\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m max_val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m output_data[h, w, d] \u001b[38;5;241m=\u001b[39m max_val\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Find the indices of the maximum value in the region\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2692\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_max_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2688\u001b[0m                     where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m-> 2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mmaximum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[1;32m   2811\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# layer_weights, layer_bias, layer_output, fc_weights, fc_bias = stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, 10, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfa0ca-62b1-4f6d-b244-ba820e803088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "batch_size = 2000\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch:\", i+1)\n",
    "    \n",
    "    # Generate a random permutation of indices\n",
    "    permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "\n",
    "    # Shuffle both X_train and Y_train using the same permutation of indices\n",
    "    X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "    Y_train_shuffled = Y_train[permuted_indices]\n",
    "\n",
    "    for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(X_train_shuffled))\n",
    "        batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "        for j in range(batch_start, batch_end):\n",
    "            # Get a single training example\n",
    "            layer_input = X_train_shuffled[:, :, j]\n",
    "            label = Y_train_shuffled[j]\n",
    "\n",
    "            # Forward propagation\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "\n",
    "            # Back propagation\n",
    "            delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "                layer_weights, layer_bias, fc_weights, fc_bias\n",
    "            )\n",
    "\n",
    "            # Accumulate gradients\n",
    "            batch_gradients[0] += delta_conv_weights\n",
    "            batch_gradients[1] += delta_conv_bias\n",
    "            batch_gradients[2] += delta_fc_weights\n",
    "            batch_gradients[3] += delta_fc_bias\n",
    "\n",
    "        # Average gradients after processing the batch\n",
    "        batch_gradients = [grad / batch_size for grad in batch_gradients]\n",
    "\n",
    "        # Update parameters after processing the batch\n",
    "        layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "            layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "            *batch_gradients,  # Use averaged gradients\n",
    "            learning_rate\n",
    "        )\n",
    "\n",
    "    # Get the accuracy\n",
    "    counter = 0\n",
    "    for j in range(750):\n",
    "        test_input = X_dev[:, :, j]\n",
    "        layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "            test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "        )\n",
    "        prediction = get_prediction(final_output)\n",
    "        predicted_label = prediction[0]\n",
    "        if Y_dev[j] == predicted_label:\n",
    "            counter += 1\n",
    "    print(\"Accuracy:\", counter / 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fe5e4e4-2c9c-48c8-8f9a-1b506ae446fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "347324b7-1503-442c-99ae-e8454cce1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e8af405-d2e9-4aa2-8b1d-f639f8ba86e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 41000)\n",
      "(41000,)\n",
      "(28, 28, 41000)\n",
      "(41000,)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random permutation of indices\n",
    "permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "# Shuffle both X_train and Y_train using the same permutation of indices\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "Y_train_shuffled = Y_train[permuted_indices]\n",
    "print(X_train_shuffled.shape)\n",
    "print(Y_train_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00505807-682e-4d76-8a12-b0025b6de059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a training batch\n",
    "for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(X_train_shuffled))\n",
    "    batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "    for j in range(batch_start, batch_end):\n",
    "        # Get a single training example\n",
    "        layer_input = X_train_shuffled[:, :, j]\n",
    "        label = Y_train_shuffled[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66b04fb3-7b88-4034-8ba4-2bec8e1e3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "    layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "baedc9e8-e0f2-4819-a421-8de7305123dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propagation\n",
    "delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "    layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "    layer_weights, layer_bias, fc_weights, fc_bias\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93915544-9066-4247-b7c5-c681f6da4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gradients[0] += delta_conv_weights\n",
    "batch_gradients[1] += delta_conv_bias\n",
    "batch_gradients[2] += delta_fc_weights\n",
    "batch_gradients[3] += delta_fc_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ef29900-65f8-4ab9-bc87-1bcbaa5a447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average gradients after processing the batch\n",
    "batch_gradients = [grad / batch_size for grad in batch_gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1606c7e8-2917-4914-bd23-514505b21dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters after processing the batch\n",
    "layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "    layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "    *batch_gradients,  # Use averaged gradients\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "180bc097-d67e-4be3-97ff-5179fd6954b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09866666666666667\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy\n",
    "counter = 0\n",
    "for j in range(750):\n",
    "    test_input = X_dev[:, :, j]\n",
    "    layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "        test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "    )\n",
    "    prediction = get_prediction(final_output)\n",
    "    predicted_label = prediction[0]\n",
    "    if Y_dev[j] == predicted_label:\n",
    "        counter += 1\n",
    "print(\"Accuracy:\", counter / 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c6dd5001-17a6-4445-9d77-c455a4774bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer weights [[[ -12.15165541 -117.99700125]\n",
      "  [  -2.78956857  -90.79947179]\n",
      "  [ -49.9251018   -87.0235131 ]\n",
      "  [-121.19267874 -112.2672154 ]\n",
      "  [  -3.56354143 -134.38922531]]\n",
      "\n",
      " [[ -31.16769807 -100.49022435]\n",
      "  [ -14.43604203  -88.09573326]\n",
      "  [  -8.80938841 -106.12604368]\n",
      "  [ -12.19125561 -139.47435795]\n",
      "  [ -11.4896987  -146.20311685]]\n",
      "\n",
      " [[ -41.19882701  -96.86864108]\n",
      "  [ -22.50043357 -105.7431442 ]\n",
      "  [ -19.12630339 -125.59905047]\n",
      "  [ -29.55747443 -143.16556516]\n",
      "  [ -27.55740224 -145.20386678]]\n",
      "\n",
      " [[ -51.2187216   -83.82715286]\n",
      "  [ -30.26027418 -112.36828755]\n",
      "  [ -30.32715768 -130.36582386]\n",
      "  [ -46.67602994 -129.37748134]\n",
      "  [ -47.7108522  -121.28933543]]\n",
      "\n",
      " [[ -62.02701532  -62.22071897]\n",
      "  [ -41.9447678   -88.1478176 ]\n",
      "  [ -38.61864315  -94.40067715]\n",
      "  [ -58.58463115  -77.28027216]\n",
      "  [ -62.83591476  -69.37446679]]]\n",
      "layer bias [[[-1.02757576e-02  1.04961230e-02]\n",
      "  [-1.26965870e-01 -1.05489338e+00]\n",
      "  [-2.46142606e-01 -1.73268730e-01]\n",
      "  ...\n",
      "  [-8.34197263e-01 -7.02748346e-01]\n",
      "  [-4.45962531e-02 -1.21916420e-01]\n",
      "  [-1.36241557e+00 -4.20055440e-01]]\n",
      "\n",
      " [[-4.38219846e-02  5.54200836e-01]\n",
      "  [-1.20247101e+00  1.84487728e-01]\n",
      "  [-5.26884201e-01 -3.37851888e-02]\n",
      "  ...\n",
      "  [-5.51861743e+00 -6.95088855e-01]\n",
      "  [-1.38074270e+00  1.53867846e-01]\n",
      "  [-2.48688156e-01 -4.30267939e-02]]\n",
      "\n",
      " [[-4.33637897e-02 -2.96285201e-01]\n",
      "  [-6.11105673e-02 -1.30195114e-01]\n",
      "  [-3.37221675e+00 -2.25551037e-01]\n",
      "  ...\n",
      "  [-1.35793525e+01 -1.17490850e+01]\n",
      "  [-3.03330406e-01 -1.25600986e+00]\n",
      "  [-7.87366299e-01 -1.09341225e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.75371273e-02 -4.09446353e-01]\n",
      "  [-3.83249604e-01 -1.26304857e+00]\n",
      "  [-2.69020316e-01 -2.81005086e-01]\n",
      "  ...\n",
      "  [-3.91415343e-01 -2.01514747e-01]\n",
      "  [-2.83636053e-02 -6.66736032e-01]\n",
      "  [-4.34776386e-01 -4.83713285e-01]]\n",
      "\n",
      " [[-5.38476871e-01 -6.01358782e+00]\n",
      "  [ 9.12717077e-01 -8.41483909e-02]\n",
      "  [-9.94181791e-02 -1.92645632e+01]\n",
      "  ...\n",
      "  [-2.66613324e-01 -1.37628155e+00]\n",
      "  [-1.24378261e+00 -6.22726599e-01]\n",
      "  [ 6.69374156e-01 -1.49943901e+00]]\n",
      "\n",
      " [[-3.19746745e-01 -3.60045463e-01]\n",
      "  [ 3.35214858e-01 -7.40996854e+00]\n",
      "  [ 1.61195667e-02 -1.10010167e+00]\n",
      "  ...\n",
      "  [-1.55256233e-01 -4.91949950e+00]\n",
      "  [ 7.22029187e-02 -3.80815599e-01]\n",
      "  [ 8.02390781e-02 -1.17076987e-02]]]\n",
      "layer output [[[0.         0.01049612]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.55420084]\n",
      "  [0.         0.18448773]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.15386785]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.91271708 0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.66937416 0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.33521486 0.        ]\n",
      "  [0.01611957 0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.07220292 0.        ]\n",
      "  [0.08023908 0.        ]]]\n",
      "fc weights [[-0.78365048 -1.07411532  0.40648519 ...  1.18049451 -1.05516261\n",
      "  -1.61311148]\n",
      " [-0.24728409 -0.02411486 -0.39916386 ... -2.74114412  0.07809228\n",
      "  -0.4884818 ]\n",
      " [ 0.94186909  0.69588405  3.04875741 ...  8.72056183  0.09190731\n",
      "   6.16301192]\n",
      " ...\n",
      " [ 0.09574712 -0.37425917  0.22820399 ...  1.78798417 -0.31229823\n",
      "  -0.03081021]\n",
      " [ 0.12252832  0.23133784 -0.02108229 ...  2.44444617  0.28909643\n",
      "   0.74548742]\n",
      " [-0.06706137 -0.17354469 -0.16733226 ...  3.87123152 -0.12989382\n",
      "   1.01738235]]\n",
      "fc_bias [[-1.319305  ]\n",
      " [ 0.8345076 ]\n",
      " [-1.90449779]\n",
      " [ 0.33733743]\n",
      " [-0.31474554]\n",
      " [-0.50912293]\n",
      " [-0.19075376]\n",
      " [ 1.53555455]\n",
      " [ 0.16639665]\n",
      " [ 0.82103221]]\n"
     ]
    }
   ],
   "source": [
    "print(\"layer weights\", layer_weights)\n",
    "print(\"layer bias\", layer_bias)\n",
    "print(\"layer output\", layer_output)\n",
    "print(\"fc weights\", fc_weights)\n",
    "print(\"fc_bias\", fc_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f93376-fa78-4650-900f-c222b2a50e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training loop\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        Y_batch = Y_train[i:i+batch_size]\n",
    "\n",
    "        for x, y in zip(X_batch, Y_batch):\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                x, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "\n",
    "            delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                x, layer_output, layer_pool, layer_indices, final_output, y, layer_weights, layer_bias, fc_weights, fc_bias\n",
    "           \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> old-repo/main
