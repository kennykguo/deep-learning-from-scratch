2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Current SDK version is 0.17.6
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Configure stats pid to 356383
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Loading settings from /home/kennykguo/.config/wandb/settings
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Loading settings from /home/kennykguo/deep_learning_from_scratch/reinforcement_learning/wandb/settings
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_init.py:_log_setup():521] Logging user logs to /home/kennykguo/deep_learning_from_scratch/reinforcement_learning/wandb/run-20240815_233759-bdi4u3rf/logs/debug.log
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_init.py:_log_setup():522] Logging internal logs to /home/kennykguo/deep_learning_from_scratch/reinforcement_learning/wandb/run-20240815_233759-bdi4u3rf/logs/debug-internal.log
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_init.py:init():559] calling init triggers
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_init.py:init():566] wandb.init called with sweep_config: {}
config: {}
2024-08-15 23:37:59,708 INFO    MainThread:356383 [wandb_init.py:init():584] re-initializing run, found existing run on stack: z1q9fm7z
2024-08-15 23:37:59,710 INFO    MainThread:356383 [wandb_run.py:_finish():2110] finishing run kennykguo-developer/deep_learning_from_scratch-reinforcement_learning/z1q9fm7z
2024-08-15 23:37:59,711 INFO    MainThread:356383 [jupyter.py:save_history():444] not saving jupyter history
2024-08-15 23:37:59,711 INFO    MainThread:356383 [jupyter.py:save_ipynb():372] not saving jupyter notebook
2024-08-15 23:37:59,711 INFO    MainThread:356383 [wandb_init.py:_jupyter_teardown():449] cleaning up jupyter logic
2024-08-15 23:37:59,711 INFO    MainThread:356383 [wandb_run.py:_atexit_cleanup():2377] got exitcode: 0
2024-08-15 23:37:59,711 INFO    MainThread:356383 [wandb_run.py:_restore():2355] restore
2024-08-15 23:37:59,711 INFO    MainThread:356383 [wandb_run.py:_restore():2361] restore done
2024-08-15 23:38:05,975 INFO    MainThread:356383 [wandb_run.py:_footer_history_summary_info():4035] rendering history
2024-08-15 23:38:05,975 INFO    MainThread:356383 [wandb_run.py:_footer_history_summary_info():4067] rendering summary
2024-08-15 23:38:05,997 INFO    MainThread:356383 [wandb_run.py:_footer_sync_info():3994] logging synced files
2024-08-15 23:38:06,168 INFO    MainThread:356383 [wandb_init.py:init():609] starting backend
2024-08-15 23:38:06,169 INFO    MainThread:356383 [wandb_init.py:init():613] setting up manager
2024-08-15 23:38:06,170 INFO    MainThread:356383 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-08-15 23:38:06,171 INFO    MainThread:356383 [wandb_init.py:init():621] backend started and connected
2024-08-15 23:38:06,179 INFO    MainThread:356383 [wandb_run.py:_label_probe_notebook():1337] probe notebook
2024-08-15 23:38:06,179 INFO    MainThread:356383 [wandb_run.py:_label_probe_notebook():1347] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2024-08-15 23:38:06,179 INFO    MainThread:356383 [wandb_init.py:init():716] updated telemetry
2024-08-15 23:38:06,303 INFO    MainThread:356383 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2024-08-15 23:38:07,211 INFO    MainThread:356383 [wandb_run.py:_on_init():2438] communicating current version
2024-08-15 23:38:07,362 INFO    MainThread:356383 [wandb_run.py:_on_init():2447] got version response upgrade_message: "wandb version 0.17.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-08-15 23:38:07,362 INFO    MainThread:356383 [wandb_init.py:init():800] starting run threads in backend
2024-08-15 23:38:17,746 INFO    MainThread:356383 [wandb_run.py:_console_start():2416] atexit reg
2024-08-15 23:38:17,747 INFO    MainThread:356383 [wandb_run.py:_redirect():2258] redirect: wrap_raw
2024-08-15 23:38:17,747 INFO    MainThread:356383 [wandb_run.py:_redirect():2323] Wrapping output streams.
2024-08-15 23:38:17,747 INFO    MainThread:356383 [wandb_run.py:_redirect():2348] Redirects installed.
2024-08-15 23:38:17,749 INFO    MainThread:356383 [wandb_init.py:init():843] run started, returning control to user process
2024-08-15 23:38:17,751 INFO    MainThread:356383 [wandb_run.py:_config_callback():1385] config_cb None None {'trl_ppo_trainer_config': {'exp_name': 'ipykernel_launcher', 'seed': 0, 'log_with': 'wandb', 'task_name': None, 'model_name': 'lvwerra/gpt2-imdb', 'query_dataset': 'imdb', 'reward_model': 'sentiment-analysis:lvwerra/distilbert-imdb', 'remove_unused_columns': True, 'tracker_project_name': 'trl', 'steps': 20000, 'learning_rate': 1.41e-05, 'adap_kl_ctrl': True, 'init_kl_coef': 0.2, 'kl_penalty': 'kl', 'target': 6, 'horizon': 10000, 'gamma': 1, 'lam': 0.95, 'cliprange': 0.2, 'cliprange_value': 0.2, 'vf_coef': 0.1, 'batch_size': 128, 'forward_batch_size': None, 'mini_batch_size': 128, 'gradient_accumulation_steps': 1, 'world_size': 1, 'ppo_epochs': 4, 'max_grad_norm': None, 'optimize_cuda_cache': None, 'optimize_device_cache': False, 'early_stopping': False, 'target_kl': 1, 'compare_steps': 1, 'ratio_threshold': 10.0, 'use_score_scaling': False, 'use_score_norm': False, 'score_clip': None, 'whiten_rewards': False, 'gradient_checkpointing': False, 'is_encoder_decoder': False, 'is_peft_model': False, 'backward_batch_size': 128, 'global_backward_batch_size': 128, 'global_batch_size': 128, 'total_ppo_epochs': 157}}
