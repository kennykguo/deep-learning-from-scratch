{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef195e91-cf22-43c4-aec2-67216b6353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "data = pd.read_csv('../../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d8f8ca-66fc-4a13-8442-04e4a21ba2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d100e1c-fe7d-4718-8f90-081afa05ccfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "def plot_mnist_image(image_array):\n",
    "    image = image_array.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "plot_mnist_image(data[2, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ef5ed9-2c6a-4060-aaf1-84f5c75767ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "m, n = data.shape\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e6b5f1-e3a7-43a7-96b9-4cc371322534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 4, ..., 8, 9, 4],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data) # Shuffles all the individual rows\n",
    "data_dev = data[0:1000].T #Take the first 1000 rows, and transpose the matrix to get 1000 examples as column vectors\n",
    "data_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfc2746-5ec9-48b7-8f56-18f31dee1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev = data_dev[0] #Takes the first row, which contains all of the answers to the numbers (the Y is what we want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca04569-7231-41b8-a1a5-880d4cb8abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = data_dev[1:]\n",
    "# X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02bce0cb-6db8-4824-b6fa-7afdba377565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_dev = X_dev.reshape(28,28,1000)\n",
    "print(X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b59dca3-a0e1-4c4c-8897-c31be0d041d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# print(X_dev[:,:,1])\n",
    "plot_mnist_image(X_dev[:,:,6])\n",
    "print(Y_dev[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f90aef05-a41a-4c59-ad00-63c93e1fffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99fcae13-b528-49de-a18f-b6f9ed4cfb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= data_train[1:n] #Takes all of the data corresponding to all of the entries\n",
    "X_train = X_train.reshape(28,28,41000)\n",
    "# X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b515a33-35df-49d8-80fc-b3fb17971ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(input_data):\n",
    "    # 24, 24, 2\n",
    "    input_height, input_width, input_depth = input_data.shape\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = input_height // 2 # 12\n",
    "    output_width = input_width // 2 # 12\n",
    "    output_depth = input_depth # 2 - depth stays the same\n",
    "\n",
    "    # Initialize the output array and array to store indices\n",
    "    output_data = np.zeros((output_height, output_width, output_depth))\n",
    "    indices = np.zeros((output_height, output_width, output_depth, 2), dtype=int)\n",
    "\n",
    "    # Apply max pooling\n",
    "    for h in range(output_height):\n",
    "        for w in range(output_width):\n",
    "            for d in range(output_depth):\n",
    "                # Extract the 2x2 region of interest from the input data\n",
    "                region = input_data[h*2:(h+1)*2, w*2:(w+1)*2, d]\n",
    "                # Compute the maximum value in the region\n",
    "                max_val = np.max(region)\n",
    "                output_data[h, w, d] = max_val\n",
    "                # Find the indices of the maximum value in the region\n",
    "                max_indices = np.unravel_index(np.argmax(region), region.shape)\n",
    "                # Store the indices relative to the region and convert to global indices\n",
    "                indices[h, w, d] = [h*2 + max_indices[0], w*2 + max_indices[1]]\n",
    "\n",
    "    return output_data, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d7b5b43-0f57-4013-ab85-80ec5b90216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_ReLU(Z):\n",
    "  return Z > 0\n",
    "\n",
    "def der_ReLU2(Z, alpha=0.01):\n",
    "    return np.where(Z > 0, Z, alpha * Z)\n",
    "\n",
    "def ReLU(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU2(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def sigmoid(z):\n",
    "    # Compute the sigmoid function element-wise\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def softmax(Z):\n",
    "    # Apply softmax column-wise\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0))  # Subtracting the maximum value in each column to avoid overflow\n",
    "    return exp_Z / np.sum(exp_Z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "460fd0ab-c756-4c3a-a2e9-77ad87330d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def params():\n",
    "    layer_weights = np.random.randn(5, 5, 2) * np.sqrt(2. / 5)\n",
    "    layer_bias = np.random.randn(24, 24, 2) * np.sqrt(2. / 5)\n",
    "    layer_output = np.zeros((24,24,2)) #(24,24,2)\n",
    "    fc_weights = np.random.randn(10, 288) * np.sqrt(2. / 288)\n",
    "    fc_bias = np.random.randn(10,1) #(10, 1)\n",
    "    # fc_bias *= 0\n",
    "    fc_bias = fc_bias.reshape(10, 1)\n",
    "    return layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "\n",
    "def forward_propagation(layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias):\n",
    "    # layer_input (28, 28)\n",
    "    # layer_weights (5, 5, 2)\n",
    "    # layer_bias (24, 24, 2)\n",
    "    # layer_output (24, 24, 2)\n",
    "    # layer_bias (10, 288)\n",
    "    # layer_bias (10, 1)\n",
    "    \n",
    "    # Convolution\n",
    "    for i in range(2): # 2 filters in total\n",
    "        layer_output[:,:,i] = signal.correlate2d(layer_input, layer_weights[:,:,i], mode='valid')\n",
    "    layer_output = layer_output + layer_bias   # (24, 24, 2)\n",
    "    \n",
    "    # Activation layer\n",
    "    layer_output = ReLU(layer_output)  # (24, 24, 2)\n",
    "    \n",
    "    # Pool layer\n",
    "    layer_pool, layer_indices = max_pooling(layer_output)  # (12, 12, 2)\n",
    "\n",
    "    \n",
    "    # Flattening (changed to 288,1)\n",
    "    layer_pool = layer_pool.reshape(288,1) # (288,1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    final_output = fc_weights.dot(layer_pool)  # (10, 288) (288, 1) = (10, 1)\n",
    "    final_output.reshape(10,1) \n",
    "    final_output = final_output + fc_bias # (10, 1) + (10, 1) = (10, 1)\n",
    "    final_output = softmax(final_output) # (10, 1) -> (10, 1)\n",
    "    \n",
    "    return layer_output, layer_pool, layer_indices, final_output\n",
    "\n",
    "\n",
    "def create(Y):\n",
    "  column_Y = np.zeros((10, 1))\n",
    "  column_Y[Y] = 1\n",
    "  column_Y = column_Y.T\n",
    "  return column_Y.reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a21241-e082-487c-a194-adb44fa414b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropogation through layers\n",
    "\n",
    "def back_prop(layer_input, layer_output, layer_pool, layer_indices, final_output, label, layer_weights, layer_bias, fc_weights, fc_bias):\n",
    "    # Initalize parameters\n",
    "    delta_conv_weights = np.zeros((5,5,2))  # (5,5,2)\n",
    "    delta_conv_bias = np.zeros((24,24,2)) # (24, 24, 2)\n",
    "    delta_fc_weights = np.zeros((10, 288)) #  (10, 288)\n",
    "    delta_fc_bias = np.zeros((10, 1)) # (10, 1)\n",
    "    delta_fc_bias.reshape(10, 1)\n",
    "    \n",
    "    # Backpropogate cost\n",
    "    x = create(label) \n",
    "    dZ = (final_output - x) # (10,1) - (10,1) = (10,1) \n",
    "    # dZ = dZ.reshape((10,1))\n",
    "    \n",
    "    #Backpropogate weights and biases\n",
    "    layer_pool = layer_pool.reshape(1,288)\n",
    "    delta_fc_weights = dZ.dot(layer_pool) # (10 x 1 ) (1 x 288) = (10 x 288)\n",
    "    delta_fc_bias = dZ\n",
    "    \n",
    "    # Backpropogate error\n",
    "    dZ_pool_output = np.dot(fc_weights.T, dZ) * der_ReLU(layer_pool.reshape(288, 1)) #(288 x 10) (10 x 1) = (288 x 1)\n",
    "    \n",
    "    # Unflattening\n",
    "    dZ_pool_output = dZ_pool_output.reshape(12,12,2)\n",
    "    \n",
    "    # Unpooling\n",
    "    dZ_pool_input = np.zeros((24,24,2))\n",
    "    for i in range(12): # height\n",
    "        for j in range(12): # width\n",
    "            for k in range(2): # depth\n",
    "                # Get the global indices from layer_indices\n",
    "                x_index, y_index = layer_indices[i, j, k]\n",
    "                # Assign the gradient from dZ_pool_output to the corresponding position in dZ_pool_input\n",
    "                dZ_pool_input[x_index, y_index, k] = dZ_pool_output[i, j, k]\n",
    "    \n",
    "    # Backpropogating convolutional layer - dZ_pool_input is the output of the convolutional layer\n",
    "    for i in range(2): # For each filter in the kernel - # of filters = 2\n",
    "        delta_conv_weights[:,:,i] = signal.correlate(layer_input, dZ_pool_input[:,:,i], mode = \"valid\") #\n",
    "    delta_conv_bias = dZ_pool_input\n",
    "\n",
    "    return delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias\n",
    "\n",
    "def update_params(layer_weights, layer_bias, fc_weights, fc_bias, delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias, learning_rate):\n",
    "    layer_weights \n",
    "    layer_weights = layer_weights - learning_rate * delta_conv_weights\n",
    "    layer_bias = layer_bias - learning_rate * delta_conv_bias\n",
    "    fc_weights = fc_weights -learning_rate * delta_fc_weights\n",
    "    fc_bias = fc_bias - learning_rate * delta_fc_bias\n",
    "    return layer_weights, layer_bias, fc_weights, fc_bias\n",
    "\n",
    "def get_prediction(A2):\n",
    "  return np.argmax(A2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82da6438-d7ca-4ebb-bb38-7dd0e611f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X_train, X_dev, Y_train, Y_dev, epochs, learning_rate, batch_size):\n",
    "    # Initialize parameters\n",
    "    layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "    num_examples = X_train.shape[2]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch:\", i+1)\n",
    "        \n",
    "        # Generate a random permutation of indices\n",
    "        permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "\n",
    "        # Shuffle both X_train and Y_train using the same permutation of indices\n",
    "        X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "        Y_train_shuffled = Y_train[permuted_indices]\n",
    "        for batch_start in range(0, int(X_train.shape[2]/100), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, num_examples)\n",
    "            batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "            for j in range(batch_start, batch_end):\n",
    "                # print(batch_start, batch_end, j)\n",
    "                # Get a single training example\n",
    "                layer_input = X_train_shuffled[:, :, j]\n",
    "                label = Y_train_shuffled[j]\n",
    "\n",
    "                # Forward propagation\n",
    "                layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                    layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "                )\n",
    "\n",
    "                # Back propagation\n",
    "                delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "                    layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "                    layer_weights, layer_bias, fc_weights, fc_bias\n",
    "                )\n",
    "\n",
    "                # Accumulate gradients\n",
    "                batch_gradients[0] += delta_conv_weights\n",
    "                batch_gradients[1] += delta_conv_bias\n",
    "                batch_gradients[2] += delta_fc_weights\n",
    "                batch_gradients[3] += delta_fc_bias\n",
    "\n",
    "            # Average gradients after processing the batch\n",
    "            batch_gradients = [grad / batch_size for grad in batch_gradients]\n",
    "\n",
    "            # Update parameters after processing the batch\n",
    "            layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "                layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "                *batch_gradients,  # Use averaged gradients\n",
    "                learning_rate\n",
    "            )\n",
    "\n",
    "        # Get training accuracy\n",
    "        counter = 0\n",
    "        for j in range(int(X_train_shuffled.shape[2]/100)):\n",
    "            test_input = X_train_shuffled[:, :, j]\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "            prediction = get_prediction(final_output)\n",
    "            predicted_label = prediction[0]\n",
    "            if Y_train_shuffled[j] == predicted_label:\n",
    "                counter += 1\n",
    "        print(\"Training Accuracy:\", counter / int(X_train_shuffled.shape[2]/100))\n",
    "        counter = 0\n",
    "        for j in range(500):\n",
    "            test_input = X_dev[:, :, j]\n",
    "            layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "                test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "            )\n",
    "            prediction = get_prediction(final_output)\n",
    "            predicted_label = prediction[0]\n",
    "            if Y_dev[j] == predicted_label:\n",
    "                counter += 1\n",
    "        print(\"Validation Accuracy:\", counter / 500)\n",
    "        \n",
    "    return layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45106863-de98-4639-8fc5-92edb75e446c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Accuracy: 0.13902439024390245\n",
      "Validation Accuracy: 0.118\n",
      "Epoch: 2\n",
      "Training Accuracy: 0.2\n",
      "Validation Accuracy: 0.168\n",
      "Epoch: 3\n",
      "Training Accuracy: 0.23902439024390243\n",
      "Validation Accuracy: 0.23\n",
      "Epoch: 4\n",
      "Training Accuracy: 0.28780487804878047\n",
      "Validation Accuracy: 0.272\n",
      "Epoch: 5\n",
      "Training Accuracy: 0.23170731707317074\n",
      "Validation Accuracy: 0.286\n",
      "Epoch: 6\n",
      "Training Accuracy: 0.3195121951219512\n",
      "Validation Accuracy: 0.342\n",
      "Epoch: 7\n",
      "Training Accuracy: 0.37317073170731707\n",
      "Validation Accuracy: 0.39\n",
      "Epoch: 8\n",
      "Training Accuracy: 0.3878048780487805\n",
      "Validation Accuracy: 0.392\n",
      "Epoch: 9\n",
      "Training Accuracy: 0.45121951219512196\n",
      "Validation Accuracy: 0.416\n",
      "Epoch: 10\n",
      "Training Accuracy: 0.4292682926829268\n",
      "Validation Accuracy: 0.416\n",
      "Epoch: 11\n",
      "Training Accuracy: 0.3829268292682927\n",
      "Validation Accuracy: 0.432\n",
      "Epoch: 12\n",
      "Training Accuracy: 0.4878048780487805\n",
      "Validation Accuracy: 0.434\n",
      "Epoch: 13\n",
      "Training Accuracy: 0.47073170731707314\n",
      "Validation Accuracy: 0.44\n",
      "Epoch: 14\n",
      "Training Accuracy: 0.4024390243902439\n",
      "Validation Accuracy: 0.43\n",
      "Epoch: 15\n",
      "Training Accuracy: 0.4658536585365854\n",
      "Validation Accuracy: 0.46\n",
      "Epoch: 16\n",
      "Training Accuracy: 0.44878048780487806\n",
      "Validation Accuracy: 0.432\n",
      "Epoch: 17\n",
      "Training Accuracy: 0.45365853658536587\n",
      "Validation Accuracy: 0.466\n",
      "Epoch: 18\n",
      "Training Accuracy: 0.43658536585365854\n",
      "Validation Accuracy: 0.452\n",
      "Epoch: 19\n",
      "Training Accuracy: 0.47560975609756095\n",
      "Validation Accuracy: 0.45\n",
      "Epoch: 20\n",
      "Training Accuracy: 0.4585365853658537\n",
      "Validation Accuracy: 0.456\n",
      "Epoch: 21\n",
      "Training Accuracy: 0.4585365853658537\n",
      "Validation Accuracy: 0.456\n",
      "Epoch: 22\n",
      "Training Accuracy: 0.4658536585365854\n",
      "Validation Accuracy: 0.456\n",
      "Epoch: 23\n",
      "Training Accuracy: 0.43902439024390244\n",
      "Validation Accuracy: 0.45\n",
      "Epoch: 24\n",
      "Training Accuracy: 0.45365853658536587\n",
      "Validation Accuracy: 0.496\n",
      "Epoch: 25\n",
      "Training Accuracy: 0.47073170731707314\n",
      "Validation Accuracy: 0.466\n",
      "Epoch: 26\n",
      "Training Accuracy: 0.5\n",
      "Validation Accuracy: 0.492\n",
      "Epoch: 27\n",
      "Training Accuracy: 0.4585365853658537\n",
      "Validation Accuracy: 0.468\n",
      "Epoch: 28\n",
      "Training Accuracy: 0.5195121951219512\n",
      "Validation Accuracy: 0.466\n",
      "Epoch: 29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layer_weights, layer_bias, layer_output, fc_weights, fc_bias \u001b[38;5;241m=\u001b[39m \u001b[43mstochastic_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(X_train, X_dev, Y_train, Y_dev, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m layer_output, layer_pool, layer_indices, final_output \u001b[38;5;241m=\u001b[39m forward_propagation(\n\u001b[1;32m     26\u001b[0m     layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Back propagation\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias \u001b[38;5;241m=\u001b[39m \u001b[43mback_prop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_bias\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Accumulate gradients\u001b[39;00m\n\u001b[1;32m     36\u001b[0m batch_gradients[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m delta_conv_weights\n",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m, in \u001b[0;36mback_prop\u001b[0;34m(layer_input, layer_output, layer_pool, layer_indices, final_output, label, layer_weights, layer_bias, fc_weights, fc_bias)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Backpropogating convolutional layer - dZ_pool_input is the output of the convolutional layer\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m): \u001b[38;5;66;03m# For each filter in the kernel - # of filters = 2\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     delta_conv_weights[:,:,i] \u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdZ_pool_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     40\u001b[0m delta_conv_bias \u001b[38;5;241m=\u001b[39m dZ_pool_input\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/scipy/signal/_signaltools.py:241\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# this either calls fftconvolve or this function with method=='direct'\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_reverse_and_conj\u001b[49m\u001b[43m(\u001b[49m\u001b[43min2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# fastpath to faster numpy.correlate for 1d inputs when possible\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(in1, in2, mode):\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/scipy/signal/_signaltools.py:1413\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     method \u001b[38;5;241m=\u001b[39m choose_conv_method(volume, kernel, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1413\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfftconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m     result_type \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(volume, kernel)\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_type\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/scipy/signal/_signaltools.py:669\u001b[0m, in \u001b[0;36mfftconvolve\u001b[0;34m(in1, in2, mode, axes)\u001b[0m\n\u001b[1;32m    664\u001b[0m s2 \u001b[38;5;241m=\u001b[39m in2\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    666\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m((s1[i], s2[i])) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axes \u001b[38;5;28;01melse\u001b[39;00m s1[i] \u001b[38;5;241m+\u001b[39m s2[i] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    667\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(in1\u001b[38;5;241m.\u001b[39mndim)]\n\u001b[0;32m--> 669\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43m_freq_domain_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_fast_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_conv_mode(ret, s1, s2, mode, axes)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/scipy/signal/_signaltools.py:506\u001b[0m, in \u001b[0;36m_freq_domain_conv\u001b[0;34m(in1, in2, axes, shape, calc_fast_len)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     fft, ifft \u001b[38;5;241m=\u001b[39m sp_fft\u001b[38;5;241m.\u001b[39mfftn, sp_fft\u001b[38;5;241m.\u001b[39mifftn\n\u001b[0;32m--> 506\u001b[0m sp1 \u001b[38;5;241m=\u001b[39m \u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m sp2 \u001b[38;5;241m=\u001b[39m fft(in2, fshape, axes\u001b[38;5;241m=\u001b[39maxes)\n\u001b[1;32m    509\u001b[0m ret \u001b[38;5;241m=\u001b[39m ifft(sp1 \u001b[38;5;241m*\u001b[39m sp2, fshape, axes\u001b[38;5;241m=\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/scipy/fft/_backend.py:25\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/scipy/fft/_pocketfft/basic.py:223\u001b[0m, in \u001b[0;36mr2cn\u001b[0;34m(forward, x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least 1 axis must be transformed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilized\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = stochastic_gradient_descent(\n",
    "    X_train, X_dev, Y_train, Y_dev, 400, 0.2, 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "347324b7-1503-442c-99ae-e8454cce1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "counter = 0\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "layer_weights, layer_bias, layer_output, fc_weights, fc_bias = params()\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e8af405-d2e9-4aa2-8b1d-f639f8ba86e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 41000)\n",
      "(41000,)\n",
      "(28, 28, 41000)\n",
      "(41000,)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random permutation of indices\n",
    "permuted_indices = np.random.permutation(X_train.shape[2])\n",
    "# Shuffle both X_train and Y_train using the same permutation of indices\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "X_train_shuffled = X_train[:, :, permuted_indices]\n",
    "Y_train_shuffled = Y_train[permuted_indices]\n",
    "print(X_train_shuffled.shape)\n",
    "print(Y_train_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00505807-682e-4d76-8a12-b0025b6de059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a training batch\n",
    "for batch_start in range(0, len(X_train_shuffled), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(X_train_shuffled))\n",
    "    batch_gradients = [0, 0, 0, 0]  # Accumulate gradients over the batch\n",
    "    for j in range(batch_start, batch_end):\n",
    "        # Get a single training example\n",
    "        layer_input = X_train_shuffled[:, :, j]\n",
    "        label = Y_train_shuffled[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b04fb3-7b88-4034-8ba4-2bec8e1e3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "    layer_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baedc9e8-e0f2-4819-a421-8de7305123dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propagation\n",
    "delta_conv_weights, delta_conv_bias, delta_fc_weights, delta_fc_bias = back_prop(\n",
    "    layer_input, layer_output, layer_pool, layer_indices, final_output, label,\n",
    "    layer_weights, layer_bias, fc_weights, fc_bias\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93915544-9066-4247-b7c5-c681f6da4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gradients[0] += delta_conv_weights\n",
    "batch_gradients[1] += delta_conv_bias\n",
    "batch_gradients[2] += delta_fc_weights\n",
    "batch_gradients[3] += delta_fc_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ef29900-65f8-4ab9-bc87-1bcbaa5a447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average gradients after processing the batch\n",
    "batch_gradients = [grad / batch_size for grad in batch_gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1606c7e8-2917-4914-bd23-514505b21dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters after processing the batch\n",
    "layer_weights, layer_bias, fc_weights, fc_bias = update_params(\n",
    "    layer_weights, layer_bias, fc_weights, fc_bias,\n",
    "    *batch_gradients,  # Use averaged gradients\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180bc097-d67e-4be3-97ff-5179fd6954b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09466666666666666\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy\n",
    "counter = 0\n",
    "for j in range(750):\n",
    "    test_input = X_dev[:, :, j]\n",
    "    layer_output, layer_pool, layer_indices, final_output = forward_propagation(\n",
    "        test_input, layer_weights, layer_bias, layer_output, fc_weights, fc_bias\n",
    "    )\n",
    "    prediction = get_prediction(final_output)\n",
    "    predicted_label = prediction[0]\n",
    "    if Y_dev[j] == predicted_label:\n",
    "        counter += 1\n",
    "print(\"Accuracy:\", counter / 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6dd5001-17a6-4445-9d77-c455a4774bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAI1UlEQVR4nO3dP2uUSx/H4b3DEtiIGEEUUQQLtbOQFFaCiKDgSwi+ALHQ1t53YJs62IlgY5NOLBS0EAQDgmkEkfiHtTBx93RfHh7OwTsz2d3s7nXV+TkT2eTjFM40w+Fw2AGATqezMOkNAHBwiAIAIQoAhCgAEKIAQIgCACEKAIQoABDdtl/YNM0o9wHAiLX5v8pOCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQra/OBmZTzbX4ba5iPohqnwKY1u+7DScFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBm/j2FXq9XNX/58uXi2Y2Njaq1J2V5eblq/s+fP8WzP3/+rFqbvZvltwH+yzx+z205KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBANMOWd8g2TTPqvYxk7QsXLlSt/f79+6p5aGNxcbF4djAYVK1d8/O1s7NTtfakHD16tGq+3+8Xz/7+/btq7Rptft07KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA0W37hTV3rrd8suE/9Xq94tmlpaWqtWEcJnnH/jza3t6umj9y5EjxbO37F7u7u1Xzf+OkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDRDFvea11zdXbNbKdTf/U2wH66evVq8ezGxsY+7mRv2vwudVIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgOiOYxFXXwOzZGGh/N/T58+fr1r7w4cPVfN/46QAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMRY3lOo1e2Wb3Npaalq7R8/flTNw6itrKxUzb969WqfdjI/vnz5Ujx77969qrXv3LlTNf83TgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEFNxdfbu7m7xrKuvmXWuvh6/muura67dHgcnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgmuFwOGz1hU0z6r0ATIWWvzb/1ZkzZ6rW3traKp5ts28nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI7jgWqb12u+aaWoD/9+TJk6r5R48eFc/WXH09Dk4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEA0w5aPFdS+iTAp3nKYLysrK8Wzr1+/Lp71OZku379/r5pfXl4unp3kZ6XN2k4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABDdSW9g1FxpPF1Onz5dNb+9vV0867MyXba2topnV1dXq9ae5c+KkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoARDNseQds0zSj3gsz4uTJk8Wzx48fr1r77du3VfOMz/r6etX8x48fi2cfPHhQtfa0avPr3kkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIipeE+hZu2W3x7/o+Y9hE6n0zlx4kTx7Js3b6rWZrwePnxYPHvp0qWqtW/evFk1P4+8pwDAnogCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCADEVV2ezdzXXVx8+fLhq7c3Nzap5pke/3y+erf2cDQaDqvl55OpsAPZEFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgupPeAP/u2LFjVfNnz54tnn358mXV2kyXr1+/Fs9ev369eNZ7CGVG/baNkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhKuzR+jUqVPFs71er2pt11/Pj2fPnlXN3717t3j2xYsXVWtz8DgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4OvsvLl68WDz77du34tnNzc3iWabP8+fPi2cfP35ctfb6+nrVPOM1HA5H+uc7KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMfPvKSwuLlbNLyyUd/PTp09VazM9nj59WjX/7t274tm1tbWqtSelaZqq+VG/KzCvnBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIGb+6uxer1c1//nz533aCQfd7du3i2d3dnaq1r5//37V/DRy9fXB5KQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAEQzbHmpedM0o97LSBw6dKhq/tevX8Wz7osfv5p3CW7dulU8e+3ateLZaVbze8HPx/i1+Tt3UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA6E56A6PW7/cnvQX2YHV1tWr+xo0bxbPzev11Dddfzx4nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgmmHLC9Gbphn1XkZiYaGue4PBYJ92Mj+uXLlSPLu2tla19rlz56rm59Gkfra9xTB+bf7OnRQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFpfnQ3A7HNSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIP4BvuJCy8nSAC8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"layer weights\", layer_weights)\n",
    "# print(\"layer bias\", layer_bias)\n",
    "# print(\"layer output\", layer_output)\n",
    "# print(\"fc weights\", fc_weights)\n",
    "# print(\"fc_bias\", fc_bias)\n",
    "plt.imshow(layer_output[:,:,1], cmap='gray')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
