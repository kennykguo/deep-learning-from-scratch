{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dPuz7WksL2FJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8OMEIfPPpIl",
    "outputId": "c228ebd4-7e42-40c1-c308-406d1ccd2807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "e5eIyEr-H9XW",
    "outputId": "1107d27d-4519-4218-a143-ee30008a1304"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "4REb08ykI8pH",
    "outputId": "417a6e8f-fea0-4469-c0a0-f662571b0d6a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "def plot_mnist_image(image_array):\n",
    "    image = image_array.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "plot_mnist_image(data[3, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG-IID2ZJCar",
    "outputId": "c24847d0-bded-4654-fbe0-185668455aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "m, n = data.shape\n",
    "print(m,n)\n",
    "# m is the number of training examples, n is the number of features + 1 (Y column)\n",
    "# m is # of rows, n is the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvDjeD2UPxZm",
    "outputId": "f3934e4b-64fe-45f5-c423-3c4e35fd496a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 8, 7, ..., 0, 7, 8],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data) # Shuffles all the individual rows\n",
    "data_dev = data[0:1000].T #Take the first 1000 rows, and transpose the matrix to get 1000 examples as column vectors\n",
    "data_dev\n",
    "\n",
    "# 1000 x 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxP2oNOjmy4k",
    "outputId": "18515c55-9a29-475d-da22-b2b7d01de611",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 7, 8, 5, 0, 7, 8, 7, 2, 3, 5, 4, 9, 0, 5, 0, 4, 1, 2, 5, 6,\n",
       "       6, 8, 2, 2, 8, 9, 9, 0, 2, 5, 0, 1, 3, 3, 3, 4, 4, 6, 7, 4, 4, 2,\n",
       "       7, 0, 8, 0, 0, 5, 1, 0, 8, 9, 1, 5, 1, 9, 9, 4, 2, 0, 8, 7, 3, 0,\n",
       "       0, 3, 6, 8, 3, 7, 7, 2, 9, 3, 1, 6, 5, 8, 6, 8, 9, 0, 0, 4, 2, 3,\n",
       "       0, 2, 3, 6, 6, 9, 4, 2, 2, 9, 7, 0, 8, 8, 6, 4, 3, 0, 9, 4, 9, 5,\n",
       "       2, 0, 5, 4, 2, 3, 8, 4, 9, 8, 7, 7, 2, 0, 7, 2, 1, 8, 0, 8, 8, 9,\n",
       "       5, 4, 2, 8, 9, 8, 3, 8, 7, 5, 3, 7, 3, 6, 9, 3, 2, 5, 8, 9, 1, 5,\n",
       "       4, 0, 8, 1, 4, 2, 3, 3, 7, 4, 2, 0, 4, 0, 2, 7, 1, 5, 0, 7, 5, 7,\n",
       "       1, 3, 7, 3, 7, 5, 9, 3, 7, 2, 9, 7, 9, 9, 9, 6, 0, 4, 6, 0, 7, 9,\n",
       "       9, 7, 2, 1, 8, 2, 5, 5, 7, 3, 9, 2, 6, 1, 2, 5, 1, 6, 2, 7, 7, 5,\n",
       "       8, 1, 3, 4, 6, 7, 1, 1, 0, 4, 5, 5, 3, 4, 5, 0, 0, 3, 0, 4, 7, 0,\n",
       "       4, 1, 6, 9, 2, 1, 6, 1, 8, 1, 0, 6, 7, 2, 1, 6, 0, 2, 8, 4, 5, 1,\n",
       "       4, 1, 4, 5, 1, 0, 8, 1, 4, 0, 6, 4, 1, 4, 4, 1, 0, 0, 0, 0, 1, 8,\n",
       "       2, 8, 2, 5, 7, 7, 0, 7, 7, 9, 9, 6, 8, 0, 2, 1, 8, 9, 3, 8, 0, 8,\n",
       "       5, 1, 8, 1, 3, 1, 1, 5, 2, 1, 6, 2, 5, 0, 9, 2, 6, 9, 3, 5, 1, 8,\n",
       "       5, 7, 3, 2, 0, 7, 0, 7, 4, 1, 7, 3, 6, 1, 9, 7, 9, 7, 2, 2, 8, 9,\n",
       "       9, 5, 7, 1, 9, 8, 2, 0, 4, 4, 0, 4, 1, 6, 9, 4, 9, 2, 8, 1, 4, 7,\n",
       "       3, 7, 4, 3, 5, 4, 4, 1, 3, 2, 8, 7, 4, 3, 9, 1, 5, 0, 3, 1, 8, 8,\n",
       "       1, 2, 1, 3, 4, 6, 7, 3, 7, 0, 4, 7, 3, 9, 2, 4, 5, 4, 8, 2, 8, 9,\n",
       "       1, 2, 7, 9, 8, 4, 1, 0, 0, 0, 5, 9, 6, 6, 5, 4, 0, 9, 5, 1, 6, 8,\n",
       "       7, 1, 6, 8, 7, 6, 9, 4, 0, 1, 6, 3, 1, 4, 7, 9, 6, 6, 1, 0, 9, 5,\n",
       "       5, 2, 7, 1, 4, 9, 3, 8, 5, 9, 3, 2, 2, 1, 7, 6, 3, 7, 1, 8, 7, 7,\n",
       "       1, 7, 3, 8, 4, 0, 4, 5, 4, 7, 1, 6, 1, 4, 3, 6, 2, 9, 0, 9, 1, 1,\n",
       "       7, 8, 8, 5, 6, 1, 6, 9, 2, 3, 4, 4, 8, 4, 3, 0, 6, 1, 0, 3, 1, 1,\n",
       "       6, 7, 2, 0, 5, 8, 3, 8, 3, 1, 4, 9, 2, 0, 9, 1, 9, 9, 8, 9, 5, 8,\n",
       "       5, 9, 9, 1, 9, 8, 3, 6, 2, 4, 8, 5, 9, 1, 7, 6, 5, 0, 9, 5, 4, 8,\n",
       "       1, 6, 9, 4, 0, 1, 9, 7, 1, 3, 5, 7, 5, 1, 9, 9, 3, 9, 7, 3, 5, 9,\n",
       "       8, 6, 9, 8, 2, 9, 9, 7, 1, 6, 7, 4, 2, 3, 4, 0, 3, 6, 9, 2, 1, 9,\n",
       "       3, 1, 7, 7, 4, 1, 9, 8, 3, 1, 7, 3, 1, 3, 9, 1, 5, 8, 4, 4, 0, 3,\n",
       "       3, 5, 4, 6, 4, 1, 6, 9, 2, 0, 7, 2, 3, 2, 4, 5, 4, 8, 7, 1, 1, 2,\n",
       "       0, 5, 4, 6, 6, 3, 8, 3, 9, 0, 2, 5, 2, 9, 2, 6, 8, 0, 9, 5, 0, 6,\n",
       "       5, 4, 6, 0, 3, 0, 0, 1, 1, 2, 7, 3, 2, 0, 9, 8, 0, 3, 3, 1, 2, 0,\n",
       "       5, 5, 6, 6, 8, 5, 2, 8, 7, 8, 7, 6, 8, 6, 1, 0, 8, 1, 0, 3, 3, 3,\n",
       "       0, 3, 9, 0, 2, 4, 7, 8, 2, 2, 9, 8, 2, 1, 9, 6, 1, 0, 8, 6, 1, 4,\n",
       "       8, 5, 3, 2, 6, 2, 1, 2, 8, 9, 6, 0, 7, 7, 0, 1, 2, 4, 2, 3, 6, 9,\n",
       "       7, 3, 6, 2, 4, 2, 7, 0, 1, 9, 3, 7, 1, 4, 7, 0, 1, 3, 4, 7, 4, 6,\n",
       "       0, 0, 0, 5, 8, 4, 0, 6, 5, 5, 6, 6, 1, 8, 1, 3, 0, 0, 8, 8, 8, 4,\n",
       "       6, 9, 2, 0, 2, 3, 6, 2, 3, 6, 3, 1, 0, 1, 9, 3, 7, 8, 2, 3, 2, 6,\n",
       "       7, 9, 0, 3, 8, 6, 0, 5, 3, 4, 9, 6, 1, 9, 1, 6, 3, 8, 8, 5, 9, 1,\n",
       "       1, 2, 6, 7, 6, 4, 9, 2, 8, 2, 3, 5, 7, 4, 0, 4, 6, 9, 8, 8, 9, 7,\n",
       "       0, 3, 7, 7, 2, 1, 0, 9, 3, 8, 3, 5, 2, 0, 9, 9, 0, 7, 7, 6, 0, 6,\n",
       "       0, 8, 2, 9, 2, 1, 6, 3, 4, 1, 0, 2, 3, 3, 3, 7, 0, 5, 9, 8, 8, 1,\n",
       "       2, 3, 0, 2, 2, 9, 7, 8, 6, 9, 5, 0, 1, 1, 3, 2, 3, 0, 0, 9, 6, 1,\n",
       "       2, 5, 2, 8, 2, 8, 8, 2, 5, 6, 5, 4, 3, 7, 2, 6, 3, 1, 6, 5, 2, 1,\n",
       "       1, 5, 0, 1, 0, 4, 2, 5, 8, 4, 3, 4, 3, 8, 4, 9, 2, 3, 3, 7, 1, 3,\n",
       "       3, 8, 9, 1, 5, 0, 7, 0, 7, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev = data_dev[0] #Takes the first row, which contains all of the answers to the numbers (the Y is what we want)\n",
    "Y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWeKiAlsm1oF",
    "outputId": "943393de-eb67-4bd3-ce8d-b5dd3e45741e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1000)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.11372549 0.65882353\n",
      " 0.98039216 0.97254902 0.96862745 0.98431373 0.56078431 0.01960784\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.07843137 0.56470588 0.97254902 0.95686275 0.32156863 0.\n",
      " 0.         0.15294118 0.89019608 0.51372549 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.19607843 0.99607843\n",
      " 0.72156863 0.12156863 0.         0.         0.         0.\n",
      " 0.45490196 0.64705882 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.19607843 0.99607843 0.09411765 0.\n",
      " 0.         0.         0.         0.01568627 0.73333333 0.69019608\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.10196078 0.9372549  0.50980392 0.         0.         0.\n",
      " 0.         0.25490196 0.97647059 0.32941176 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5372549\n",
      " 0.8745098  0.03529412 0.         0.         0.07843137 0.63529412\n",
      " 0.59607843 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.17647059 0.97647059 0.52156863\n",
      " 0.         0.08235294 0.63137255 0.90196078 0.32156863 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.5254902  0.97254902 0.11372549 0.54117647\n",
      " 0.98039216 0.3254902  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.84705882 0.95686275 0.97254902 0.34901961 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50980392\n",
      " 1.         0.65490196 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.10588235 0.85490196 0.98039216 0.76078431\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.10980392\n",
      " 0.84705882 0.64313725 0.10196078 0.84705882 0.35294118 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01960784 0.69803922 0.77254902 0.01960784\n",
      " 0.         0.21960784 0.95294118 0.36078431 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23921569 0.96862745 0.25882353 0.         0.         0.\n",
      " 0.30588235 0.94509804 0.58431373 0.02745098 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.02745098 0.80392157 0.61568627\n",
      " 0.         0.         0.         0.         0.         0.27843137\n",
      " 0.83921569 0.50196078 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16470588 0.89803922 0.11372549 0.         0.\n",
      " 0.         0.         0.         0.         0.2627451  0.9372549\n",
      " 0.1372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.44705882\n",
      " 0.84705882 0.03137255 0.         0.         0.         0.\n",
      " 0.         0.         0.03137255 0.85098039 0.44313725 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.19607843 0.99607843 0.6627451\n",
      " 0.02745098 0.         0.         0.         0.         0.\n",
      " 0.40392157 0.99607843 0.4        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01176471 0.4        0.96078431 0.85882353 0.61176471\n",
      " 0.61176471 0.61568627 0.61176471 0.85490196 0.85098039 0.39607843\n",
      " 0.01176471 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20392157 0.54117647 0.6745098  0.78039216 0.78039216\n",
      " 0.6745098  0.43921569 0.09019608 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "X_dev = data_dev[1:] #Takes all of the data corresponding to all of the entries (the X values)\n",
    "X_dev = X_dev / 255.\n",
    "# We divide all elements, elementwise, by 255 so that all numbers are decimal values, between 0 and 1\n",
    "print(X_dev.shape)\n",
    "print(X_dev[:, 1])\n",
    "print(X_dev[:, 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFJGdfIkSkP6",
    "outputId": "d5f61668-03f2-4afd-9361-b018e7bbc062",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  13,  97, 138, 180, 253, 255, 253, 253, 117,  13,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  38, 151, 212, 252, 252, 252, 252, 228, 236, 252,\n",
       "       252, 137,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  34, 184, 240, 252, 253, 208, 183,  89,  69,  32,\n",
       "        44,  69, 162, 100,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  62, 215, 252, 252, 210,  98,  17,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 158, 243, 252, 221,  96,  12,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   7, 212, 253, 255, 249,  63,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  91, 252, 252, 228, 117,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 119, 234, 252, 221,  32,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 161, 252, 252,\n",
       "        85,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 127, 244,\n",
       "       252, 116,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       191, 253, 222,  25,   0,   0,   0,   0,   0,   0,  24, 170, 222,\n",
       "       138,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 118, 252, 252, 135,  47, 110, 161, 161, 161, 161, 253,\n",
       "       252, 252, 172,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  17, 227, 252, 252, 252, 253, 252, 252, 252,\n",
       "       252, 253, 252, 170,  13,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  50, 160, 160, 244, 253, 193,\n",
       "       160, 194, 252, 253, 172,  13,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n",
       "        23,   8, 116, 238, 252, 180,   8,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   3,  66, 253, 253, 180,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  97, 252, 252, 120,   8,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 222, 252, 202,  13,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  95, 253, 214,  33,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 220, 180,  18,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[1000:m].T\n",
    "data_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3k210Xo9ooen"
   },
   "outputs": [],
   "source": [
    "Y_train = data_train[0] #Takes the first row, which contains all of the answers to the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wCnPsdqxotp0"
   },
   "outputs": [],
   "source": [
    "X_train= data_train[1:n] #Takes all of the data corresponding to all of the entries\n",
    "X_train\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "n_TnFSWzUOdz"
   },
   "outputs": [],
   "source": [
    "#X_train\n",
    "#Y_train\n",
    "\n",
    "def params(batch_size):\n",
    "  W1 = np.random.rand(15, 784) - 0.5\n",
    "  b1 = np.random.rand(15, batch_size) - 0.5\n",
    "  W2 = np.random.rand(10, 15) - 0.5\n",
    "  b2 = np.random.rand(10, batch_size) - 0.5\n",
    "  return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    # Apply softmax column-wise\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0))  # Subtracting the maximum value in each column to avoid overflow\n",
    "    return exp_Z / np.sum(exp_Z, axis=0)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X, batch_size):\n",
    "    Z1 = W1.dot(X) + b1 # (10 x784) (784 x n) + (10 x n) -> (10 x n)\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2 # (10 x 10) (10 x n) + (10 x n) = (10 x n)\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def der_ReLU(Z):\n",
    "  return Z > 0\n",
    "\n",
    "def create(Y): # Passing in a 1 x 41000 matrix (41000 columns, 1 row)\n",
    "  mat_Y = np.zeros((Y.size, 10)) # 41000 x 10\n",
    "  mat_Y[np.arange(Y.size), Y] = 1 # array([    0,     1,     2, ..., 40997, 40998, 40999]), then indexing the Y values aswell at each column, changing that value to 1\n",
    "  mat_Y = mat_Y.T # 10 x 41000\n",
    "  return mat_Y\n",
    "\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W1, W2, X, Y, batch_size):\n",
    "  mat_Y = create(Y)\n",
    "  dZ2 = (1/batch_size) * (A2 - mat_Y) # 10 x 41000 - - - Back propogation eq. #1\n",
    "  dW2 = dZ2.dot(A1.T) # (10 x 41000) (41000 x 10) -> (10 x 10) - - - Back propogation eq. #4\n",
    "  db2 = np.sum(dZ2) # scalar  - - - Back propogation eq. #3\n",
    "  dZ1 = (1/batch_size) * (W2.T.dot(dZ2) * der_ReLU(Z1)) # (10 x 10) (10 x 41000) * elementwise (1 or 0) Back propogation eq. #2\n",
    "  dW1=  dZ1.dot(X.T) # (10 x 41000) (41000 x 784) -> (10 x 784) - - - Back propogation eq. #4\n",
    "  db1 = np.sum(dZ1) #scalar - - - Back propogation eq. #3\n",
    "  return dW1, db1, dW2, db2\n",
    "\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "  W1 = W1 - alpha * dW1\n",
    "  b1 = b1 - alpha * db1\n",
    "  W2 = W2 - alpha * dW2\n",
    "  b2 = b2 - alpha * db2\n",
    "  return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  # print(predictions)\n",
    "  # print(Y)\n",
    "  return np.sum(predictions == Y) / Y.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uF4cuvomklzP",
    "outputId": "2ffe30dc-e5a6-4f4a-d355-bdabff22b96d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = X_train.shape[1]\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FWQAzUy_kK3l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stochastic_gradient_descent(X, Y, epochs, alpha, batch_size):\n",
    "    # Initialize the random parameters\n",
    "    W1, b1, W2, b2 = params(batch_size)\n",
    "\n",
    "    # Calculate the number of examples\n",
    "    num_examples = X.shape[1]\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Generate a random permutation of indices\n",
    "        permuted_indices = np.random.permutation(num_examples)\n",
    "\n",
    "        # Shuffle both X and Y using the same permutation of indices\n",
    "        X_shuffled = X[:, permuted_indices]\n",
    "        Y_shuffled = Y[permuted_indices]\n",
    "\n",
    "        # Iterate over the shuffled data in batches\n",
    "        for j in range(0, num_examples, batch_size):\n",
    "            X_batch = X_shuffled[:, j:j + batch_size]\n",
    "            Y_batch = Y_shuffled[j:j + batch_size]\n",
    "\n",
    "            # Forward propagation\n",
    "            Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_batch, batch_size)\n",
    "\n",
    "            # Back propagation\n",
    "            dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W1, W2, X_batch, Y_batch, batch_size)\n",
    "\n",
    "            # Update weights\n",
    "            W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "\n",
    "        print(\"Epoch:\", i)\n",
    "        # Calculate accuracy using the entire dataset\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_batch, batch_size)\n",
    "        print(\"Accuracy:\", get_accuracy(get_predictions(A2), Y_batch))\n",
    "\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfYy_XctvU87",
    "outputId": "1dbd0a79-0e61-488e-9020-1e6ee3d70e28",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Accuracy: 0.6\n",
      "Epoch: 1\n",
      "Accuracy: 0.52\n",
      "Epoch: 2\n",
      "Accuracy: 0.54\n",
      "Epoch: 3\n",
      "Accuracy: 0.63\n",
      "Epoch: 4\n",
      "Accuracy: 0.6\n",
      "Epoch: 5\n",
      "Accuracy: 0.6\n",
      "Epoch: 6\n",
      "Accuracy: 0.75\n",
      "Epoch: 7\n",
      "Accuracy: 0.7\n",
      "Epoch: 8\n",
      "Accuracy: 0.63\n",
      "Epoch: 9\n",
      "Accuracy: 0.68\n",
      "Epoch: 10\n",
      "Accuracy: 0.77\n",
      "Epoch: 11\n",
      "Accuracy: 0.82\n",
      "Epoch: 12\n",
      "Accuracy: 0.77\n",
      "Epoch: 13\n",
      "Accuracy: 0.73\n",
      "Epoch: 14\n",
      "Accuracy: 0.76\n",
      "Epoch: 15\n",
      "Accuracy: 0.73\n",
      "Epoch: 16\n",
      "Accuracy: 0.75\n",
      "Epoch: 17\n",
      "Accuracy: 0.76\n",
      "Epoch: 18\n",
      "Accuracy: 0.8\n",
      "Epoch: 19\n",
      "Accuracy: 0.83\n",
      "Epoch: 20\n",
      "Accuracy: 0.84\n",
      "Epoch: 21\n",
      "Accuracy: 0.83\n",
      "Epoch: 22\n",
      "Accuracy: 0.82\n",
      "Epoch: 23\n",
      "Accuracy: 0.81\n",
      "Epoch: 24\n",
      "Accuracy: 0.77\n",
      "Epoch: 25\n",
      "Accuracy: 0.8\n",
      "Epoch: 26\n",
      "Accuracy: 0.65\n",
      "Epoch: 27\n",
      "Accuracy: 0.72\n",
      "Epoch: 28\n",
      "Accuracy: 0.76\n",
      "Epoch: 29\n",
      "Accuracy: 0.81\n",
      "Epoch: 30\n",
      "Accuracy: 0.82\n",
      "Epoch: 31\n",
      "Accuracy: 0.86\n",
      "Epoch: 32\n",
      "Accuracy: 0.84\n",
      "Epoch: 33\n",
      "Accuracy: 0.81\n",
      "Epoch: 34\n",
      "Accuracy: 0.79\n",
      "Epoch: 35\n",
      "Accuracy: 0.82\n",
      "Epoch: 36\n",
      "Accuracy: 0.75\n",
      "Epoch: 37\n",
      "Accuracy: 0.85\n",
      "Epoch: 38\n",
      "Accuracy: 0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mstochastic_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(X, Y, epochs, alpha, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m Y_shuffled \u001b[38;5;241m=\u001b[39m Y[permuted_indices]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Iterate over the shuffled data in batches\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     20\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_shuffled[:, j:j \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m     21\u001b[0m     Y_batch \u001b[38;5;241m=\u001b[39m Y_shuffled[j:j \u001b[38;5;241m+\u001b[39m batch_size]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = stochastic_gradient_descent(X_train, Y_train, 100, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "shhDA3BmvqiP",
    "outputId": "36eeab71-c65b-4c70-a1ad-ef36f072fef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 8 3 1 5 8 0 5 5 6 1 1 6 2 9 5 3 7 0 2 4 7 8 0 0 1 3 4 2 9 6 5 9 4 1 8\n",
      " 7 8 3 1 1 5 0 7 0 0 6 7 9 2 4 9 0 6 1 1 1 8 9 7 2 7 4 0 8 4 1 3 4 8 8 4 8\n",
      " 9 5 0 9 1 1 3 5 3 4 7 9 0 2 3 9 5 5 3 7 7 3 7 7 2 7]\n",
      "[5 3 0 9 1 5 8 0 5 5 6 1 1 3 2 9 5 8 7 5 2 4 7 8 0 0 1 3 4 2 3 6 5 9 4 1 8\n",
      " 7 8 3 1 1 5 0 5 8 0 6 7 9 2 4 9 0 6 1 1 1 2 9 7 2 2 4 0 8 4 1 3 4 3 8 4 8\n",
      " 7 5 0 4 1 1 3 8 3 4 7 3 0 2 7 4 5 8 3 7 7 3 7 5 2 7]\n",
      "Accuracy is: 81.0 %\n"
     ]
    }
   ],
   "source": [
    "# Testing our model:\n",
    "\n",
    "# Create batch from unseen data\n",
    "training_example = X_dev[:,100:200]\n",
    "Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, training_example, batch_size = 1)\n",
    "predictions = get_predictions (A2)\n",
    "print(predictions)\n",
    "print(Y_dev[100:200])\n",
    "\n",
    "print(\"Accuracy is:\", get_accuracy(Y_dev[100:200], predictions) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZjaNbHcxiz7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
