{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e84e255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kennykguo/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/kennykguo/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/kennykguo/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/kennykguo/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/kennykguo/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torchtext/transforms.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/kennykguo/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torchtext/functional.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from torchtext.datasets import WikiText2, EnWik9, AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchtext.data.functional import sentencepiece_tokenizer, load_sp_model\n",
    "\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d70b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "# Step size for parameter updates\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Number of training epochs\n",
    "nepochs = 20\n",
    "\n",
    "# Number of samples processed together\n",
    "batch_size = 32\n",
    "\n",
    "# Maximum sequence length\n",
    "max_len = 128\n",
    "\n",
    "# Root directory of the dataset\n",
    "data_set_root = \"../../data/news_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb711b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGNews dataset class definition\n",
    "class AGNews(Dataset):\n",
    "    def __init__(self, test_train=\"train\"):\n",
    "        # Read the AG News dataset CSV file based on the test_train parameter (train or test)\n",
    "        self.df = pd.read_csv(os.path.join(data_set_root, test_train + \".csv\"),\n",
    "                              names=[\"Class\", \"Title\", \"Content\"])\n",
    "        \n",
    "        # Fill missing values with empty string\n",
    "        self.df.fillna('', inplace=True)\n",
    "        \n",
    "        # Combine Title and Content columns into a single Article column\n",
    "        self.df['Article'] = self.df['Title'] + \" : \" + self.df['Content']\n",
    "        \n",
    "        # Drop Title and Content columns as they are no longer needed\n",
    "        self.df.drop(['Title', 'Content'], axis=1, inplace=True)\n",
    "        \n",
    "        # Replace special characters with whitespace in the Article column\n",
    "        self.df['Article'] = self.df['Article'].str.replace(r'\\\\n|\\\\|\\\\r|\\\\r\\\\n|\\n|\"', ' ', regex=True)\n",
    "\n",
    "    # Method to get a single item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        # Get the text of the article at the given index, converted to lowercase\n",
    "        text = self.df.loc[index][\"Article\"].lower()\n",
    "\n",
    "        return text\n",
    "\n",
    "    # Method to get the length of the dataset\n",
    "    def __len__(self):\n",
    "        # Return the total number of articles in the dataset\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4417ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = AGNews(test_train=\"train\")\n",
    "dataset_test = AGNews(test_train=\"test\")\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7192529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁i', '▁am', '▁creat', 'ing']\n"
     ]
    }
   ],
   "source": [
    "sp_model = load_sp_model(\"../../data/news_data/spm_ag_news.model\")\n",
    "\n",
    "# Create a tokenizer using the loaded model\n",
    "tokenizer = sentencepiece_tokenizer(sp_model)\n",
    "\n",
    "# Iterate over tokens generated by the tokenizer\n",
    "for token in tokenizer([\"i am creating\"]):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "031db2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to yield tokens from a file\n",
    "def yield_tokens(file_path):\n",
    "    # Open the file in UTF-8 encoding\n",
    "    with io.open(file_path, encoding='utf-8') as f:\n",
    "        # Iterate over each line in the file\n",
    "        for line in f:\n",
    "            # Yield the token split by tab character\n",
    "            yield [line.split(\"\\t\")[0]]\n",
    "\n",
    "# Build a vocabulary from the tokens yielded by the yield_tokens function\n",
    "    # <pad> is a padding token that is added to the end of a sentence to ensure the length of all sequences in a batch is the same\n",
    "    # <sos> signals the \"Start-Of-Sentence\" aka the start of the sequence\n",
    "    # <eos> signal the \"End-Of-Sentence\" aka the end of the sequence\n",
    "    # <unk> \"unknown\" token is used if a token is not contained in the vocab\n",
    "# From torchtext library (build_vocab_from_iterator)\n",
    "# Builds a generator object, that is treated like an iterator\n",
    "# Define special tokens with special_first=True to place them at the beginning of the vocabulary\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(\"../../data/news_data/spm_ag_news.vocab\"),\n",
    "    specials=['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "# Set default index for out-of-vocabulary tokens\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa2a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDrop(nn.Module):\n",
    "    \"\"\" For a batch of tokens indices, randomly replace a non-specical token with <pad>.\n",
    "    prob (float): probability of dropping a token\n",
    "    pad_token (int): index for the <pad> token\n",
    "    num_special (int): Number of special tokens, assumed to be at the start of the vocab\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prob=0.1, pad_token=0, num_special=4):\n",
    "        self.prob = prob\n",
    "        self.num_special = num_special\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # Randomly sample a bernoulli distribution with p = prob\n",
    "        # Create a mask where 1 means we will replace that token\n",
    "        # Discrete probability distribution\n",
    "        # Here we want to treat the ones as the indexes to drop\n",
    "        mask = torch.bernoulli(self.prob * torch.ones_like(sample)).long()\n",
    "        \n",
    "        # Only replace if the token is not a special token\n",
    "        # Ones or zeros. If cannot drop, 0, if can drop, 1\n",
    "        can_drop = (sample >= self.num_special).long()\n",
    "        # Multiply together to get the corresponding tokens to be dropped and not dropped\n",
    "        # Here, 1 represents drop, 0 represents do not drop\n",
    "        mask = mask * can_drop\n",
    "\n",
    "        # Make a mask of pad_token to use for replacing dropped indices with the pad_token\n",
    "        replace_with = (self.pad_token * torch.ones_like(sample)).long()\n",
    "        \"\"\" Sample is the original sample\n",
    "        The mask indicates what tokens can be replaced (0 to not be replaced, 1 to be replaced)\n",
    "        Replace_with is a list of of the pad_token tokens\n",
    "        Here, (1-mask) creates the complement mask. (now, 0 indicates drop, 1 indicates to not drop)\n",
    "        1-1 = 0, 1-0 = 0\n",
    "        Multiplying by sample, retains the original tokens that are not to be kept, and applies the mask on the sample\n",
    "        Here, mask * replace_with does elementwise multiplication and adds the corresponding pad_token to the tokens replaced\n",
    "        \"\"\"\n",
    "        sample_out = (1 - mask) * sample + mask * replace_with\n",
    "        \n",
    "        return sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72346ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation pipeline for training data\n",
    "train_transform = T.Sequential(\n",
    "    # Tokenize sentences using pre-existing SentencePiece tokenizer model\n",
    "    T.SentencePieceTokenizer(\"../../data/news_data/spm_ag_news.model\"),\n",
    "    # Convert tokens to indices based on given vocabulary\n",
    "    T.VocabTransform(vocab=vocab),\n",
    "    # Add <sos> token at the beginning of each sentence (index 1 in vocabulary)\n",
    "    T.AddToken(1, begin=True),\n",
    "    # Crop the sentence if it is longer than the max length\n",
    "    T.Truncate(max_seq_len=max_len),\n",
    "    # Add <eos> token at the end of each sentence (index 2 in vocabulary)\n",
    "    T.AddToken(2, begin=False),\n",
    "    # Convert the list of lists to a tensor and pad sentences with the <pad> token if shorter than max length\n",
    "    T.ToTensor(padding_value=0)\n",
    ")\n",
    "\n",
    "# Define a transformation pipeline for generation (without truncation)\n",
    "gen_transform = T.Sequential(\n",
    "    # Tokenize sentences using pre-existing SentencePiece tokenizer model\n",
    "    T.SentencePieceTokenizer(\"../../data/news_data/spm_ag_news.model\"),\n",
    "    # Convert tokens to indices based on given vocabulary\n",
    "    T.VocabTransform(vocab=vocab),\n",
    "    # Add <sos> token at the beginning of each sentence (index 1 in vocabulary)\n",
    "    T.AddToken(1, begin=True),\n",
    "    # Convert the list of lists to a tensor and pad sentences with the <pad> token if shorter than max length\n",
    "    T.ToTensor(padding_value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a4b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE\n",
      "un agency agrees to police iranian enrichment freeze as us voices &lt;b&gt;...&lt;/b&gt; : vienna, austria - the un nuclear agency agreed on ways to police irans suspension of some nuclear programs, but a us official said washington might still try to take the case to the security council.\n",
      "\n",
      "TOKENS\n",
      "['<sos>', '▁un', '▁agency', '▁agree', 's', '▁to', '▁police', '▁iranian', '▁enrichment', '▁freeze', '▁as', '▁us', '▁voices', '▁&', 'lt', '<unk>', 'b', '&', 'gt', '<unk>', '...', '&', 'lt', '<unk>', '/', 'b', '&', 'gt', '<unk>', '▁:', '▁vienna', '<unk>', '▁austria', '▁-', '▁the', '▁un', '▁nuclear', '▁agency', '▁agreed', '▁on', '▁ways', '▁to', '▁police', '▁iran', 's', '▁suspension', '▁of', '▁some', '▁nuclear', '▁programs', '<unk>', '▁but', '▁a', '▁us', '▁official', '▁said', '▁washington', '▁might', '▁still', '▁try', '▁to', '▁take', '▁the', '▁case', '▁to', '▁the', '▁security', '▁council', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "text = next(iter(data_loader_train))\n",
    "index = 0\n",
    "input_tokens = train_transform(text)\n",
    "print(\"SENTENCE\")\n",
    "print(text[index])\n",
    "print()\n",
    "print(\"TOKENS\")\n",
    "print(vocab.lookup_tokens(input_tokens[index].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "460c6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS BACK TO SENTENCE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sos> un agency agrees to police iranian enrichment freeze as us voices &lt<unk>b&gt<unk>...&lt<unk>/b&gt<unk> : vienna<unk> austria - the un nuclear agency agreed on ways to police irans suspension of some nuclear programs<unk> but a us official said washington might still try to take the case to the security council.<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TOKENS BACK TO SENTENCE\")\n",
    "\n",
    "pred_text = \"\".join(vocab.lookup_tokens(input_tokens[index].numpy()))\n",
    "pred_text.replace(\"▁\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350ac2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_emb, num_layers=1, emb_size=128, hidden_size=128):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Embedding layer to convert token indices to dense vectors\n",
    "        self.embedding = nn.Embedding(num_emb, emb_size) # (bs, T, emb_size)\n",
    "\n",
    "        # Additional MLP layers for embedding transformation\n",
    "        self.mlp_emb = nn.Sequential(nn.Linear(emb_size, emb_size),\n",
    "                                     nn.LayerNorm(emb_size),\n",
    "                                     nn.ELU(),\n",
    "                                     nn.Linear(emb_size, emb_size))\n",
    "        \n",
    "        # LSTM layer for sequential processing\n",
    "        self.lstm = nn.LSTM(input_size=emb_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Multi-head attention mechanism to capture dependencies between tokens\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size, \n",
    "                                               num_heads=8,\n",
    "                                               batch_first=True, \n",
    "                                               dropout=0.1)\n",
    "\n",
    "        # Final MLP layers for output transformation\n",
    "        self.mlp_out = nn.Sequential(nn.Linear(hidden_size, hidden_size//2),\n",
    "                                     nn.LayerNorm(hidden_size//2),\n",
    "                                     nn.ELU(),\n",
    "                                     nn.Dropout(0.5),\n",
    "                                     nn.Linear(hidden_size//2, num_emb))\n",
    "        \n",
    "    def forward(self, input_token, hidden_seq, hidden_in, mem_in):\n",
    "        input_embs = self.embedding(input_token) # (bs, T, emb_size)\n",
    "        input_embs = self.mlp_emb(input_embs) # (bs, T, emb_size)\n",
    "                \n",
    "        # Pass input embeddings through LSTM layer\n",
    "        output, (hidden_out, mem_out) = self.lstm(input_embs, (hidden_in, mem_in))\n",
    "        # (bs, T, hidden_size)\n",
    "        # (nl, bs, hidden_size)\n",
    "        # (nl, bs, hidden_size)\n",
    "        \n",
    "        # Log the output of the final LSTM layer\n",
    "        hidden_seq += [output]\n",
    "        hidden_cat = torch.cat(hidden_seq, 1)\n",
    "        \n",
    "        # Apply multi-head attention mechanism over LSTM outputs\n",
    "        # Use a single query from the current timestep\n",
    "        # Keys and Values created from the outputs of LSTM from all previous timesteps\n",
    "        attn_output, attn_output_weights = self.attention(output, hidden_cat, hidden_cat)  # Q, K, V\n",
    "        # bs, T, hidden_size)\n",
    "        \n",
    "        # Combine attention output with LSTM output\n",
    "        attn_output = attn_output + output\n",
    "                \n",
    "        # Apply final MLP layers for output transformation\n",
    "        return self.mlp_out(attn_output), hidden_seq, hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6341169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "emb_size = 256\n",
    "\n",
    "hidden_size = 256\n",
    "\n",
    "num_layers = 2\n",
    "\n",
    "lstm_generator = LSTM(num_emb=len(vocab), num_layers=num_layers, emb_size=emb_size, hidden_size=hidden_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(lstm_generator.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "td = TokenDrop(prob=0.1)\n",
    "\n",
    "training_loss_logger = []\n",
    "\n",
    "entropy_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dd56a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/20 [00:00<?, ?it/s]\n",
      "Training:   0%|                                                                                | 0/3750 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   0%|                                                                      | 1/3750 [00:06<7:09:49,  6.88s/it]\u001b[A\n",
      "Training:   0%|                                                                      | 2/3750 [00:10<5:14:27,  5.03s/it]\u001b[A\n",
      "Training:   0%|                                                                      | 3/3750 [00:15<5:00:30,  4.81s/it]\u001b[A\n",
      "Training:   0%|                                                                      | 4/3750 [00:18<4:18:39,  4.14s/it]\u001b[A\n",
      "Training:   0%|                                                                      | 5/3750 [00:21<3:58:44,  3.83s/it]\u001b[A\n",
      "Training:   0%|                                                                      | 6/3750 [00:25<3:57:10,  3.80s/it]\u001b[A\n",
      "Training:   0%|▏                                                                     | 7/3750 [00:31<4:49:21,  4.64s/it]\u001b[A\n",
      "Training:   0%|▏                                                                     | 8/3750 [00:34<4:14:29,  4.08s/it]\u001b[A\n",
      "Training:   0%|▏                                                                     | 9/3750 [00:40<4:52:16,  4.69s/it]\u001b[A\n",
      "Training:   0%|▏                                                                    | 10/3750 [00:43<4:27:42,  4.29s/it]\u001b[A\n",
      "Training:   0%|▏                                                                    | 11/3750 [00:49<4:46:05,  4.59s/it]\u001b[A\n",
      "Training:   0%|▏                                                                    | 12/3750 [00:54<5:06:47,  4.92s/it]\u001b[A\n",
      "Training:   0%|▏                                                                    | 13/3750 [00:57<4:28:42,  4.31s/it]\u001b[A\n",
      "Training:   0%|▎                                                                    | 14/3750 [01:00<4:03:26,  3.91s/it]\u001b[A\n",
      "                                                                                                                        \u001b[A\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m output_token \u001b[38;5;241m=\u001b[39m output_text[:, i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Forward pass through the LSTM model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m pred, hidden_seq, hidden, memory \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute the loss between predicted tokens and ground truth\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(pred\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), output_token)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 48\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_token, hidden_seq, hidden_in, mem_in)\u001b[0m\n\u001b[1;32m     43\u001b[0m hidden_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(hidden_seq, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Apply multi-head attention mechanism over LSTM outputs\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Use a single query from the current timestep\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Keys and Values created from the outputs of LSTM from all previous timesteps\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_cat\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Q, K, V\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# bs, T, hidden_size)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Combine attention output with LSTM output\u001b[39;00m\n\u001b[1;32m     52\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m output\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/functional.py:5364\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5363\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 5364\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5366\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.8/site-packages/torch/nn/functional.py:4896\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4894\u001b[0m     b_q, b_kv \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39msplit([E, E \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   4895\u001b[0m q_proj \u001b[38;5;241m=\u001b[39m linear(q, w_q, b_q)\n\u001b[0;32m-> 4896\u001b[0m kv_proj \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_kv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_kv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4897\u001b[0m \u001b[38;5;66;03m# reshape to 2, E and not E, 2 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[1;32m   4898\u001b[0m kv_proj \u001b[38;5;241m=\u001b[39m kv_proj\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m2\u001b[39m, E))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(0, nepochs, leave=False, desc=\"Epoch\"):    \n",
    "    # Set the model to training mode\n",
    "    lstm_generator.train()\n",
    "    steps = 0\n",
    "    # Iterate over the training data loader, displaying progress\n",
    "    for text in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        # Transform the text data into token indices and move it to the appropriate device\n",
    "        text_tokens = train_transform(list(text)).to(device)\n",
    "        bs = text_tokens.shape[0]\n",
    "        \n",
    "        # Randomly drop input tokens to improve generalization\n",
    "        input_text = td(text_tokens[:, 0:-1])\n",
    "        output_text = text_tokens[:, 1:]\n",
    "        \n",
    "        # Initialize the memory buffers for the LSTM\n",
    "        hidden = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "        memory = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "        \n",
    "        # Use a list to log the output of the LSTM at each timestep for the attention mechanism\n",
    "        hidden_seq = []\n",
    "        \n",
    "        # Manually loop through the LSTM to log the output for attention mechanism\n",
    "        loss = 0\n",
    "        for i in range(input_text.shape[1]):\n",
    "            input_token = input_text[:, i].unsqueeze(1)\n",
    "            output_token = output_text[:, i].unsqueeze(1)\n",
    "\n",
    "            # Forward pass through the LSTM model\n",
    "            pred, hidden_seq, hidden, memory = lstm_generator(input_token, hidden_seq, hidden, memory)\n",
    "\n",
    "            # Compute the loss between predicted tokens and ground truth\n",
    "            loss += loss_fn(pred.transpose(1, 2), output_token)\n",
    "        \n",
    "        # Average the loss over all time steps\n",
    "        loss /= (i + 1)\n",
    "        \n",
    "        # Zero the gradients to prevent accumulation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagation to compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log the training loss for visualization\n",
    "        training_loss_logger.append(loss.item())\n",
    "        \n",
    "        # Compute the entropy of the predicted distribution\n",
    "        with torch.no_grad():\n",
    "            dist = Categorical(logits=pred)\n",
    "            entropy_logger.append(dist.entropy().mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4b610",
   "metadata": {},
   "source": [
    "## Generate some text!\n",
    "Lets use the fact that all of the articles have the title and content seperated by a \":\" to get our model to generate some content based on a title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ecf35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some test examples\n",
    "text = next(iter(data_loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aecfeb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL PROMPT:\n",
      "been there, won that\n",
      "\n",
      "ORIGINAL CONTENT:\n",
      " nd hopes usc game mirrors effort vs. &lt;b&gt;...&lt;/b&gt; \n",
      "\n",
      "PROMPT TOKENS:\n",
      "tensor([[    1,  5762, 18427,     3, 19769, 18409,   237]])\n",
      "['<sos>', '▁been', '▁there', '<unk>', '▁won', '▁that', ':']\n"
     ]
    }
   ],
   "source": [
    "# Select an index from the test data\n",
    "index = 0\n",
    "temp = 0.8\n",
    "\n",
    "# Extract the title and content from the text\n",
    "title = text[index].split(\":\")[0]\n",
    "content = text[index].split(\":\")[1]\n",
    "\n",
    "# Create an initial prompt using the title\n",
    "init_prompt = [title + \":\"]\n",
    "\n",
    "# Transform the initial prompt into tokens and move to the appropriate device\n",
    "input_tokens = gen_transform(init_prompt).to(device)\n",
    "\n",
    "# Print the initial prompt, original content, and prompt tokens for inspection\n",
    "print(\"INITIAL PROMPT:\")\n",
    "print(title)\n",
    "print(\"\")\n",
    "print(\"ORIGINAL CONTENT:\")\n",
    "print(content)\n",
    "print(\"\\nPROMPT TOKENS:\")\n",
    "print(input_tokens)\n",
    "print(vocab.lookup_tokens(input_tokens[0].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6148b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 341.70it/s]\n"
     ]
    }
   ],
   "source": [
    "log_tokens = []\n",
    "lstm_generator.eval()\n",
    "\n",
    "with torch.no_grad():    \n",
    "    # Initialize the hidden state and memory for LSTM\n",
    "    hidden = torch.zeros(num_layers, 1, hidden_size, device=device)\n",
    "    memory = torch.zeros(num_layers, 1, hidden_size, device=device)\n",
    "    \n",
    "    # Initialize the hidden sequence for logging LSTM outputs\n",
    "    hidden_seq = []\n",
    "    \n",
    "    # Pass each token of the input_tokens through the LSTM\n",
    "    for i in range(input_tokens.shape[1]):\n",
    "        input_token = input_tokens[:, i].unsqueeze(1)\n",
    "\n",
    "        # Pass the input token through the LSTM model\n",
    "        data_pred, hidden_seq, hidden, memory = lstm_generator(input_token, hidden_seq, hidden, memory)\n",
    "        \n",
    "    # Sample the next token based on the output distribution of the LSTM\n",
    "    dist = Categorical(logits=data_pred[:, -1]/temp)\n",
    "    input_tokens = dist.sample().reshape(1, 1)\n",
    "    \n",
    "    # Generate text tokens for a fixed number of iterations or until reaching end-of-sequence token\n",
    "    for i in trange(10):\n",
    "        # Pass the current token through the LSTM model\n",
    "        data_pred, hidden_seq, hidden, memory = lstm_generator(input_tokens, hidden_seq, hidden, memory)\n",
    "        \n",
    "        # Sample the next token based on the output distribution of the LSTM\n",
    "        dist = Categorical(logits=data_pred[:, -1]/temp)\n",
    "        input_tokens = dist.sample().reshape(1, 1)\n",
    "        \n",
    "        # Append the sampled token to the log_tokens list\n",
    "        log_tokens.append(input_tokens.cpu())\n",
    "        \n",
    "        # Break the loop if the end-of-sequence token is sampled\n",
    "        if input_tokens.item() == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "024ddad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁came▁rebuke▁grad▁hurdle▁iverson▁ceremoni▁gem▁reserved▁marketing▁silk\n"
     ]
    }
   ],
   "source": [
    "# Join the tokens in log_tokens into a single string using the vocabulary lookup\n",
    "pred_text = \"\".join(vocab.lookup_tokens(torch.cat(log_tokens, 1)[0].numpy()))\n",
    "\n",
    "# Print the generated text\n",
    "print(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "286c2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been there, won that: came rebuke grad hurdle iverson ceremoni gem reserved marketing silk\n"
     ]
    }
   ],
   "source": [
    "# Combine the initial title with the generated text\n",
    "final_article = init_prompt[0] + pred_text.replace(\"▁\", \" \").replace(\"<unk>\", \"\")\n",
    "\n",
    "# Print the final article\n",
    "print(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b626aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets have a look at the probabilities\n",
    "_ = plt.plot(F.softmax(data_pred[:, -1]/temp, -1).cpu().numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep-learning)",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
