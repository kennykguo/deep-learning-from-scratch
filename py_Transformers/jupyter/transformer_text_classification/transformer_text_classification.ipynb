{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5d05196f-035c-49d6-8922-d823e8fb9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.functional import generate_sp_model, load_sp_model, sentencepiece_tokenizer, sentencepiece_numericalizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "708aeccf-e502-47c2-894f-237215dbab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/data/main/torchdata.datapipes.iter.html\n",
    "# https://medium.com/deelvin-machine-learning/comparison-of-pytorch-dataset-and-torchdata-datapipes-486e03068c58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c39fc1-a25f-4b57-9e32-9f727014b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"2\"', '\"Nets get Carter from Raptors\"', '\"INDIANAPOLIS -- All-Star Vince Carter was traded by the Toronto Raptors to the New Jersey Nets for Alonzo Mourning', ' Eric Williams', ' Aaron Williams', ' and a pair of first-round draft picks yesterday.\"\\n']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "root = \"data\"\n",
    "with open(os.path.join(root, \"train.csv\")) as f:\n",
    "        with open(os.path.join(root, \"data.txt\"), \"w\") as f2:\n",
    "            for line in f:\n",
    "                text_only = \"\".join(line.split(\",\")[1:])\n",
    "                filtered = re.sub(r'\\\\|\\\\n|;', ' ', text_only.replace('\"', ' ').replace('\\n', ' '))\n",
    "                filtered = filtered.replace(' #39;', \"'\")\n",
    "                filtered = filtered.replace(' #38;', \"&\")\n",
    "                filtered = filtered.replace(' #36;', \"$\")\n",
    "                filtered = filtered.replace(' #151;', \"-\")\n",
    "                f2.write(filtered.lower() + \"\\n\")\n",
    "\n",
    "# Example line\n",
    "print(line.split(\",\"))\n",
    "print(type(line.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3cbf43-85b6-4905-a1bf-f29e03a3874b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=data/data.txt --model_prefix=SentencePiece/transformer --vocab_size=20000 --model_type=unigram\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/data.txt\n",
      "  input_format: \n",
      "  model_prefix: SentencePiece/transformer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(319) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(174) LOG(INFO) Loading corpus: data/data.txt\n",
      "trainer_interface.cc(375) LOG(INFO) Loaded all 120000 sentences\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(395) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(456) LOG(INFO) all chars count=28222889\n",
      "trainer_interface.cc(467) LOG(INFO) Done: 99.9756% characters are covered.\n",
      "trainer_interface.cc(477) LOG(INFO) Alphabet size=48\n",
      "trainer_interface.cc(478) LOG(INFO) Final character coverage=0.999756\n",
      "trainer_interface.cc(510) LOG(INFO) Done! preprocessed 120000 sentences.\n",
      "unigram_model_trainer.cc(138) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(142) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(193) LOG(INFO) Initialized 152602 seed sentencepieces\n",
      "trainer_interface.cc(516) LOG(INFO) Tokenizing input sentences with whitespace: 120000\n",
      "trainer_interface.cc(526) LOG(INFO) Done! 120631\n",
      "unigram_model_trainer.cc(488) LOG(INFO) Using 120631 sentences for EM training\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=62443 obj=11.2717 num_tokens=276733 num_tokens/piece=4.43177\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=49790 obj=9.0969 num_tokens=277388 num_tokens/piece=5.57116\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=37337 obj=9.0515 num_tokens=288412 num_tokens/piece=7.72456\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=37324 obj=9.03806 num_tokens=288579 num_tokens/piece=7.73173\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=27993 obj=9.07602 num_tokens=309208 num_tokens/piece=11.0459\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=27993 obj=9.06489 num_tokens=309177 num_tokens/piece=11.0448\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=22000 obj=9.12194 num_tokens=328649 num_tokens/piece=14.9386\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=21999 obj=9.10707 num_tokens=328625 num_tokens/piece=14.9382\n",
      "trainer_interface.cc(604) LOG(INFO) Saving model: SentencePiece/transformer.model\n",
      "trainer_interface.cc(615) LOG(INFO) Saving vocabs: SentencePiece/transformer.vocab\n"
     ]
    }
   ],
   "source": [
    "# Generate the SentencePiece tokenizer\n",
    "    # Text tokenizer and detokenizer\n",
    "    # Unsupervised text tokenizer. It will tokenize words into subpieces instead of words\n",
    "    # This function will create a set of subtokens to fit the set vocabulary size\n",
    "    # There will always be enough subwords to subtokenize a dataset if you think about it :) -> max 2 length pairs = 26!\n",
    "    # Saved in the home directory\n",
    "generate_sp_model(os.path.join(root, \"data.txt\"), vocab_size=20000, model_prefix='SentencePiece/transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e9b8c6-f18f-4cd0-a686-de839cbe2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class must inherit from Dataset to use DataLoader from torch\n",
    "class AGNews(Dataset):\n",
    "    def __init__(self, num_datapoints, set=\"train\"):\n",
    "\n",
    "        # Reads the file into a pandas DataFrame\n",
    "        self.df = pd.read_csv(os.path.join(root, set + \".csv\"), names=[\"Class\", \"Title\", \"Content\"])\n",
    "\n",
    "        # Replaces empty entries with a space\n",
    "        self.df.fillna('', inplace=True)\n",
    "\n",
    "        # Concatenates title and content into one heading 'article'\n",
    "        self.df['Article'] = self.df['Title'] + \" : \" + self.df['Content']\n",
    "        self.df.drop(['Title', 'Content'], axis=1, inplace=True)\n",
    "        self.df['Article'] = self.df['Article'].str.replace(r'\\\\n|\\\\|\\\\r|\\\\r\\\\n|\\n|\"', ' ', regex=True)\n",
    "\n",
    "        # Clean up 'Article' column text\n",
    "        self.df['Article'] = self.df['Article'].replace({' #39;': \"'\", ' #38;': \"&\", ' #36;': \"$\", ' #151;': \"-\"}, regex=True)\n",
    "\n",
    "        # Gets the first num_datapoints datapoints\n",
    "        if num_datapoints is not None:\n",
    "            self.df = self.df.head(num_datapoints)\n",
    "\n",
    "    # To use for DataLoader\n",
    "    def __getitem__(self, index):\n",
    "        text = self.df.loc[index][\"Article\"].lower()\n",
    "        # See if we can remove array indexing\n",
    "        class_index = int(self.df.loc[index][\"Class\"]) - 1\n",
    "        return class_index, text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Create training and testing datasets from train.csv, test.csv, using AGNews class\n",
    "train_dataset = AGNews(num_datapoints=10000, set=\"train\")\n",
    "test_dataset = AGNews(num_datapoints=10000, set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c57c0c02-ff0b-4d53-8754-bf7c0be6c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "db1b0de6-ecdb-41e4-8b78-28eb4c06d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99d0d48a-2913-497f-9ab9-34350dfd5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for the training and testing datasets\n",
    "# Dataloaders allow for batching, shuffling\n",
    "\n",
    "batch_size = 32  # Example batch size\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e1088bb3-c7a2-4b83-9016-27b4293696b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize individual entries\n",
    "# x = list(sp_tokenizer([text_batch[0]]))[0]\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ddd4cab-8ebe-481a-b9e6-bcea113890c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and numericalization\n",
    "\n",
    "# Load the trained SentencePiece model\n",
    "sp_model = load_sp_model(\"transformer.model\")\n",
    "\n",
    "# Create a tokenizer function from file\n",
    "sp_tokenizer = sentencepiece_tokenizer(sp_model)\n",
    "\n",
    "# Create a numericalizer function from file\n",
    "sp_numericalizer = sentencepiece_numericalizer(sp_model)\n",
    "\n",
    "# Example usage\n",
    "# for class_index, text_batch in dataloader_train:\n",
    "    \n",
    "#     # text_batch is a list of sentences\n",
    "#     tokenized_text_batch = [list(sp_tokenizer([t]))[0] for t in text_batch]\n",
    "\n",
    "#     numericalized_text_batch = [list(sp_numericalizer([t]))[0] for t in text_batch]\n",
    "    \n",
    "#     print(f\"Original Text: {text_batch[0]}\")\n",
    "    \n",
    "#     print(f\"Tokenized Text: {tokenized_text_batch[0]}\")\n",
    "    \n",
    "#     print(f\"Numericalized Text: {numericalized_text_batch[0]}\")\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "47863551-0b36-471a-9962-9bf732969868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdc1832f-a16b-4b45-8152-86754e96e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(file_path):\n",
    "    with io.open(file_path, encoding='utf-8') as f:\n",
    "        # Iterate through each line in the file\n",
    "        for line in f:\n",
    "            # Yield the token from the first column (split by tab)\n",
    "            yield [line.split(\"\\t\")[0]]\n",
    "\n",
    "# Build a vocabulary from the tokens yielded by the yield_tokens function\n",
    "    # <pad> is a padding token that is added to the end of a sentence to ensure the length of all sequences in a batch is the same\n",
    "    # <sos> signals the \"Start-Of-Sentence\" aka the start of the sequence\n",
    "    # <eos> signal the \"End-Of-Sentence\" aka the end of the sequence\n",
    "    # <unk> \"unknown\" token is used if a token is not contained in the vocab\n",
    "# From torchtext library (build_vocab_from_iterator)\n",
    "# Builds a generator object, that is treated like an iterator\n",
    "vocab = build_vocab_from_iterator(yield_tokens(\"transformer.vocab\"), specials=['<pad>', '<sos>', '<eos>', '<unk>'], special_first=True)\n",
    "\n",
    "# Set the default index for unknown tokens to the index of the '<unk>' token\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b607f19d-1f63-4040-af39-2db2615c668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab['<pad>'])  # Should print the index of <pad>\n",
    "# print(vocab['<sos>'])  # Should print the index of <sos>\n",
    "# print(vocab['<eos>'])  # Should print the index of <eos>\n",
    "# print(vocab['<unk>'])  # Should print the index of <unk>\n",
    "# print(vocab['▁the'])   # Should print the index of ▁the (if present)\n",
    "# print(vocab['unknown_token'])  # Should print the index of <unk> as it's not in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b0ddb0c-f8e9-4491-8aa1-4a1a6d5d84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sequence length for text inputs\n",
    "max_len = 160\n",
    "\n",
    "# Data transform to turn text into vocab token\n",
    "# Text transformation pipeline aliased T\n",
    "text_transform = T.Sequential(\n",
    "    # Tokenize with pretrained Tokenizer\n",
    "    T.SentencePieceTokenizer(\"transformer.model\"),\n",
    "    # Converts the sentences to indices based on given vocabulary\n",
    "    T.VocabTransform(vocab=vocab),\n",
    "    # Add <sos> at beginning of each sentence. \n",
    "    # 1 because the index for <sos> in vocabulary is 1 as seen in previous section\n",
    "    T.AddToken(vocab['<sos>'], begin=True),\n",
    "    # Crop the sentence if it is longer than the max length\n",
    "    T.Truncate(max_seq_len=max_len),\n",
    "    ## Add <eos> at beginning of each sentence. \n",
    "    # 2 because the index for <eos> in vocabulary is 2\n",
    "    T.AddToken(vocab['<eos>'], begin=False),\n",
    "    # Convert the list of lists to a tensor, this will also\n",
    "    # Pad a sentence with the <pad> token if it is shorter than the max length\n",
    "    # This ensures all sentences are the same length\n",
    "    # T.ToTensor(padding_value=vocab['<pad>']),\n",
    ")\n",
    "\n",
    "# Custom padding function\n",
    "def pad_sequence(seq, max_len, padding_value):\n",
    "    if len(seq) < max_len:\n",
    "        seq += [padding_value] * (max_len - len(seq))\n",
    "    return seq[:max_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "598a72b7-adef-48ef-8a98-59b24373bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,  3686,     3,  1556, 11578,  5040,  9237, 16819,    50,     2,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    1,  4555,  4555,     3,  4555,     3,  4555,     3,  4555,     3,\n",
      "          4555,     3,  4555,     3,  4555,     2,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    1,  5521,  5521,  5521,  5521,  5521,  5521,  5521,     2,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "torch.Size([3, 160])\n"
     ]
    }
   ],
   "source": [
    "# Example text data\n",
    "example_texts = [\"This is an example sentence.\", \"a a, a, a, a, a, a, a\", \"b b b b b b b\"]\n",
    "\n",
    "padding_idx = 0\n",
    "\n",
    "# Loop through all examples, separated by a comma\n",
    "transformed_texts = [pad_sequence(text_transform([text])[0], max_len, padding_idx) for text in example_texts]\n",
    "\n",
    "# Convert to tensor and stack into a batch\n",
    "batch_tensor = torch.stack([torch.tensor(seq, dtype=torch.long) for seq in transformed_texts])\n",
    "\n",
    "print(batch_tensor)\n",
    "print(batch_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1beb384c-6a4a-423c-91fb-f3cb75fe9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDrop(nn.Module):\n",
    "    \"\"\" For a batch of tokens indices, randomly replace a non-specical token with <pad>.\n",
    "    prob (float): probability of dropping a token\n",
    "    pad_token (int): index for the <pad> token\n",
    "    num_special (int): Number of special tokens, assumed to be at the start of the vocab\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prob=0.1, pad_token=0, num_special=4):\n",
    "        self.prob = prob\n",
    "        self.num_special = num_special\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # Randomly sample a bernoulli distribution with p = prob\n",
    "        # Create a mask where 1 means we will replace that token\n",
    "        # Discrete probability distribution\n",
    "        # Here we want to treat the ones as the indexes to drop\n",
    "        mask = torch.bernoulli(self.prob * torch.ones_like(sample)).long()\n",
    "        \n",
    "        # Only replace if the token is not a special token\n",
    "        # Ones or zeros. If cannot drop, 0, if can drop, 1\n",
    "        can_drop = (sample >= self.num_special).long()\n",
    "        # Multiply together to get the corresponding tokens to be dropped and not dropped\n",
    "        # Here, 1 represents drop, 0 represents do not drop\n",
    "        mask = mask * can_drop\n",
    "\n",
    "        # Make a mask of pad_token to use for replacing dropped indices with the pad_token\n",
    "        replace_with = (self.pad_token * torch.ones_like(sample)).long()\n",
    "        # Sample is the original sample\n",
    "        # THe mask indicates what tokens can be replaced (0 to not be replaced, 1 to be replaced)\n",
    "        # Replace_with is a list of of the pad_token tokens\n",
    "        # Here, (1-mask) creates the complement mask. (now, 0 indicates drop, 1 indicates to not drop)\n",
    "        # 1-1 = 0, 1-0 = 0\n",
    "        # Multiplying by sample, retains the original tokens that are not to be kept, and applies the mask on the sample\n",
    "        # Here, mask * replace_with does elementwise multiplication and adds the corresponding pad_token to the tokens replaced\n",
    "        sample_out = (1 - mask) * sample + mask * replace_with\n",
    "        \n",
    "        return sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ec49e3c-8b79-4bf7-854c-f39fd7a9a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the device of the input tensor\n",
    "        device = x.device\n",
    "        \n",
    "        # Calculate half of the hidden size\n",
    "        half_dim = self.hidden_size // 2\n",
    "        \n",
    "        # Compute the scaling factor\n",
    "        emb_scale = math.log(10000) / (half_dim - 1)\n",
    "        \n",
    "        # Generate the sinusoidal frequencies\n",
    "        emb_frequencies = torch.exp(torch.arange(half_dim, device=device) * -emb_scale)\n",
    "        \n",
    "        # Apply frequencies to the positions\n",
    "        emb = x[:, :, None] * emb_frequencies[None, None, :]\n",
    "        \n",
    "        # Concatenate sin and cos functions to form positional embeddings\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        \n",
    "        return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b9cc2310-f2c2-4f54-820a-f29519b492c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanoTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "        This class implements a simplified Transformer model for sequence classification. \n",
    "        It uses an embedding layer for tokens, sinusoidal positional embeddings, \n",
    "        a Transformer, and a Linear layer.\n",
    "        \n",
    "        num_emb: The number of unique tokens in the vocabulary. (vocab_size)\n",
    "        output_size: The size of the output layer (number of classes). (4)\n",
    "        hidden_size: The dimension of the hidden layer in the Transformer block (default: 128)\n",
    "        num_heads: The number of heads in the multi-head attention layer (default: 4).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_emb, output_size, hidden_size=128, num_heads=4):\n",
    "        \n",
    "        # Inherits from nn.Module's attributes\n",
    "        super(NanoTransformer, self).__init__()\n",
    "\n",
    "        # Create an embedding for each token\n",
    "        self.embedding = nn.Embedding(num_emb, hidden_size) # (vocab_size, 128)\n",
    "        \n",
    "        # Scaling down the embedding weights\n",
    "        self.embedding.weight.data = 0.001 * self.embedding.weight.data\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_emb = SinusoidalPosEmb(hidden_size) # (128)\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_size, num_heads = num_heads, batch_first = True)\n",
    "\n",
    "        # Linear layer\n",
    "        self.mlp = nn.Sequential(nn.Linear(hidden_size, hidden_size), # (batch_size, 128, 128)\n",
    "                                 nn.LayerNorm(hidden_size), # (batch_size, 128, 128)\n",
    "                                 nn.ELU(), # (batch_size, 128, 128)\n",
    "                                 nn.Linear(hidden_size, hidden_size)) # (batch_size, 128, 128)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size) # (batch_size, 128, 128)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # batch_size, time_steps\n",
    "        batch_size, l = input_seq.shape # (32, 160)\n",
    "\n",
    "        input_embs = self.embedding(input_seq) # (32, 160) -> (32, 160, 128)\n",
    "        \n",
    "        # Add a unique embedding to each token embedding depending on it's position in the sequence\n",
    "        seq_indx = torch.arange(l) # (160)\n",
    "        \n",
    "        pos_emb = self.pos_emb(seq_indx.repeat(batch_size, 1)) # (1, 160, 128) -> (32, 160, 128)\n",
    "        \n",
    "        embs = input_embs + pos_emb # (32, 160, 128) + (32, 160, 128)\n",
    "        \n",
    "        output, attn_map = self.multihead_attn(embs, embs, embs) # (32, 160, 128)\n",
    "        \n",
    "        output = self.mlp(output) # (32, 160, 128)\n",
    "\n",
    "        return self.fc_out(output), attn_map # (32, 160, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "561a2785-752b-4f53-ba90-da82428e3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Embedding size\n",
    "hidden_size = 256\n",
    "\n",
    "# Learning rate for the optimizer\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Number of epochs for training\n",
    "nepochs = 20\n",
    "\n",
    "# Batch size for data loaders\n",
    "batch_size = 128\n",
    "\n",
    "# Maximum sequence length for text inputs\n",
    "max_len = 128\n",
    "\n",
    "output_size = 4\n",
    "\n",
    "num_heads = 4\n",
    "\n",
    "time_steps = 160\n",
    "\n",
    "# Create the Transformer model\n",
    "tf_classifier = NanoTransformer(num_emb=len(vocab), output_size=4, hidden_size = hidden_size, num_heads = 4).to(device)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optim.Adam(tf_classifier.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Cosine annealing scheduler to decay the learning rate\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=nepochs, eta_min=0)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Custom transform to randomly replace a token with <pad>\n",
    "td = TokenDrop(prob=0.5)\n",
    "\n",
    "# Training and testing loss\n",
    "training_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "# Training and testing accuracy\n",
    "training_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "train_acc = 0\n",
    "\n",
    "test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "60012da2-236e-46c0-b5ff-dc55a21257d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-This Model Has 5517060 (Approximately 5 Million) Parameters!\n"
     ]
    }
   ],
   "source": [
    "# Number of model parameters\n",
    "num_model_params = 0\n",
    "for param in tf_classifier.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cf14c176-ef03-441d-9616-1b055316995a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Train 27525.42%, Test 108325.23%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[292], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m batch_tensor \u001b[38;5;241m=\u001b[39m td(batch_tensor)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Get the model predictions\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m pred, _ \u001b[38;5;241m=\u001b[39m tf_classifier(batch_tensor)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Compute the loss using cross-entropy loss\u001b[39;00m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred[:, \u001b[38;5;241m0\u001b[39m, :], labels)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[208], line 50\u001b[0m, in \u001b[0;36mNanoTransformer.forward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     46\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(seq_indx\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# (1, 160, 128) -> (32, 160, 128)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m embs \u001b[38;5;241m=\u001b[39m input_embs \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (32, 160, 128) + (32, 160, 128)\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m output, attn_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultihead_attn(embs, embs, embs) \u001b[38;5;66;03m# (32, 160, 128)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(output) \u001b[38;5;66;03m# (32, 160, 128)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output), attn_map\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1267\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   1269\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_zero_attn,\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1271\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1272\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m   1273\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m   1274\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m   1275\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1276\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:5470\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5469\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m-> 5470\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   5472\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:1885\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over each epoch\n",
    "for epoch in range(nepochs):\n",
    "    \n",
    "    print('Accuracy: Train %.2f%%, Test %.2f%%' %(train_acc * 100, test_acc * 100))\n",
    "    \n",
    "    tf_classifier.train()\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    # Loop over each batch in the training dataset\n",
    "    for batch_idx, (labels, texts) in enumerate(dataloader_train):\n",
    "        # Number of examples in the batch\n",
    "        batch_size = labels.shape[0]\n",
    "        \n",
    "        # Transform the text to tokens\n",
    "        # text_tokens = text_transform(list(texts)).to(device)\n",
    "\n",
    "        transformed_texts = [pad_sequence(text_transform([text])[0], max_len, padding_idx) for text in texts]\n",
    "        # Convert to tensor and stack into a batch\n",
    "        batch_tensor = torch.stack([torch.tensor(seq, dtype=torch.long) for seq in transformed_texts])\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # TokenDrop\n",
    "        batch_tensor = td(batch_tensor)\n",
    " \n",
    "        # Get the model predictions\n",
    "        pred, _ = tf_classifier(batch_tensor)\n",
    "\n",
    "        # Compute the loss using cross-entropy loss\n",
    "        loss = loss_fn(pred[:, 0, :], labels)\n",
    "        \n",
    "        # Backpropagation and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log the training loss\n",
    "        training_loss.append(loss.item())\n",
    "        \n",
    "        # Update training accuracy\n",
    "        train_acc += (pred[:, 0, :].argmax(1) == labels).sum()\n",
    "        steps += batch_size\n",
    "    \n",
    "    # Calculate average training accuracy\n",
    "    train_acc = (train_acc / steps).item()\n",
    "    training_acc_list.append(train_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    tf_classifier.eval()\n",
    "    steps = 0\n",
    "    \n",
    "    # Loop over each batch in the testing dataset\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, texts) in enumerate(dataloader_train):\n",
    "            batch_size = labels.shape[0]\n",
    "            # Transform the text to tokens and move to the GPU\n",
    "            # text_tokens = text_transform(list(texts)).to(device)\n",
    "            # padded_tokens = pad_sequence(text_tokens, max_len, padding_idx)\n",
    "            transformed_texts = [pad_sequence(text_transform([text])[0], max_len, padding_idx) for text in texts]\n",
    "            # Convert to tensor and stack into a batch\n",
    "            batch_tensor = torch.stack([torch.tensor(seq, dtype=torch.long) for seq in transformed_texts])\n",
    "            \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the model predictions (Do not return attention map)\n",
    "            pred, _ = tf_classifier(batch_tensor)\n",
    "\n",
    "            # Compute the loss using cross-entropy loss\n",
    "            loss = loss_fn(pred[:, 0, :], labels)\n",
    "            # Corresponds to the start of sentence token\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "            # Update testing accuracy\n",
    "            test_acc += (pred[:, 0, :].argmax(1) == labels).sum()\n",
    "            steps += batch_size\n",
    "\n",
    "        # Calculate average testing accuracy\n",
    "        test_acc = (test_acc / steps).item()\n",
    "        test_acc_list.append(test_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5c1d7b89-977b-4822-a80c-64e7d6e5081c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(np.linspace(0, nepochs, len(training_loss_list)), training_loss_list)\n",
    "_ = plt.plot(np.linspace(0, nepochs, len(test_loss_list)), test_loss_list)\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "_ = plt.title(\"Training Vs Test Loss\")\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ae485636-eaae-4123-b8dc-200ccfedf863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(np.linspace(0, nepochs, len(training_acc_list)), training_acc_list)\n",
    "_ = plt.plot(np.linspace(0, nepochs, len(test_acc_list)), test_acc_list)\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "_ = plt.title(\"Training Vs Test Accuracy\")\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Accuracy\")\n",
    "print(\"Max Test Accuracy %.2f%%\" % (np.max(test_acc_list) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "58c1f111-2c6e-4552-ba07-9c0215745739",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[306], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     label, text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader_train))\n\u001b[0;32m---> 10\u001b[0m     text_tokens \u001b[38;5;241m=\u001b[39m text_transform(\u001b[38;5;28mlist\u001b[39m(text))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     pred, attention_map \u001b[38;5;241m=\u001b[39m tf_classifier(text_tokens)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "ag_news_classes = [\n",
    "    \"World\",\n",
    "    \"Sports\",\n",
    "    \"Business\",\n",
    "    \"Science/Technology\"\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    label, text = next(iter(dataloader_train))\n",
    "    text_tokens = text_transform(list(text)).to(device)\n",
    "    pred, attention_map = tf_classifier(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "02e987ca-bc6f-4c6b-b6c9-d956aee4e3a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attention_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[310], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_index \u001b[38;5;241m<\u001b[39m label\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Select the attention map for a single sample and the first attention head\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m att_map \u001b[38;5;241m=\u001b[39m attention_map[test_index, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m pred_class \u001b[38;5;241m=\u001b[39m ag_news_classes[pred[test_index, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[1;32m      9\u001b[0m top5 \u001b[38;5;241m=\u001b[39m att_map\u001b[38;5;241m.\u001b[39margsort(descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attention_map' is not defined"
     ]
    }
   ],
   "source": [
    "test_index = 3\n",
    "\n",
    "# Choose a text index smaller than the total number in the batch!\n",
    "assert test_index < label.shape[0]\n",
    "\n",
    "# Select the attention map for a single sample and the first attention head\n",
    "att_map = attention_map[test_index, 0]\n",
    "pred_class = ag_news_classes[pred[test_index, -1].argmax().item()]\n",
    "top5 = att_map.argsort(descending=True)[:5]\n",
    "top5_tokens = vocab.lookup_tokens(text_tokens[test_index, top5].cpu().numpy())\n",
    "\n",
    "\n",
    "print(\"Article:\")\n",
    "print(text[test_index])\n",
    "print(\"\\nPredicted label:\")\n",
    "print(pred_class)\n",
    "print(\"True label:\")\n",
    "print(ag_news_classes[label[test_index].item()])\n",
    "\n",
    "print(\"\\nTop 5 Tokens:\")\n",
    "print(top5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e3dbd933-329f-4fa1-a5fd-bab5ac498b9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'att_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[308], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mplot(att_map\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      2\u001b[0m _ \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention score per token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'att_map' is not defined"
     ]
    }
   ],
   "source": [
    "_ = plt.plot(att_map.cpu().numpy())\n",
    "_ = plt.title(\"Attention score per token\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
