{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dPuz7WksL2FJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "e5eIyEr-H9XW",
    "outputId": "1107d27d-4519-4218-a143-ee30008a1304"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "4REb08ykI8pH",
    "outputId": "417a6e8f-fea0-4469-c0a0-f662571b0d6a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "def plot_mnist_image(image_array):\n",
    "    image = image_array.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "plot_mnist_image(data[3, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG-IID2ZJCar",
    "outputId": "c24847d0-bded-4654-fbe0-185668455aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "m, n = data.shape\n",
    "print(m,n)\n",
    "# m is the number of training examples, n is the number of features + 1 (Y column)\n",
    "# m is # of rows, n is the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvDjeD2UPxZm",
    "outputId": "f3934e4b-64fe-45f5-c423-3c4e35fd496a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data) # Shuffles all the individual rows\n",
    "data_dev = data[0:1000].T #Take the first 1000 rows, and transpose the matrix to get 1000 examples as column vectors\n",
    "data_dev.shape\n",
    "# 1000 x 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxP2oNOjmy4k",
    "outputId": "18515c55-9a29-475d-da22-b2b7d01de611",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev = data_dev[0] #Takes the first row, which contains all of the answers to the numbers (the Y is what we want)\n",
    "Y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWeKiAlsm1oF",
    "outputId": "943393de-eb67-4bd3-ce8d-b5dd3e45741e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev = data_dev[1:] # Takes all of the data corresponding to all of the entries (the X values)\n",
    "X_dev = X_dev / 255. # Normalization\n",
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFJGdfIkSkP6",
    "outputId": "d5f61668-03f2-4afd-9361-b018e7bbc062",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        25, 132, 161, 253, 172,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  26, 211, 252, 252, 252, 252, 105,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  37, 160, 252, 252, 252, 242, 216,  76,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  81, 253, 252, 252, 252, 212,  60,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 207, 253, 252, 252, 241,  89,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  63, 125, 250, 250, 180, 105,  48,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  29, 229, 252, 252, 143,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  85, 252, 252, 252,  75,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 175, 237, 252, 153,\n",
       "        23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 221, 252,\n",
       "       206,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  90, 161,\n",
       "       253, 253, 253, 143, 132, 255, 253, 236,  52,   4,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n",
       "       217, 252, 252, 252, 252, 252, 252, 253, 252, 252, 252,  72,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  14, 200, 252, 252, 252, 252, 236, 216,  96, 108, 238, 252,\n",
       "       146,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  25, 225, 252, 252, 236, 101,  48,   0,   0,  17,\n",
       "       221, 252, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  37, 252, 252, 235,  70,   0,   0,   0,\n",
       "         0, 111, 252, 252,  72,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  37, 252, 252, 235, 193,  90,\n",
       "        73,  73, 194, 227, 252, 215,  17,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 134, 252, 252, 252,\n",
       "       252, 252, 252, 252, 253, 252, 240,  79,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10, 193, 252,\n",
       "       183, 183, 252, 252, 252, 252, 249, 144,  31,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14,\n",
       "       211, 252,  72,   7,  23,  23,  81,  23,  22,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  42, 252, 244, 115,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[1000:m].T\n",
    "data_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3k210Xo9ooen"
   },
   "outputs": [],
   "source": [
    "Y_train = data_train[0] #Takes the first row, which contains all of the answers to the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wCnPsdqxotp0"
   },
   "outputs": [],
   "source": [
    "X_train= data_train[1:n] #Takes all of the data corresponding to all of the entries\n",
    "X_train\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "n_TnFSWzUOdz"
   },
   "outputs": [],
   "source": [
    "# Functionalities\n",
    "def params(batch_size):\n",
    "  W1 = np.random.rand(15, 784) - 0.5\n",
    "  b1 = np.random.rand(15, batch_size) - 0.5\n",
    "  W2 = np.random.rand(10, 15) - 0.5\n",
    "  b2 = np.random.rand(10, batch_size) - 0.5\n",
    "  return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z): # Takes in a scalar, returns a scalar\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    # Apply softmax column-wise\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0))  # Subtracting the maximum value in each column to avoid overflow\n",
    "    return exp_Z / np.sum(exp_Z, axis=0)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X, batch_size):\n",
    "    Z1 = W1.dot(X) + b1 # (10 x784) (784 x n) + (10 x n) -> (10 x n)\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2 # (10 x 10) (10 x n) + (10 x n) = (10 x n)\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def der_ReLU(Z):\n",
    "  return Z > 0\n",
    "\n",
    "def create(Y): # Passing in a 1 x 41000 matrix (41000 columns, 1 row)\n",
    "  mat_Y = np.zeros((Y.size, 10)) # 41000 x 10\n",
    "  mat_Y[np.arange(Y.size), Y] = 1 # array([    0,     1,     2, ..., 40997, 40998, 40999]), then indexing the Y values aswell at each column, changing that value to 1\n",
    "  mat_Y = mat_Y.T # 10 x 41000\n",
    "  return mat_Y\n",
    "\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W1, W2, X, Y, batch_size):\n",
    "  mat_Y = create(Y)\n",
    "  dZ2 = (1/batch_size) * (A2 - mat_Y) # 10 x 41000 - - - Back propogation eq. #1\n",
    "  dW2 = dZ2.dot(A1.T) # (10 x 41000) (41000 x 10) -> (10 x 10) - - - Back propogation eq. #4\n",
    "  db2 = np.sum(dZ2) # scalar  - - - Back propogation eq. #3\n",
    "  dZ1 = (1/batch_size) * (W2.T.dot(dZ2) * der_ReLU(Z1)) # (10 x 10) (10 x 41000) * elementwise (1 or 0) Back propogation eq. #2\n",
    "  dW1=  dZ1.dot(X.T) # (10 x 41000) (41000 x 784) -> (10 x 784) - - - Back propogation eq. #4\n",
    "  db1 = np.sum(dZ1) #scalar - - - Back propogation eq. #3\n",
    "  return dW1, db1, dW2, db2\n",
    "\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "  W1 = W1 - alpha * dW1\n",
    "  b1 = b1 - alpha * db1\n",
    "  W2 = W2 - alpha * dW2\n",
    "  b2 = b2 - alpha * db2\n",
    "  return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  # print(predictions)\n",
    "  # print(Y)\n",
    "  return np.sum(predictions == Y) / Y.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FWQAzUy_kK3l"
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, epochs, alpha, batch_size):\n",
    "    W1, b1, W2, b2 = params(batch_size)\n",
    "    num_examples = X.shape[1]\n",
    "\n",
    "    for i in range(epochs):\n",
    "        permuted_indices = np.random.permutation(num_examples)\n",
    "        X_shuffled = X[:, permuted_indices]\n",
    "        Y_shuffled = Y[permuted_indices]\n",
    "\n",
    "        for j in range(0, num_examples, batch_size):\n",
    "            X_batch = X_shuffled[:, j:j + batch_size]\n",
    "            Y_batch = Y_shuffled[j:j + batch_size]\n",
    "\n",
    "            Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_batch, batch_size)\n",
    "            dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W1, W2, X_batch, Y_batch, batch_size)\n",
    "            W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "\n",
    "        # Print epoch and accuracy formatted nicely\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_batch, batch_size)\n",
    "        accuracy = get_accuracy(get_predictions(A2), Y_batch)\n",
    "        print(f\"Epoch: {i:<5} | Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfYy_XctvU87",
    "outputId": "1dbd0a79-0e61-488e-9020-1e6ee3d70e28",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0     | Accuracy: 0.50\n",
      "Epoch: 1     | Accuracy: 0.56\n",
      "Epoch: 2     | Accuracy: 0.55\n",
      "Epoch: 3     | Accuracy: 0.57\n",
      "Epoch: 4     | Accuracy: 0.58\n",
      "Epoch: 5     | Accuracy: 0.62\n",
      "Epoch: 6     | Accuracy: 0.62\n",
      "Epoch: 7     | Accuracy: 0.65\n",
      "Epoch: 8     | Accuracy: 0.73\n",
      "Epoch: 9     | Accuracy: 0.70\n",
      "Epoch: 10    | Accuracy: 0.76\n",
      "Epoch: 11    | Accuracy: 0.67\n",
      "Epoch: 12    | Accuracy: 0.83\n",
      "Epoch: 13    | Accuracy: 0.80\n",
      "Epoch: 14    | Accuracy: 0.77\n",
      "Epoch: 15    | Accuracy: 0.74\n",
      "Epoch: 16    | Accuracy: 0.76\n",
      "Epoch: 17    | Accuracy: 0.75\n",
      "Epoch: 18    | Accuracy: 0.80\n",
      "Epoch: 19    | Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = stochastic_gradient_descent(X_train, Y_train, 20, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "shhDA3BmvqiP",
    "outputId": "36eeab71-c65b-4c70-a1ad-ef36f072fef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[4 4 2 6 7 5 3 4 1 1 9 0 3 3 3 2 5 0 9 4 9 9 5 2 0 5 1 1 8 7 3 2 4 0 4 2 1\n",
      " 1 3 3 0 0 2 3 4 6 8 7 4 3 2 0 8 7 7 5 4 3 7 0 4 5 4 0 0 1 1 8 2 9 0 3 3 0\n",
      " 4 1 3 7 1 2 0 0 2 7 7 0 3 7 2 6 2 4 4 7 3 3 4 5 3 1]\n",
      "Correct labels:\n",
      "[4 4 9 6 7 5 8 9 1 1 4 0 3 3 3 2 5 0 4 4 9 9 5 2 0 5 1 1 8 2 3 2 4 0 9 3 1\n",
      " 1 3 3 0 0 2 3 4 6 8 7 4 3 2 0 4 7 7 5 4 3 6 0 4 3 4 0 7 1 1 8 2 4 7 3 3 0\n",
      " 6 1 3 7 1 2 0 1 2 7 7 0 3 7 5 6 2 9 7 7 7 5 4 8 3 4]\n",
      "Accuracy: 77.0 %\n"
     ]
    }
   ],
   "source": [
    "# Testing our model:\n",
    "\n",
    "# Create batch from unseen data\n",
    "training_example = X_dev[:,100:200]\n",
    "Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, training_example, batch_size = 1)\n",
    "predictions = get_predictions (A2)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)\n",
    "print(\"Correct labels:\")\n",
    "print(Y_dev[100:200])\n",
    "\n",
    "print(\"Accuracy:\", get_accuracy(Y_dev[100:200], predictions) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZjaNbHcxiz7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
