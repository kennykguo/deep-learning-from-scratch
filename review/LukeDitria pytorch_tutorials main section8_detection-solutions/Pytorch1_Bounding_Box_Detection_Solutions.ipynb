{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sb01NHS5PMS8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "import torchvision.models as models\n",
    "\n",
    "# You'll need to install albumentations!\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image, ImageOps\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "from Trainer import ModelTrainer\n",
    "\n",
    "from Datasets import CUB200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUaeH517PMS_"
   },
   "outputs": [],
   "source": [
    "# The size of our mini batches\n",
    "batch_size = 64\n",
    "\n",
    "# How many itterations of our dataset\n",
    "num_epochs = 50\n",
    "\n",
    "# Optimizer learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# You'll need to Download Dataset found here\n",
    "# https://www.kaggle.com/datasets/wenewone/cub2002011\n",
    "# Unzip and rename to cub_200\n",
    "# Where to load/save the dataset from \n",
    "data_set_root = \"../../datasets/cub_200\"\n",
    "\n",
    "# What to resize our images to \n",
    "image_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVGVcxx0PMTB"
   },
   "outputs": [],
   "source": [
    "start_from_checkpoint = False\n",
    "\n",
    "save_dir = '../data/Models'\n",
    "model_name = 'ResNet34_CUB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRJXAwTXPMTD"
   },
   "outputs": [],
   "source": [
    "# Set device to GPU_indx if GPU is avaliable\n",
    "gpu_indx = 0\n",
    "device = torch.device(gpu_indx if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "keIwAFK-PMTG"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([A.SmallestMaxSize(max_size=image_size),\n",
    "                             A.RandomCrop(height=image_size, width=image_size),\n",
    "                             A.HorizontalFlip(p=0.5),\n",
    "                             A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "                             A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n",
    "                             A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "                             A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225]),\n",
    "                            ToTensorV2()], \n",
    "                            bbox_params=A.BboxParams(format='coco',\n",
    "                                                     min_area=0, min_visibility=0.0, \n",
    "                                                     label_fields=['class_labels']))\n",
    "\n",
    "transform = A.Compose([A.SmallestMaxSize(max_size=image_size),\n",
    "                       A.RandomCrop(height=image_size, width=image_size),\n",
    "                       A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225]),\n",
    "                       ToTensorV2()], \n",
    "                      bbox_params=A.BboxParams(format='coco',\n",
    "                                               min_area=0, min_visibility=0.0, \n",
    "                                               label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection over Union (IoU)\n",
    "To train our model to correctly predict the bounding box we're going to use logistic regression. However to calulate the performance of our model (and the accuracy of the predicted bounding boxes) we're going to use the [Intersection over Union](https://medium.com/analytics-vidhya/iou-intersection-over-union-705a39e7acef) metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module class that will return the IoU for a batch of outputs\n",
    "class BboxIOU(nn.Module):\n",
    "    \n",
    "    def xyhw_to_xyxy(self, bbox):\n",
    "        \"\"\"\n",
    "        Converts from (x_min, y_min, width, height) to (x_min, y_min, x_max, y_max) format\n",
    "        \"\"\"\n",
    "        new_bbox = torch.cat((bbox[:, 0:1], \n",
    "                              bbox[:, 1:2],\n",
    "                              bbox[:, 2:3] + bbox[:, 0:1], \n",
    "                              bbox[:, 3:4] + bbox[:, 1:2]), 1)\n",
    "        return new_bbox\n",
    "\n",
    "    def bb_intersection_over_union(self, pred_xyhw, target_xyhw):\n",
    "        pred_xyxy = self.xyhw_to_xyxy(pred_xyhw)\n",
    "        target_xyxy = self.xyhw_to_xyxy(target_xyhw)\n",
    "\n",
    "        # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "        xA = torch.cat((pred_xyxy[:, 0:1], target_xyxy[:, 0:1]), 1).max(dim=1)[0].unsqueeze(1)\n",
    "        yA = torch.cat((pred_xyxy[:, 1:2], target_xyxy[:, 1:2]), 1).max(dim=1)[0].unsqueeze(1)\n",
    "        xB = torch.cat((pred_xyxy[:, 2:3], target_xyxy[:, 2:3]), 1).min(dim=1)[0].unsqueeze(1)\n",
    "        yB = torch.cat((pred_xyxy[:, 3:4], target_xyxy[:, 3:4]), 1).min(dim=1)[0].unsqueeze(1)\n",
    "\n",
    "        # Compute the area of intersection rectangle\n",
    "        x_len = F.relu(xB - xA)\n",
    "        y_len = F.relu(yB - yA)\n",
    "        # Negative area means no overlap\n",
    "        interArea = x_len * y_len\n",
    "\n",
    "        # If you don't have xyhw values, calculate areas like this\n",
    "#         w1 = (pred_xyxy[:, 0:1] - pred_xyxy[:, 2:3]).abs()\n",
    "#         h1 = (pred_xyxy[:, 1:2] - pred_xyxy[:, 3:4]).abs()\n",
    "\n",
    "#         w2 = (target_xyxy[:, 0:1] - target_xyxy[:, 2:3]).abs()\n",
    "#         h2 = (target_xyxy[:, 1:2] - target_xyxy[:, 3:4]).abs()\n",
    "\n",
    "#         area1 = w1 * h1\n",
    "#         area2 = w2 * h2\n",
    "\n",
    "        area1 = pred_xyhw[:, 2:3] * pred_xyhw[:, 3:4]\n",
    "        area2 = target_xyhw[:, 2:3] * target_xyhw[:, 3:4]\n",
    "\n",
    "        # Compute the intersection over union by taking the intersection\n",
    "        # area and dividing it by the sum of prediction + ground-truth\n",
    "        # areas - the interesection area\n",
    "        iou = interArea / (area1 + area2 - interArea + 1e-5)\n",
    "\n",
    "        # Return the intersection over union value\n",
    "        return iou\n",
    "\n",
    "    def forward(self, predictions, data):\n",
    "        \"\"\"\n",
    "        data: list of data, index 0 is the input image index [0] is the target\n",
    "        predictions: raw output of the model, the first 4 outputs are assumed to be the bounding box values\n",
    "        \"\"\"\n",
    "        \n",
    "        pred_bbox = torch.sigmoid(predictions[:, :4])\n",
    "        target_bbox = data[1].to(pred_bbox.device)\n",
    "        \n",
    "        return self.bb_intersection_over_union(pred_bbox, target_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7L2lrkdPMTM"
   },
   "source": [
    "# Create the training, testing and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29503,
     "status": "ok",
     "timestamp": 1568947936500,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "5FyAAqHWPMTM",
    "outputId": "d566a865-6439-47d3-a195-6b897199d923"
   },
   "outputs": [],
   "source": [
    "# Define our Datasets\n",
    "# You'll need to download the dataset from Kaggle\n",
    "# https://www.kaggle.com/datasets/wenewone/cub2002011\n",
    "# Unzip it (and the directories it contains) into the datasets directory \n",
    "# and rename the top-level directory cub_200\n",
    "\n",
    "train_data = CUB200(data_set_root, image_size=image_size, \n",
    "                    transform=train_transform, test_train=0)\n",
    "\n",
    "test_data = CUB200(data_set_root, image_size=image_size, \n",
    "                   transform=transform, test_train=1)\n",
    "\n",
    "# Split trainging data into train and validation set with 90/10% traning/validation split\n",
    "validation_split = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data)*validation_split)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [n_train_examples, n_valid_examples],\n",
    "                                                       generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGdAgnKgPMTc"
   },
   "source": [
    "# Create the Pretrained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34657,
     "status": "ok",
     "timestamp": 1568947941813,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "JQPwhQuaPMTd",
    "outputId": "000d7dfc-5cd1-4afc-ef52-d7c1c7cc2754"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the ResNet34 Model\n",
    "# res_net = models.resnet34(pretrained=True)\n",
    "# or\n",
    "res_net = models.resnet34(weights=\"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer(model=res_net.to(device), output_size=4, device=device, \n",
    "                             loss_fun=nn.BCEWithLogitsLoss(), batch_size=batch_size, \n",
    "                             learning_rate=learning_rate, save_dir=save_dir, model_name=model_name,\n",
    "                             eval_metric=BboxIOU(), start_from_checkpoint=start_from_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.set_data(train_set=train_data, test_set=test_data, val_set=valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Learning Rate Scheduler\n",
    "We can dynamically change the <a href=\"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\">learning rate</a> during training to help our model converge to a better minimum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.set_lr_schedule(optim.lr_scheduler.StepLR(model_trainer.optimizer, \n",
    "                                                        step_size=1, \n",
    "                                                        gamma=0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30371,
     "status": "ok",
     "timestamp": 1568947937416,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "2ET6pMrYPMTa",
    "outputId": "9131cd8c-eab1-4a66-d4fc-1314ae775814"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "images, bbox, labels = next(iter(model_trainer.test_loader))\n",
    "out = torchvision.utils.make_grid(images, normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_indx = 3\n",
    "ex_img = images[example_indx]\n",
    "\n",
    "# The bounding box is represented in the (x_min, y_min, width, height) format\n",
    "# aka the coordinate of the top left corner of the box and the box height and width\n",
    "\n",
    "# draw_bounding_boxes expects it in the (x_min, y_min, x_max, y_max) formatweights=ResNet18_Weights.IMAGENET1K_V1\n",
    "# aka the coordinates of the top left and bottom right corners of the box\n",
    "ex_label = bbox[example_indx].unsqueeze(0) * image_size\n",
    "ex_label[:, 2] += ex_label[:, 0]\n",
    "ex_label[:, 3] += ex_label[:, 1]\n",
    "\n",
    "img_out = (((ex_img - ex_img.min())/(ex_img.max() - ex_img.min())) * 255).to(torch.uint8)\n",
    "img_box = torchvision.utils.draw_bounding_boxes(img_out, ex_label, colors=(0, 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "out = torchvision.utils.make_grid(img_box.unsqueeze(0).float(), normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how many Parameter's our Model has!\n",
    "num_params = 0\n",
    "for param in model_trainer.model.parameters():\n",
    "    num_params += param.flatten().shape[0]\n",
    "print(\"This model has %d (approximately %d Million) Parameters!\" % (num_params, num_params//1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model!\n",
    "Our full training method is now fully contained within the trainner class! Simply run the run_training method and specify how many epochs it should train for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1568948678396,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "K27MEsO5PMT-",
    "outputId": "0c03f2f2-e250-4fad-dae5-b0dbaad8bda4"
   },
   "outputs": [],
   "source": [
    "model_trainer.run_training(num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The highest validation IoU was %.2f\" %(model_trainer.best_valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1568948455980,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "HoLp_P3xPMUE",
    "outputId": "b241900f-ff45-42f0-dc33-14b48126836f"
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10,5))\n",
    "train_x = np.linspace(0, num_epochs, len(model_trainer.train_loss_logger))\n",
    "_ = plt.plot(train_x, model_trainer.train_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an image to test\n",
    "example_indx = 50\n",
    "ex_img = images[example_indx]\n",
    "img_out = (((ex_img - ex_img.min())/(ex_img.max() - ex_img.min())) * 255).to(torch.uint8)\n",
    "\n",
    "real_label = bbox[example_indx].unsqueeze(0) * image_size\n",
    "real_label[:, 2] += real_label[:, 0]\n",
    "real_label[:, 3] += real_label[:, 1]\n",
    "\n",
    "# Get the model's prediction for the Bounding Box\n",
    "model_trainer.eval()\n",
    "with torch.no_grad():\n",
    "    pred_out = torch.sigmoid(model_trainer(ex_img.unsqueeze(0).to(device)))\n",
    "    pred_label = (pred_out * image_size).cpu()\n",
    "    pred_label[:, 2] += pred_label[:, 0]\n",
    "    pred_label[:, 3] += pred_label[:, 1]\n",
    "    \n",
    "# Draw the box on the image\n",
    "img_box = torchvision.utils.draw_bounding_boxes(img_out, real_label, colors=(0, 255, 0))\n",
    "img_box = torchvision.utils.draw_bounding_boxes(img_box, pred_label, colors=(255, 0, 0))\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "out = torchvision.utils.make_grid(img_box.unsqueeze(0).float(), normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10,5))\n",
    "train_x = np.linspace(0, num_epochs, len(model_trainer.train_acc_logger))\n",
    "_ = plt.plot(train_x, model_trainer.train_acc_logger, c = \"y\")\n",
    "valid_x = np.linspace(0, num_epochs, len(model_trainer.val_acc_logger))\n",
    "_ = plt.plot(valid_x, model_trainer.val_acc_logger, c = \"k\")\n",
    "\n",
    "_ = plt.title(\"Average IoU\")\n",
    "_ = plt.legend([\"Training IoU\", \"Validation IoU\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_F2Qy9WPMUG"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1568948469315,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "dKMx57tEPMUH",
    "outputId": "7590031a-2a9e-4701-9799-320155e5efd6"
   },
   "outputs": [],
   "source": [
    "# Call the evaluate function and pass the evaluation/test dataloader etc\n",
    "test_acc = model_trainer.evaluate_model(train_test_val=\"test\")\n",
    "print(\"The Test Average IoU is: %.2f\" %(test_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet18_STL10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
