{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kmeans Clustering</h1>\n",
    "<img src=\"../data/K_means.gif\" width=\"1000\" align=\"center\">\n",
    "With our knowledge of Python and now Numpy lets create an implementation of a famous machine learning algorithm \"K-Means Clustering\". The job of a clustering algorithm is to break a dataset into some number of \"clusters\" (groups), the number of clusters usually defined by the user. K-Means clustering works by iteratively updating a pre-defined number of cluster centers. It does this by finding the distance between each datapoint and every cluster center. Datapoints are then assigned to the cluster center they are closest to and each cluster center is updated to be the mean of the new cluster. These steps are repeated for some number of steps or until the cluster centers converge (they stop moving so much).<br>\n",
    "\n",
    "[For more Information on K-means](https://en.wikipedia.org/wiki/K-means_clustering)<br>\n",
    "\n",
    "<b>Lets have a look at the steps of K-means clustering</b><br>\n",
    "1. Define the number of clusters \"k\" you want to group your data into<br>\n",
    "2. Randomly initialise k vectors with the same size as each datapoint, this is the initialisation of our cluster centers<br>\n",
    "3. Calculate the distance between each datapoint and each cluster center (using MSE or equivalent)<br>\n",
    "4. For every datapoint find the cluster center they are closest to<br>\n",
    "5. Re-calculate the cluster centers by finding the mean of every new cluster<br>\n",
    "6. Repeat steps 3-5 for n steps or until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np               \n",
    "import time\n",
    "\n",
    "# Custom module to deal with downloading the dataset\n",
    "from load import test_x\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using the module \"load\" that comes with this notebook, lets load our dataset</b><br>\n",
    "The dataset we'll be using is the MNIST dataset, a dataset of small, low-res handwritten digits. There are 60000 training images and 10000 test images divided up into 10 classes (digits 0-9). Here we will be using the test set (as it's a smaller set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of datapoint\n",
    "num_img = 10000  \n",
    "# Number of cluster centers, 10 because the dataset contains 10 classes eg: digit 0 to 9\n",
    "num_means = 10   \n",
    "# We'll perform this many iterations of the algorithm\n",
    "iterations = 100\n",
    "# Each image is 28*28 pixels, which has been flattened to a vector 0f 784 values\n",
    "data_size = 28*28\n",
    "# The images are 8 bit greyscale images (values range from 0-255)\n",
    "# We'll rescale the pixel values to be between 0-1 (We don't REALLY need to do this for k-means)\n",
    "test_x = (test_x.astype(float) / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Kmeans Initialization </h3>\n",
    "Here we'll initialise the cluster centers to random values by randomly sampling 10 points from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate K indicies for k datapoints from the dataset (indicies need to be int)\n",
    "means  = test_x[np.random.randint(0, num_img , num_means)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lets visualise the random means!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10, 20))\n",
    "_ = plt.imshow(means.reshape(num_means, 28, 28).transpose((1, 0, 2)).reshape(28, num_means*28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Kmeans Algorithm </h3>\n",
    "Now implement the main steps of the K-Means clustering algorithm! Try and make it as efficient as possible and minimise the time/iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Initialise a vector that wil contain the the cluster index for each datapoint\n",
    "cluster_index = np.zeros(num_img)\n",
    "\n",
    "for i in trange(iterations, leave=False): \n",
    "# Implement a step of k-means clustering\n",
    "    # For every datapoint find the cluster center that it is closest to and log it in cluster_index\n",
    "    for j in range(num_img):\n",
    "        # Init a list to store the distance from the datapoint to each cluster center\n",
    "        dist_to_center = []\n",
    "        # Calculate the distance from the datapoint to each cluster center and store it in the list\n",
    "        for k in range(num_means):\n",
    "            dist = np.mean((test_x[j, :] - means[k, :])**2)\n",
    "            dist_to_center.append(dist)\n",
    "        # Find the index of the cluster center with the smallest distance to the datapoint and store it\n",
    "        cluster_index[j] = np.argmin(dist_to_center)\n",
    "\n",
    "# Updating the cluster center positions\n",
    "    # For every cluster find the new mean (new cluster center)\n",
    "    for o in trange(num_means, leave=False):\n",
    "        # initialise a counter of the number of points in the cluster\n",
    "        count = 0\n",
    "        # init a sum of the datapoints in the cluster\n",
    "        cluster_sum = 0\n",
    "        # Find all the datapoints in the cluster and sum them together \n",
    "        # and keep track of the number of datapoints in the cluster\n",
    "        for p in range(num_img):\n",
    "            if cluster_index[p] == o:\n",
    "                count+=1\n",
    "                cluster_sum+=test_x[p,:]\n",
    "        # Find the new mean of the cluster\n",
    "        if count > 0:\n",
    "            means[o, :] = cluster_sum/count\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"%d iterations took %.2f seconds, which corresponds to %.2fs/iteration\" % (iterations, end_time - start_time, (end_time - start_time)/iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lets visualise the the cluster centers!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20, 10))\n",
    "img = means.reshape(num_means, 28, 28).transpose((1, 0, 2)).reshape(28, num_means*28)\n",
    "_ = plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
