{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kmeans Clustering</h1>\n",
    "<img src=\"../data/K_means.gif\" width=\"1000\" align=\"center\">\n",
    "With our knowledge of Python and now Numpy lets create an implementation of a famous machine learning algorithm \"K-Means Clustering\". The job of a clustering algorithm is to break a dataset into some number of \"clusters\" (groups), the number of clusters usually defined by the user. K-Means clustering working by iteratively updating  a pre-defined number of cluster centers. It does this by finding the distance between each datapoint and every cluster center. Datapoints are then assigned to the cluster center they are closest to and each cluster center is updated to be the mean of the new cluster. These steps are updated for some number of steps or until the cluster centers converge (they stop moving so much)<br>\n",
    "<b>Lets have a look at the steps of K-means clustering</b><br>\n",
    "1. Define the number of clusters \"k\" you want to group your data into<br>\n",
    "2. Randomly initialise k vectors with the same size as each datapoint, this is the initialisation of our cluster centers<br>\n",
    "3. Calculate the distance between each datapoint and each cluster center (using MSE or equivalent)<br>\n",
    "4. For every datapoint find the cluster center they are closest to<br>\n",
    "5. Re-calculate the cluster centers by finding the mean of every new cluster<br>\n",
    "6. Repeat steps 3-6 for n steps or until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np     \n",
    "import torch\n",
    "from load import test_x\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using the module \"load\" that comes with this notebook, lets load our dataset</b><br>\n",
    "The dataset we'll be using is the MNIST dataset, a dataset of small, low-res handwritten digits. There are 60000 training images and 10000 test images divided up into 10 classes (digits 0-9). Here we will be using the test set (as it's a smaller set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sneak peak at using GPUs for computation! (Will only work if you have a cuda enabled GPU)\n",
    "# device = \"cpu\"\n",
    "gpu_indx = 0\n",
    "device = torch.device(gpu_indx if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"cuda or cpu?:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of datapoint\n",
    "num_img = 10000  \n",
    "# Number of cluster centers, 10 because the dataset contains 10 classes eg: digit 0 to 9\n",
    "num_means = 10   \n",
    "# We'll perform this many iterations of the algorithm\n",
    "iterations = 100\n",
    "# Each image is 28*28 pixels, which has been flattened to a vector 0f 784 values\n",
    "data_size = 28*28\n",
    "# The images are 8 bit greyscale images (values range from 0-255)\n",
    "# We'll rescale the pixel values to be between 0-1 (We don't REALLY need to do this for k-means)\n",
    "test_x_tensor = torch.FloatTensor((test_x.astype(float) / 255)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Kmeans Initialization </h3>\n",
    "Here we'll initialise the cluster centers to random values by creating a 10*784 matrix (2D Tensor) by randomly sampling 10 points from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate K indicies for k datapoints from the dataset (indicies need to be int)\n",
    "means = test_x_tensor[np.random.randint(0, num_img , num_means)]\n",
    "eye_mat = torch.eye(num_means, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initial operation to initialize Pytorch\n",
    "means = torch.mm(eye_mat, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20, 10))\n",
    "img = means.cpu().float().numpy().reshape(num_means, 28, 28).transpose((1, 0, 2)).reshape(28, num_means*28)\n",
    "_ = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Kmeans Algorithm </h3>\n",
    "Now implement the main steps of the K-Means clustering algorithm! Try and make it as efficient as possible and minimise the time/iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for i in trange(iterations):\n",
    "        # Add on a dimension in the right place and use broadcasting to find the differences\n",
    "        diff_from_means = means.unsqueeze(0) - test_x_tensor.unsqueeze(1)\n",
    "\n",
    "        # Using absolute sum of differences here\n",
    "        dist_to_means = diff_from_means.pow(2).mean(2)\n",
    "\n",
    "        # Expand dims is anther way to add a dimension\n",
    "        indx_of_means = dist_to_means.argmin(1)\n",
    "\n",
    "        # Create a one hot coded vector per datapoint\n",
    "        a = eye_mat[indx_of_means].t()\n",
    "        # Multiply to get the sums of each cluster then divide by elements per cluster to get means\n",
    "        means = torch.mm(a, test_x_tensor) / a.sum(1, keepdims=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"%d iterations took %.2f seconds, which corresponds to %.4fs/iteration\" % (iterations, end_time - start_time, (end_time - start_time)/iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lets visualise the the cluster centers!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20, 10))\n",
    "img = means.cpu().float().numpy().reshape(num_means, 28, 28).transpose((1, 0, 2)).reshape(28, num_means*28)\n",
    "_ = plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
