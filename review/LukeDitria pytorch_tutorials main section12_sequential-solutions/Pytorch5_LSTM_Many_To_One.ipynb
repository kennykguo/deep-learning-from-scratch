{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947e1a34",
   "metadata": {},
   "source": [
    "# MNIST LSTM Classifier\n",
    "## Treating an image as a sequence, with a Many-To-One Method\n",
    "In this Notebook we see how we can use an LSTM as a many to one model that takes in a sequence of data and provides a single output at the end of the sequence.<br>\n",
    "As an example we use the MNIST dataset and \"patchify\" it, splitting the image into a sequence of patches and passing them to the model one patch at a time.\n",
    "\n",
    "[<img src=\"https://static.packt-cdn.com/products/9781789346640/graphics/assets/79db1776-f471-4fe6-89b0-67cbae844bfc.png\">](LSTM)\n",
    "<br>\n",
    "[Corresponding Tutorial Video](https://youtu.be/lyUT6dOARGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torchvision\n",
    "\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3701b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of our mini batches\n",
    "batch_size = 128\n",
    "\n",
    "# How many itterations of our dataset\n",
    "num_epochs = 50\n",
    "\n",
    "# Optimizer learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Where to load/save the dataset from \n",
    "data_set_root = \"../../datasets\"\n",
    "\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84543d9",
   "metadata": {},
   "source": [
    "## Create MNIST Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0551906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a composition of transforms\n",
    "# transforms.Compose will perform the transforms in order\n",
    "# NOTE: some transform only take in a PIL image, others only a Tensor\n",
    "# EG Resize and ToTensor take in a PIL Image, Normalize takes in a Tensor\n",
    "# Refer to documentation\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.1307], [0.308])])\n",
    "\n",
    "# Note: ToTensor() will scale unit8 and similar type data to a float and re-scale to 0-1\n",
    "# Note: We are normalizing with the dataset mean and std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99255cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our MNIST Datasets\n",
    "# Can also try with CIFAR10 Dataset\n",
    "# https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n",
    "train_data = datasets.MNIST(data_set_root, train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(data_set_root, train=False, download=True, transform=transform)\n",
    "\n",
    "# We are going to split the test dataset into a train and validation set 90%/10%\n",
    "validation_split = 0.9\n",
    "\n",
    "# Determine the number of samples for each split\n",
    "n_train_examples = int(len(train_data) * validation_split)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "# The function random_split will take our dataset and split it randomly and give us dataset\n",
    "# that are the sizes we gave it\n",
    "# Note: we can split it into to more then two pieces!\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [n_train_examples, n_valid_examples],\n",
    "                                                       generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# IMPORTANT TO KNOW!!!!!!!!!\n",
    "# Here we pass the random_split function a manual seed, this is very important as if we did not do this then \n",
    "# everytime we randomly split our training and validation set we would get different splits!!!\n",
    "# For example if we saved our model and reloaded it in the future to train some more, the dataset that we now use to\n",
    "# train with will undoubtably contain datapoints that WERE in the validation set initially!!\n",
    "# Our model would therefore be trained with both validation and training data -- very bad!!!\n",
    "# Setting the manual seed to the same value everytime prevents this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed759ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training, Validation and Evaluation/Test Datasets\n",
    "# It is best practice to separate your data into these three Datasets\n",
    "# Though depending on your task you may only need Training + Evaluation/Test or maybe only a Training set\n",
    "# (It also depends on how much data you have)\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataloader\n",
    "train_loader = dataloader.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = dataloader.DataLoader(valid_data, batch_size=batch_size)\n",
    "test_loader  = dataloader.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to turn a batch of images into a sequence of patches\n",
    "\n",
    "def extract_patches(image_tensor, patch_size=8):\n",
    "    # Get the dimensions of the image tensor\n",
    "    bs, c, h, w = image_tensor.size()\n",
    "    \n",
    "    # Define the Unfold layer with appropriate parameters\n",
    "    unfold = torch.nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    # Apply Unfold to the image tensor\n",
    "    unfolded = unfold(image_tensor)\n",
    "    \n",
    "    # Reshape the unfolded tensor to match the desired output shape\n",
    "    # Output shape: BSxLxCx8x8, where L is the number of patches in each dimension\n",
    "    # For each dimension, number of patches = (original dimension size) // patch_size\n",
    "    unfolded = unfolded.transpose(1, 2).reshape(bs, -1, c, patch_size, patch_size)\n",
    "    \n",
    "    return unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader itterable object\n",
    "dataiter = next(iter(test_loader))\n",
    "# Sample from the itterable object\n",
    "test_images, test_labels = dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise an entire batch of images!\n",
    "plt.figure(figsize = (20,10))\n",
    "out = torchvision.utils.make_grid(test_images[:8], 8, normalize=True, pad_value=0.5)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea215a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the patch size for extraction\n",
    "patch_size = 4\n",
    "\n",
    "# Extract patches from the test images using the defined function\n",
    "patches = extract_patches(test_images, patch_size=patch_size)\n",
    "\n",
    "# Calculate the grid size for visualization\n",
    "grid_size = test_images.shape[2] // patch_size\n",
    "print(\"Sequence Length %d\" % (grid_size**2))\n",
    "\n",
    "# Visualize the patches as a grid\n",
    "plt.figure(figsize=(5, 5))\n",
    "out = torchvision.utils.make_grid(patches[0], grid_size, normalize=True, pad_value=0.5)\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08d5ed",
   "metadata": {},
   "source": [
    "## Create Image Patch LSTM\n",
    "This model uses an LSTM network for sequential image data processing. It divides input images into patches and then feeds them into the LSTM layer for sequential analysis. Residual blocks are incorporated within the LSTM to enhance gradient flow and capture temporal dependencies. Finally, the output is passed through a fully connected layer for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a residual block for MLP architecture\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        # Define layer normalization for input size\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(input_size, input_size//2)\n",
    "        \n",
    "        # Layer normalization for input size // 2\n",
    "        self.norm2 = nn.LayerNorm(input_size//2)\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(input_size//2, output_size)\n",
    "        \n",
    "        # Final fully connected layer\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply layer normalization and activation function\n",
    "        x = self.act(self.norm1(x))\n",
    "        # Calculate skip connection\n",
    "        skip = self.fc3(x)\n",
    "        \n",
    "        # Apply layer normalization, fully connected layer, and activation function\n",
    "        x = self.act(self.norm2(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Add skip connection\n",
    "        return x + skip\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, output_size=10, patch_size=4, lstm_layers=1, hidden_size=64, num_blocks=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Define a fully connected layer for input data\n",
    "        self.fc_in = nn.Linear(patch_size**2, hidden_size)\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, \n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "              \n",
    "        # Define residual blocks\n",
    "        blocks = [ResBlockMLP(hidden_size, hidden_size) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        # Define the output fully connected layer\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.ELU()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, input_data, hidden_in, mem_in):\n",
    "        # Turn the images into a sequence of patches which will be passed to the model one at a time\n",
    "        bs, c, h, w = input_data.shape\n",
    "        input_seq = extract_patches(input_data, self.patch_size).reshape(bs, -1, self.patch_size**2)\n",
    "\n",
    "        # A linear layer will process the patches independently like a batch\n",
    "        x = self.act(self.fc_in(input_seq))\n",
    "        \n",
    "        # The LSTM will process the sequence of patches sequentially\n",
    "        output, (hidden_out, mem_out) = self.lstm(x, (hidden_in, mem_in))\n",
    "        \n",
    "        # We'll get an output from the model from every time-step but we'll only calculate the loss at\n",
    "        # the last timestep\n",
    "        x  = self.act(self.res_blocks(output))\n",
    "        \n",
    "        return self.fc_out(x), hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacfa598",
   "metadata": {},
   "source": [
    "## Create Model and Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# We instantiate an LSTM model for processing MNIST data. \n",
    "# The model architecture includes multiple LSTM layers, each followed by residual blocks for feature enhancement.\n",
    "# Hyperparameters such as output size, patch size, number of LSTM layers, and hidden size are defined here.\n",
    "\n",
    "# We can stack multiple LSTM blocks together in our model\n",
    "lstm_layers = 3\n",
    "\n",
    "# Hidden size for the LSTM layers\n",
    "hidden_size = 32\n",
    "\n",
    "# Instantiate the LSTM model with defined parameters and move it to the appropriate device (CPU or GPU)\n",
    "mnist_lstm = LSTM(output_size=10, patch_size=patch_size, \n",
    "                  lstm_layers=lstm_layers, hidden_size=hidden_size).to(device)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "# We use the Adam optimizer for training the model with the specified learning rate.\n",
    "optimizer = optim.Adam(mnist_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "# For classification tasks like MNIST digit recognition, we use cross-entropy loss as the loss function.\n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "\n",
    "# Initialize training and validation loss and accuracy loggers\n",
    "training_loss_logger = []\n",
    "training_acc_logger = []\n",
    "valid_loss_logger = []\n",
    "valid_acc_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a115bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in mnist_lstm.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc6dce",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_acc = 0\n",
    "valid_acc = 0\n",
    "\n",
    "# Initialize a progress bar to track epochs and display training and validation accuracies\n",
    "pbar = trange(0, num_epochs, leave=False, desc=\"Epoch\")    \n",
    "for epoch in pbar:\n",
    "    # Update the progress bar with current training and validation accuracies\n",
    "    pbar.set_postfix_str('Accuracy: Train %.2f%%, Val %.2f%%' % (train_acc * 100, valid_acc * 100))\n",
    "\n",
    "    # Set the model to training mode\n",
    "    mnist_lstm.train()\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Iterate through the training data loader\n",
    "    for data, label in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        # Move data and labels to the appropriate device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        # Initialize the hidden states and memory buffers with zeros\n",
    "        hidden = torch.zeros(lstm_layers, data.shape[0], hidden_size, device=device)\n",
    "        memory = torch.zeros(lstm_layers, data.shape[0], hidden_size, device=device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        data_pred, hidden, memory = mnist_lstm(data, hidden, memory)\n",
    "        \n",
    "        # Select the output from the last time step for calculating loss\n",
    "        last_target = data_pred[:, -1, :]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(last_target, label)\n",
    "            \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log training loss and calculate training accuracy\n",
    "        training_loss_logger.append(loss.item())\n",
    "        train_acc += (last_target.argmax(1) == label).sum()\n",
    "        \n",
    "    # Calculate and log training accuracy\n",
    "    train_acc = (train_acc/len(train_data)).item()\n",
    "    training_acc_logger.append(train_acc)\n",
    "        \n",
    "    # Set the model to evaluation mode\n",
    "    mnist_lstm.eval()\n",
    "    valid_acc = 0\n",
    "    \n",
    "    # Validate the model\n",
    "    with torch.no_grad():\n",
    "        # Iterate through the validation data loader\n",
    "        for data, label in tqdm(valid_loader, desc=\"Validation\", leave=False):\n",
    "            # Move data and labels to the appropriate device\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Initialize the hidden states and memory buffers with zeros\n",
    "            hidden = torch.zeros(lstm_layers, data.shape[0], hidden_size, device=device)\n",
    "            memory = torch.zeros(lstm_layers, data.shape[0], hidden_size, device=device)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            data_pred, hidden, memory = mnist_lstm(data, hidden, memory)\n",
    "            \n",
    "            # Select the output from the last time step for calculating loss\n",
    "            last_target = data_pred[:, -1, :]\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(last_target, label)\n",
    "            \n",
    "            # Log validation loss and calculate validation accuracy\n",
    "            valid_loss_logger.append(loss.item())\n",
    "            valid_acc += (last_target.argmax(1) == label).sum()\n",
    "            \n",
    "    # Calculate and log validation accuracy\n",
    "    valid_acc = (valid_acc/len(valid_data)).item()\n",
    "    valid_acc_logger.append(valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374bfc7",
   "metadata": {},
   "source": [
    "## Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.title(\"Train and Valid loss\")\n",
    "_ = plt.plot(np.linspace(0, num_epochs, len(training_loss_logger)), training_loss_logger)\n",
    "_ = plt.plot(np.linspace(0, num_epochs, len(valid_loss_logger)), valid_loss_logger)\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b149b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.title(\"Train and Valid Accuracy\")\n",
    "_ = plt.plot(np.linspace(0, num_epochs, len(training_acc_logger)), training_acc_logger)\n",
    "_ = plt.plot(np.linspace(0, num_epochs, len(valid_acc_logger)), valid_acc_logger)\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ed6f3",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_lstm.eval()\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        hidden = torch.zeros(lstm_layers, data.shape[0], hidden_size, device=device)\n",
    "        memory = torch.zeros(lstm_layers, data.shape[0], hidden_size, device=device)\n",
    "\n",
    "        data_pred, hidden, memory = mnist_lstm(data, hidden, memory)\n",
    "        last_target = data_pred[:, -1, :]\n",
    "\n",
    "        test_acc += (last_target.argmax(1) == label).sum()\n",
    "test_acc = (test_acc/len(test_data)).item()\n",
    "\n",
    "print(\"Test Accuracy %.2f%%\" % (test_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
