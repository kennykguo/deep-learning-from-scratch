{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49835bb4",
   "metadata": {},
   "source": [
    "# Predicting Sequential Data\n",
    "In this notebook we'll use an MLP to predict the Max Daily Temperature and Rainfall. <br>\n",
    "The MLP will take in a sequence of days and predict the information for the next day. By setting day_range larger than (days_in + 1) we can see what happens when we feed the models prediction back in as an input during training. The hope is that the model will become robust to any of it's own prediction errors and be able to predict further into the future.\n",
    "\n",
    "[Corresponding Tutorial Video](https://youtu.be/iKZzXisK1-Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Dataset import WeatherDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4852a",
   "metadata": {},
   "source": [
    "### Max Daily Temp and Rainfall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81794c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing the weather dataset\n",
    "dataset_file = \"../data/weather.csv\"\n",
    "\n",
    "# Define the date to split the dataset into training and testing sets\n",
    "split_date = pd.to_datetime('2023-01-01')\n",
    "\n",
    "# Number of days in the input sequence\n",
    "day_range = 15\n",
    "\n",
    "# Number of days the MLP will take as input\n",
    "days_in = 14\n",
    "\n",
    "# Ensure that the total number of days in the input sequence is larger than the MLP input size\n",
    "assert day_range > days_in, \"The total day range must be larger than the input days for the MLP\"\n",
    "\n",
    "# Define the hyperparameters for training the model\n",
    "learning_rate = 1e-4  # Learning rate for the optimizer\n",
    "nepochs = 500  # Number of training epochs\n",
    "batch_size = 32  # Batch size for training\n",
    "\n",
    "# Create training dataset\n",
    "# This will load the weather data, consider sequences of length day_range,\n",
    "# and split the data such that data before split_date is used for training\n",
    "dataset_train = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"train\")\n",
    "\n",
    "# Create testing dataset\n",
    "# This will load the weather data, consider sequences of length day_range,\n",
    "# and split the data such that data after split_date is used for testing\n",
    "dataset_test = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of testing examples: {len(dataset_test)}')\n",
    "data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968a1f2",
   "metadata": {},
   "source": [
    "### Plot Max Daily Temp Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028df664",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "_ = plt.title(\"Melbourne Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.plot(dataset_train.dataset.index, dataset_train.dataset.values[:, 1])\n",
    "_ = plt.plot(dataset_test.dataset.index, dataset_test.dataset.values[:, 1])\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "# Note:see here how we can just directly access the data from the dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed37d2d",
   "metadata": {},
   "source": [
    "### Res-MLP Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a residual MLP block\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        # Layer normalization for the input\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        # First fully connected layer that reduces the dimensionality by half\n",
    "        self.fc1 = nn.Linear(input_size, input_size // 2)\n",
    "        \n",
    "        # Layer normalization after the first fully connected layer\n",
    "        self.norm2 = nn.LayerNorm(input_size // 2)\n",
    "        # Second fully connected layer that outputs the desired output size\n",
    "        self.fc2 = nn.Linear(input_size // 2, output_size)\n",
    "        \n",
    "        # Skip connection layer to match the output size\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "\n",
    "        # Activation function\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and activation function to the input\n",
    "        x = self.act(self.norm1(x))\n",
    "        # Compute the skip connection output\n",
    "        skip = self.fc3(x)\n",
    "        \n",
    "        # Apply the first fully connected layer, normalization, and activation function\n",
    "        x = self.act(self.norm2(self.fc1(x)))\n",
    "        # Apply the second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Add the skip connection to the output\n",
    "        return x + skip\n",
    "\n",
    "\n",
    "class ResMLP(nn.Module):\n",
    "    def __init__(self, seq_len, output_size, num_blocks=1):\n",
    "        super(ResMLP, self).__init__()\n",
    "        \n",
    "        # Compute the length of the sequence data\n",
    "        seq_data_len = seq_len * 2\n",
    "        \n",
    "        # Define the input MLP with two fully connected layers and normalization\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(seq_data_len, 4 * seq_data_len),\n",
    "            nn.ELU(),\n",
    "            nn.LayerNorm(4 * seq_data_len),\n",
    "            nn.Linear(4 * seq_data_len, 128)\n",
    "        )\n",
    "\n",
    "        # Define the sequence of residual blocks\n",
    "        blocks = [ResBlockMLP(128, 128) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        # Final output fully connected layer\n",
    "        self.fc_out = nn.Linear(128, output_size)\n",
    "        # Activation function\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # Reshape the input sequence to be a flat vector\n",
    "        input_seq = input_seq.reshape(input_seq.shape[0], -1)\n",
    "        # Pass the input through the input MLP\n",
    "        input_vec = self.input_mlp(input_seq)\n",
    "\n",
    "        # Pass the output through the residual blocks and activation function\n",
    "        x = self.act(self.res_blocks(input_vec))\n",
    "        \n",
    "        # Compute the final output\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of the ResMLP model\n",
    "# - seq_len is the number of days the model takes as input (days_in)\n",
    "# - output_size is the number of outputs the model predicts (2: Max Daily Temperature and Rainfall)\n",
    "weather_mlp = ResMLP(seq_len=days_in, output_size=2).to(device)\n",
    "\n",
    "# Initialize the optimizer\n",
    "# - Use Adam optimizer which is an adaptive learning rate optimization algorithm\n",
    "# - It updates the weights of the model based on the computed gradients\n",
    "# - weather_mlp.parameters() returns all the parameters of the model\n",
    "# - lr is the learning rate, which controls how much to change the model in response to the estimated error\n",
    "optimizer = optim.Adam(weather_mlp.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "# - Mean Squared Error (MSE) is used as the loss function\n",
    "# - MSE calculates the average of the squares of the errors (differences between predicted and actual values)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Initialize a list to log the training loss over epochs\n",
    "training_loss_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee81ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in weather_mlp.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the number of epochs\n",
    "for epoch in trange(nepochs, desc=\"Epochs\", leave=False):\n",
    "    # Set the model to training mode\n",
    "    weather_mlp.train()\n",
    "    \n",
    "    # Iterate over the training data loader\n",
    "    for day, month, data_seq in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        \n",
    "        # Extract the initial sequence block to be used as input for the model\n",
    "        seq_block = data_seq[:, :days_in].to(device)\n",
    "        \n",
    "        # Initialize the loss for the current batch\n",
    "        loss = 0\n",
    "        \n",
    "        # Iterate over the remaining sequence to predict the next day values\n",
    "        for i in range(day_range - days_in):\n",
    "            # Get the target sequence block for the next day\n",
    "            target_seq_block = data_seq[:, i + days_in].to(device)\n",
    "            \n",
    "            # Make predictions using the model\n",
    "            data_pred = weather_mlp(seq_block)\n",
    "            \n",
    "            # Accumulate the loss for the current prediction\n",
    "            loss += loss_fn(data_pred, target_seq_block)\n",
    "            \n",
    "            # Update the input sequence by removing the oldest date and adding the new prediction\n",
    "            # Detach the new sequence to prevent backpropagation through the old sequence\n",
    "            seq_block = torch.cat((seq_block[:, 1:, :], data_pred.unsqueeze(1)), 1).detach()\n",
    "\n",
    "        # Average the accumulated loss over the number of steps\n",
    "        loss /= i + 1\n",
    "        \n",
    "        # Zero the gradients before performing backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform backpropagation to compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the model parameters using the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log the training loss for later analysis\n",
    "        training_loss_logger.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003785d6",
   "metadata": {},
   "source": [
    "### Plot Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66946d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(training_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7551e7f",
   "metadata": {},
   "source": [
    "### Run Autoregressive Prediction Roll-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test dataset values to a PyTorch tensor\n",
    "data_tensor = torch.FloatTensor(dataset_test.dataset.values)\n",
    "\n",
    "# Initialize a list to log predictions\n",
    "log_predictions = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "weather_mlp.eval()\n",
    "\n",
    "# Disable gradient calculation for the prediction process\n",
    "with torch.no_grad():\n",
    "    # Extract the initial sequence block to be used as input for the model\n",
    "    # - unsqueeze(0) adds a batch dimension to the input\n",
    "    seq_block = data_tensor[:days_in, :].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Iterate over the sequence to predict the next day values\n",
    "    for i in range(data_tensor.shape[0] - days_in):\n",
    "        # Make predictions using the model\n",
    "        data_pred = weather_mlp(seq_block)\n",
    "        \n",
    "        # Log the prediction\n",
    "        log_predictions.append(data_pred.cpu())\n",
    "        \n",
    "        # Update the input sequence by removing the oldest date and adding the new prediction\n",
    "        seq_block = torch.cat((seq_block[:, 1:, :], data_pred.unsqueeze(1)), 1)\n",
    "\n",
    "# Concatenate the logged predictions into a single tensor\n",
    "predictions_cat = torch.cat(log_predictions)\n",
    "\n",
    "# Unnormalize the predictions using the dataset's standard deviation and mean\n",
    "un_norm_predictions = (predictions_cat * dataset_test.std) + dataset_test.mean\n",
    "\n",
    "# Unnormalize the original data using the dataset's standard deviation and mean\n",
    "un_norm_data = (data_tensor * dataset_test.std) + dataset_test.mean\n",
    "\n",
    "# Trim the initial sequence from the unnormalized data to match the length of predictions\n",
    "un_norm_data = un_norm_data[days_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d337f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = (un_norm_data - un_norm_predictions).pow(2).mean().item()\n",
    "print(\"Test MSE value %.2f\" % test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ea26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(un_norm_data[:, 0])\n",
    "_ = plt.plot(un_norm_predictions[:, 0])\n",
    "_ = plt.title(\"Rainfall (mm)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 10))\n",
    "_ = plt.plot(un_norm_data[:, 1])\n",
    "_ = plt.plot(un_norm_predictions[:, 1])\n",
    "_ = plt.title(\"Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
