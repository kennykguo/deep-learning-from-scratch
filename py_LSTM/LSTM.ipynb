{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff91fc80-0bc4-471f-91e9-6c51ac49657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d27627-2fa1-4c6e-bfad-dd87852ae629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81a0afd-6bb8-4c02-9b4e-1e007cf70ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 8]) torch.Size([182580])\n",
      "torch.Size([22767, 8]) torch.Size([22767])\n",
      "torch.Size([22799, 8]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "  X, Y = [], []\n",
    "\n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee25fba-164d-4fce-a822-7c368f65d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "print(itos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34de23f0-3a4c-4d2b-9874-4aa650f11493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  5,  2, 18])\n"
     ]
    }
   ],
   "source": [
    "print(Xtr[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aff50ce0-b584-4dfd-89f0-96b8fd1db1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182580, 8, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_Xtr = F.one_hot(Xtr, 27)\n",
    "one_hot_Xtr = one_hot.view(8, -1, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48fc655-fb4e-4ea8-b9d1-398c26fb170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch = torch.randint(0, one_hot_Xtr.shape[1], (batch_size,))\n",
    "Xb = one_hot_Xtr[:, batch, :]\n",
    "time_steps, batch_size, input_size = Xb.shape\n",
    "hidden_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fddc288-34bc-4c65-bb6e-fa74c5799979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in time_steps:\n",
    "\n",
    "input = Xb[0].type(torch.float32)\n",
    "hidden = 30\n",
    "\n",
    "# Parameters\n",
    "WLSTM1 = torch.randn(vocab_size, hidden_size)\n",
    "WLSTM2 = torch.randn(hidden_size, hidden_size)\n",
    "F = torch.randn(batch_size, hidden_size)\n",
    "i1 = torch.randn(batch_size, hidden_size)\n",
    "i2 = torch.randn(batch_size, hidden_size)\n",
    "O = torch.randn(batch_size, hidden_size)\n",
    "bias1 = torch.zeros(hidden_size)\n",
    "bias2 = torch.zeros(hidden_size)\n",
    "bias3 = torch.zeros(hidden_size)\n",
    "bias4 = torch.zeros(hidden_size)\n",
    "output_matrix = torch.randn(hidden_size)\n",
    "\n",
    "# Storage\n",
    "# prev = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "hidden1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "hidden2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "total = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact4 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act4 = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "C = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Ct = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Hout = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "\n",
    "c0 = torch.zeros(batch_size, hidden_size)\n",
    "h0 = torch.zeros((batch_size, hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "011dce1a-c67f-402a-89c9-c31d57aff8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 30])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9a0a2ca-59c7-4e77-b14d-e5c1cc0a4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevh = H[t-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b06e3ba5-8fa2-4a0a-94c9-5e223c390344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "print(hidden1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a850a0e-d3f3-44c6-8085-4222b3f991e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5a5534da-33da-40c6-a260-257ae5086571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden2[t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e1f1592-8590-49c9-8f4e-dd9488bd10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed58a60a-4b54-4cd0-a0d1-a6db9aa79675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 30])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WLSTM2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b70d19ed-4345-4e02-8701-3074e5d5a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3d1cffa8-7414-4bb2-ab81-ef49a4e4a0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden2[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0e7e93b-f3d3-42a5-80c5-4b6bb5b99591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "455779e3-b05e-4b22-82ba-82ef6fa1cdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total[t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "19f7a2b8-0d8e-45d8-931e-b34a612cc0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "08e6a1b8-134e-4758-b5d4-8eaf562fb6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "for t in range(time_steps):\n",
    "    prevh = H[t-1] if t > 0 else h0\n",
    "    prevc = C[t-1] if t > 0 else c0\n",
    "    \n",
    "    hidden1[t] = input @ WLSTM1 # (32, 30)\n",
    "    hidden2[t] = prevh @ WLSTM2 # (32, 30)\n",
    "    total[t] = hidden1[t] + hidden2[t] # (32, 30)\n",
    "    \n",
    "    preact1[t] = total[t] * F + bias1 # (32, 30)\n",
    "    preact2[t] = total[t] * i1 + bias2 # (32, 30)\n",
    "    preact3[t] = total[t] * i2 + bias3 # (32, 30)\n",
    "    preact4[t] = total[t] * O + bias4 # (32, 30)\n",
    "    \n",
    "    act1[t] = torch.sigmoid(preact1[t]) # (32, 30)\n",
    "    act2[t] = torch.sigmoid(preact2[t]) # (32, 30)\n",
    "    act3[t] = torch.sigmoid(preact3[t]) # (32, 30)\n",
    "    act4[t] = torch.tanh(preact4[t]) # (32, 30)\n",
    "    \n",
    "    C[t] = act2[t] * prevc + act1[t] * act4[t] # (32, 30)\n",
    "    Ct[t] = torch.tanh(C[t]) # (32, 30)\n",
    "    Hout[t] = Ct[t] * act3[t] # (32, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7d782-5f37-4208-bb83-072e3bfad4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "dWLSTM1 = torch.zeros(vocab_size, hidden_size)\n",
    "dWLSTM2 = torch.zeros(hidden_size, hidden_size)\n",
    "dF = torch.zeros(batch_size, hidden_size)\n",
    "di1 = torch.zeros(batch_size, hidden_size)\n",
    "di2 = torch.zeros(batch_size, hidden_size)\n",
    "dO = torch.zeros(batch_size, hidden_size)\n",
    "dbias1 = torch.zeros(hidden_size)\n",
    "dbias2 = torch.zeros(hidden_size)\n",
    "dbias3 = torch.zeros(hidden_size)\n",
    "dbias4 = torch.zeros(hidden_size)\n",
    "doutput_matrix = torch.randn(hidden_size)\n",
    "\n",
    "for t in reversed(range(x)):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
