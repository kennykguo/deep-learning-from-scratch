{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ff91fc80-0bc4-471f-91e9-6c51ac49657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b5d27627-2fa1-4c6e-bfad-dd87852ae629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
      "Character to index mapping: {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "Vocabulary size: 27\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(f'Character to index mapping: {itos}')\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "\n",
    "# Shuffle the words\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f1a8cf47-b550-404c-8e7b-8df895e1f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes - X: torch.Size([208135, 8]), Y: torch.Size([208135, 8])\n",
      "Development data shapes - X: torch.Size([52028, 8]), Y: torch.Size([52028, 8])\n",
      "Training batches shape - X: torch.Size([208135, 8]), Y: torch.Size([208135, 8])\n",
      "Development batches shape - X: torch.Size([52028, 8]), Y: torch.Size([52028, 8])\n"
     ]
    }
   ],
   "source": [
    "# Function to encode words into a single continuous sequence of indices\n",
    "def encode_words(words):\n",
    "    encoded = []\n",
    "    for w in words:\n",
    "        encoded.extend([stoi[ch] for ch in '.' + w + '.'])\n",
    "    return encoded\n",
    "\n",
    "# Encode all words into a single sequence\n",
    "encoded = encode_words(words)\n",
    "\n",
    "# Function to create input-output pairs from a sequence\n",
    "def create_pairs(seq, block_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(seq) - block_size):\n",
    "        X.append(seq[i:i+block_size])\n",
    "        Y.append(seq[i+1:i+block_size+1])\n",
    "    X = torch.tensor(X, dtype=torch.long)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    return X, Y\n",
    "\n",
    "# Split into training and development sets\n",
    "n = len(encoded)\n",
    "n1 = int(0.8 * n)\n",
    "\n",
    "train_seq = encoded[:n1]\n",
    "dev_seq = encoded[n1:]\n",
    "\n",
    "block_size = 8\n",
    "\n",
    "# Create pairs for training and development sets\n",
    "Xtr, Ytr = create_pairs(train_seq, block_size)\n",
    "Xdev, Ydev = create_pairs(dev_seq, block_size)\n",
    "\n",
    "print(f'Training data shapes - X: {Xtr.shape}, Y: {Ytr.shape}')\n",
    "print(f'Development data shapes - X: {Xdev.shape}, Y: {Ydev.shape}')\n",
    "\n",
    "# Function to split data into batches of shape (batch_size, time_steps, -1)\n",
    "def split_into_batches(X, Y, batch_size):\n",
    "    # Ensure the data size is a multiple of batch_size\n",
    "    num_batches = X.size(0) // batch_size\n",
    "    X = X[:num_batches * batch_size]\n",
    "    Y = Y[:num_batches * batch_size]\n",
    "    \n",
    "    # Reshape into batches\n",
    "    X = X.view(batch_size, -1, X.size(-1))\n",
    "    Y = Y.view(batch_size, -1, Y.size(-1))\n",
    "    return X, Y\n",
    "\n",
    "# Example output\n",
    "print(f'Training batches shape - X: {Xtr.shape}, Y: {Ytr.shape}')\n",
    "print(f'Development batches shape - X: {Xdev.shape}, Y: {Ydev.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "34de23f0-3a4c-4d2b-9874-4aa650f11493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21,  8,  5, 14,  7,  0,  0,  4])\n",
      "tensor([ 8,  5, 14,  7,  0,  0,  4,  9])\n"
     ]
    }
   ],
   "source": [
    "print(Xtr[2])\n",
    "print(Ytr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "aff50ce0-b584-4dfd-89f0-96b8fd1db1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_Xtr = F.one_hot(Xtr, 27)\n",
    "one_hot_Xtr = one_hot.view(8, -1, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "418a94b8-3edb-4626-8b03-2c28458304e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 27])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "baf5cc76-204d-411b-b866-4b16c7bf2262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a48fc655-fb4e-4ea8-b9d1-398c26fb170f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 27])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "batch = torch.randint(0, one_hot_Xtr.shape[1], (batch_size,))\n",
    "Xb = one_hot_Xtr[:, batch, :] # (8, 32, 27)\n",
    "Yb = Ytr[batch]\n",
    "Yb = Yb.view(8, -1)\n",
    "time_steps, batch_size, input_size = Xb.shape\n",
    "hidden_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7fddc288-34bc-4c65-bb6e-fa74c5799979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in time_steps:\n",
    "\n",
    "Xb = Xb.type(torch.float32)\n",
    "Yb = Yb.type(torch.int64)\n",
    "\n",
    "hidden = 30\n",
    "\n",
    "# Parameters\n",
    "WLSTM1 = torch.randn(vocab_size, hidden_size)\n",
    "WLSTM2 = torch.randn(hidden_size, hidden_size)\n",
    "F = torch.randn(batch_size, hidden_size)\n",
    "i1 = torch.randn(batch_size, hidden_size)\n",
    "i2 = torch.randn(batch_size, hidden_size)\n",
    "O = torch.randn(batch_size, hidden_size)\n",
    "bias1 = torch.zeros(hidden_size)\n",
    "bias2 = torch.zeros(hidden_size)\n",
    "bias3 = torch.zeros(hidden_size)\n",
    "bias4 = torch.zeros(hidden_size)\n",
    "output_matrix = torch.randn(hidden_size, vocab_size)\n",
    "\n",
    "# Storage\n",
    "# prev = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "hidden1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "hidden2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "total = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact4 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act4 = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "C = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Ct = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Hout = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "output = torch.zeros((time_steps, batch_size, vocab_size))\n",
    "c0 = torch.zeros(batch_size, hidden_size)\n",
    "h0 = torch.zeros((batch_size, hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "23985c91-e751-4244-aa54-56b39097f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1, 12,  9,  3,  9, 15, 19,  1,  2, 18,  9, 14,  1,  0, 15, 18,\n",
       "         9,  1, 14, 14,  1,  0, 21, 18,  0,  0,  2, 18,  1, 25])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "de3eca35-988c-4ecc-92a9-a840c1f0454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "08e6a1b8-134e-4758-b5d4-8eaf562fb6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "loss = 0\n",
    "for t in range(time_steps):\n",
    "    prevh = H[t-1] if t > 0 else h0\n",
    "    prevc = C[t-1] if t > 0 else c0\n",
    "    # 32 examples of 27 one hot encoded words\n",
    "    hidden1[t] = Xb[t] @ WLSTM1 # #(32, 27) @ (27, 30) = (32, 30)\n",
    "    hidden2[t] = prevh @ WLSTM2 # (32, 30)\n",
    "    total[t] = hidden1[t] + hidden2[t] # (32, 30)\n",
    "    \n",
    "    preact1[t] = total[t] * F + bias1 # (32, 30)\n",
    "    preact2[t] = total[t] * i1 + bias2 # (32, 30)\n",
    "    preact3[t] = total[t] * i2 + bias3 # (32, 30)\n",
    "    preact4[t] = total[t] * O + bias4 # (32, 30)\n",
    "    \n",
    "    act1[t] = torch.sigmoid(preact1[t]) # (32, 30)\n",
    "    act2[t] = torch.sigmoid(preact2[t]) # (32, 30)\n",
    "    act3[t] = torch.sigmoid(preact3[t]) # (32, 30)\n",
    "    act4[t] = torch.tanh(preact4[t]) # (32, 30)\n",
    "    \n",
    "    C[t] = act2[t] * prevc + act1[t] * act4[t] # (32, 30)\n",
    "    Ct[t] = torch.tanh(C[t]) # (32, 30)\n",
    "    Hout[t] = Ct[t] * act3[t] # (32, 30)\n",
    "    output[t] = Hout[t] @ output_matrix # (32, 27)\n",
    "    counts = output.exp()\n",
    "    counts_sum = counts.sum(1, keepdims=True)\n",
    "    counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "    probs = counts * counts_sum_inv\n",
    "    logprobs = probs.log()\n",
    "    loss += -logprobs[t][torch.arange(32), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e7d2246a-f738-489e-99a6-19cac9e5938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1, 12,  9,  3,  9, 15, 19,  1,  2, 18,  9, 14,  1,  0, 15, 18,\n",
       "         9,  1, 14, 14,  1,  0, 21, 18,  0,  0,  2, 18,  1, 25])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9bbe930f-6041-42ee-a42a-7bbed3055f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 27])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "951b4529-9d08-4fca-a390-2986cf8ea9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7d782-5f37-4208-bb83-072e3bfad4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "dWLSTM1 = torch.zeros(vocab_size, hidden_size)\n",
    "dWLSTM2 = torch.zeros(hidden_size, hidden_size)\n",
    "dF = torch.zeros(batch_size, hidden_size)\n",
    "di1 = torch.zeros(batch_size, hidden_size)\n",
    "di2 = torch.zeros(batch_size, hidden_size)\n",
    "dO = torch.zeros(batch_size, hidden_size)\n",
    "dbias1 = torch.zeros(hidden_size)\n",
    "dbias2 = torch.zeros(hidden_size)\n",
    "dbias3 = torch.zeros(hidden_size)\n",
    "dbias4 = torch.zeros(hidden_size)\n",
    "doutput_matrix = torch.randn(hidden_size)\n",
    "\n",
    "for t in reversed(range(x)):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
