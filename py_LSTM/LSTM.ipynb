{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ff91fc80-0bc4-471f-91e9-6c51ac49657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b5d27627-2fa1-4c6e-bfad-dd87852ae629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
      "Character to index mapping: {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "Vocabulary size: 27\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(f'Character to index mapping: {itos}')\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "\n",
    "# Shuffle the words\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f1a8cf47-b550-404c-8e7b-8df895e1f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes - X: torch.Size([208135, 8]), Y: torch.Size([208135, 8])\n",
      "Development data shapes - X: torch.Size([52028, 8]), Y: torch.Size([52028, 8])\n",
      "Training batches shape - X: torch.Size([208135, 8]), Y: torch.Size([208135, 8])\n",
      "Development batches shape - X: torch.Size([52028, 8]), Y: torch.Size([52028, 8])\n"
     ]
    }
   ],
   "source": [
    "# Function to encode words into a single continuous sequence of indices\n",
    "def encode_words(words):\n",
    "    encoded = []\n",
    "    for w in words:\n",
    "        encoded.extend([stoi[ch] for ch in '.' + w + '.'])\n",
    "    return encoded\n",
    "\n",
    "# Encode all words into a single sequence\n",
    "encoded = encode_words(words)\n",
    "\n",
    "# Function to create input-output pairs from a sequence\n",
    "def create_pairs(seq, block_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(seq) - block_size):\n",
    "        X.append(seq[i:i+block_size])\n",
    "        Y.append(seq[i+1:i+block_size+1])\n",
    "    X = torch.tensor(X, dtype=torch.long)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    return X, Y\n",
    "\n",
    "# Split into training and development sets\n",
    "n = len(encoded)\n",
    "n1 = int(0.8 * n)\n",
    "\n",
    "train_seq = encoded[:n1]\n",
    "dev_seq = encoded[n1:]\n",
    "\n",
    "block_size = 8\n",
    "\n",
    "# Create pairs for training and development sets\n",
    "Xtr, Ytr = create_pairs(train_seq, block_size)\n",
    "Xdev, Ydev = create_pairs(dev_seq, block_size)\n",
    "\n",
    "print(f'Training data shapes - X: {Xtr.shape}, Y: {Ytr.shape}')\n",
    "print(f'Development data shapes - X: {Xdev.shape}, Y: {Ydev.shape}')\n",
    "\n",
    "# Function to split data into batches of shape (batch_size, time_steps, -1)\n",
    "def split_into_batches(X, Y, batch_size):\n",
    "    # Ensure the data size is a multiple of batch_size\n",
    "    num_batches = X.size(0) // batch_size\n",
    "    X = X[:num_batches * batch_size]\n",
    "    Y = Y[:num_batches * batch_size]\n",
    "    \n",
    "    # Reshape into batches\n",
    "    X = X.view(batch_size, -1, X.size(-1))\n",
    "    Y = Y.view(batch_size, -1, Y.size(-1))\n",
    "    return X, Y\n",
    "\n",
    "# Example output\n",
    "print(f'Training batches shape - X: {Xtr.shape}, Y: {Ytr.shape}')\n",
    "print(f'Development batches shape - X: {Xdev.shape}, Y: {Ydev.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "34de23f0-3a4c-4d2b-9874-4aa650f11493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21,  8,  5, 14,  7,  0,  0,  4])\n",
      "tensor([ 8,  5, 14,  7,  0,  0,  4,  9])\n"
     ]
    }
   ],
   "source": [
    "print(Xtr[2])\n",
    "print(Ytr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "aff50ce0-b584-4dfd-89f0-96b8fd1db1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_Xtr = F.one_hot(Xtr, 27)\n",
    "one_hot_Xtr = one_hot.view(8, -1, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "418a94b8-3edb-4626-8b03-2c28458304e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 27])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "baf5cc76-204d-411b-b866-4b16c7bf2262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a48fc655-fb4e-4ea8-b9d1-398c26fb170f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 27])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "batch = torch.randint(0, one_hot_Xtr.shape[1], (batch_size,))\n",
    "Xb = one_hot_Xtr[:, batch, :] # (8, 32, 27)\n",
    "Yb = Ytr[batch]\n",
    "Yb = Yb.view(8, -1)\n",
    "time_steps, batch_size, input_size = Xb.shape\n",
    "hidden_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7fddc288-34bc-4c65-bb6e-fa74c5799979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in time_steps:\n",
    "\n",
    "Xb = Xb.type(torch.float32)\n",
    "Yb = Yb.type(torch.int64)\n",
    "\n",
    "hidden = 30\n",
    "\n",
    "# Parameters\n",
    "WLSTM1 = torch.randn(vocab_size, hidden_size)\n",
    "WLSTM2 = torch.randn(hidden_size, hidden_size)\n",
    "Fo = torch.randn(batch_size, hidden_size)\n",
    "i1 = torch.randn(batch_size, hidden_size)\n",
    "i2 = torch.randn(batch_size, hidden_size)\n",
    "O = torch.randn(batch_size, hidden_size)\n",
    "bias1 = torch.zeros(hidden_size)\n",
    "bias2 = torch.zeros(hidden_size)\n",
    "bias3 = torch.zeros(hidden_size)\n",
    "bias4 = torch.zeros(hidden_size)\n",
    "output_matrix = torch.randn(hidden_size, vocab_size)\n",
    "\n",
    "# Storage\n",
    "# prev = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "hidden1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "hidden2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "total = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact4 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act4 = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "C = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Ct = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Hout = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "logits = torch.zeros((time_steps, batch_size, vocab_size))\n",
    "c0 = torch.zeros(batch_size, hidden_size)\n",
    "h0 = torch.zeros((batch_size, hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "23985c91-e751-4244-aa54-56b39097f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1, 12,  9,  3,  9, 15, 19,  1,  2, 18,  9, 14,  1,  0, 15, 18,\n",
       "         9,  1, 14, 14,  1,  0, 21, 18,  0,  0,  2, 18,  1, 25])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "de3eca35-988c-4ecc-92a9-a840c1f0454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "08e6a1b8-134e-4758-b5d4-8eaf562fb6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7705)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "loss = 0\n",
    "for t in range(time_steps):\n",
    "    prevh = H[t-1] if t > 0 else h0\n",
    "    prevc = C[t-1] if t > 0 else c0\n",
    "    # 32 examples of 27 one hot encoded words\n",
    "    # (32, 27)\n",
    "    # (32, 30)\n",
    "    \n",
    "    # hidden1[t] = Xb[t] @ WLSTM1 # #(32, 27) @ (27, 30) = (32, 30)\n",
    "    # hidden2[t] = prevh @ WLSTM2 # (32, 30)\n",
    "    # total[t] = hidden1[t] + hidden2[t] # (32, 30)\n",
    "    \n",
    "    preact1[t] = Xb[t] @ Fhh + prevh  bias1 # (32, 30)\n",
    "    preact2[t] = Xb[t] @ i1 + prevh bias2 # (32, 30)\n",
    "    preact3[t] = Xb[t] @ i2 + prevh bias3 # (32, 30)\n",
    "    preact4[t] = Xb[t] @ Oih  prevh * Ohh # (32, 30)\n",
    "    \n",
    "    act1[t] = torch.sigmoid(preact1[t]) # (32, 30)\n",
    "    act2[t] = torch.sigmoid(preact2[t]) # (32, 30)\n",
    "    act3[t] = torch.tanh(preact3[t]) # (32, 30)\n",
    "    act4[t] = torch.sigmoid(preact4[t]) # (32, 30)\n",
    "    \n",
    "    C[t] = act2[t] * prevc + act1[t] * act4[t] # (32, 30)\n",
    "    Ct[t] = torch.tanh(C[t]) # (32, 30)\n",
    "    Hout[t] = Ct[t] * act3[t] # (32, 30)\n",
    "    \n",
    "    logits[t] = Hout[t] @ output_matrix # (32, 27)\n",
    "    \n",
    "    counts = logits.exp()\n",
    "    counts_sum = counts.sum(1, keepdims=True)\n",
    "    counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "    probs = counts * counts_sum_inv\n",
    "    logprobs = probs.log()\n",
    "    loss += -logprobs[t][torch.arange(32), Yb].mean()\n",
    "\n",
    "\n",
    "print (loss / time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "c4e7d782-5f37-4208-bb83-072e3bfad4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backward pass\n",
    "\n",
    "# # To update\n",
    "# dWLSTM1 = torch.zeros(vocab_size, hidden_size) #(27, 30)\n",
    "# dWLSTM2 = torch.zeros(hidden_size, hidden_size) # (30, 30)\n",
    "\n",
    "# dFo = torch.zeros(batch_size, hidden_size) # (32, 30)\n",
    "# di1 = torch.zeros(batch_size, hidden_size) # (32, 30)\n",
    "# di2 = torch.zeros(batch_size, hidden_size) # (32, 30)\n",
    "# dO = torch.zeros(batch_size, hidden_size) # (32, 30)\n",
    "\n",
    "# dbias1 = torch.zeros(hidden_size) # (30)\n",
    "# dbias2 = torch.zeros(hidden_size) # (30)\n",
    "# dbias3 = torch.zeros(hidden_size) # (30)\n",
    "# dbias4 = torch.zeros(hidden_size) # (30)\n",
    "\n",
    "# doutput_matrix = torch.randn(hidden_size, vocab_size) # (30, 27)\n",
    "\n",
    "# # Placeholders (indexed with t)\n",
    "# dlogits = torch.zeros((time_steps, batch_size, vocab_size)) # (30, 27)\n",
    "# dhidden1 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "# dhidden2 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "# dtotal = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "\n",
    "# dpreact1 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30) \n",
    "# dpreact2 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "# dpreact3 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "# dpreact4 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "\n",
    "# dact1 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30) \n",
    "# dact2 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "# dact3 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "# dact4 = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "\n",
    "# dC = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "# dCt = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "# dHout = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "# dlogits = torch.zeros((time_steps, batch_size, vocab_size)) # (32, 27)\n",
    "\n",
    "# dc0 = torch.zeros(batch_size, hidden_size)\n",
    "# dh0 = torch.zeros((batch_size, hidden_size))\n",
    "\n",
    "\n",
    "\n",
    "# # Backpropogate cross entropy\n",
    "# dlogits[t] = F.softmax(logits[t], 1)\n",
    "# dlogits[t][torch.arange(batch_size), Yb] -= 1\n",
    "# dlogits /= n\n",
    "\n",
    "# # Backpropogate dHout\n",
    "# dHout[t] =  dlogits[t] @ output_matrix.T # (32, 27) @ (27, 30) = (32, 30) dHt on paper derivation\n",
    "\n",
    "# # Backpropogate output matrix\n",
    "# doutput_matrix = dlogits[t].T @ dHout[t] # (32, 27)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 1. Backpropogate dact3 (output gate)\n",
    "# dact3[t] = dHout[t] * Ct[t] # (32, 27) * (32, 27) = (32, 27)\n",
    "\n",
    "# # 2. Backpropogate dC (current cell state)\n",
    "# dC[t] = dHout[t] * act3[t] * (1 - torch.tanh(C[t])**2) # (32, 27) * (32, 27) * (32, 27) = (32, 27)\n",
    "\n",
    "\n",
    "# # 3. Backpropogate dF for act2 and previous cell state\n",
    "# if t > 0:\n",
    "#     # Forget gate activations\n",
    "#     # Last cell activations\n",
    "#     dact1[t] = dHout[t] * C[t-1] # (32, 27) * (32, 27) = (32, 27)\n",
    "#     dC[t-1] = dCt[] * Fo\n",
    "# else:\n",
    "#     df = dHout[t] * C[t-1]\n",
    "#     dc0 = dC[t] * Fo\n",
    "\n",
    "# # Backpropogate i1 activations\n",
    "# dact2[t] = dC[t] * i2\n",
    "\n",
    "# # Backpropogate i2 activations\n",
    "# dact3[t] = dC[t] * i1\n",
    "\n",
    "# # Backpropogate all preactivations\n",
    "# dpreact1[t] = dact1[t] * act1[t] * ( 1- act1[t])\n",
    "# dpreact2[t] = dact2[t] * act2[t] * ( 1- act2[t])\n",
    "# dpreact3[t] = dact3[t] * (1 - torch.tanh(dpreact3[t])**2)\n",
    "# dpreact4[t] = dact4[t] * act4[t] * ( 1- act4[t])\n",
    "\n",
    "# # Backpropogate gates\n",
    "# dFo = dpreact1[t] * total[t]\n",
    "# di1 = dpreact2[t] * total[t]\n",
    "# di2 = dpreact3[t] * total[t]\n",
    "# dO = dpreact4[t] * total[t]\n",
    "\n",
    "# # Backpropogate total\n",
    "# dtotal[t] = dpreact1[t] * Fo + dpreact2[t] * i1 + dpreact3[t] * i2 + dpreact4[t] * O\n",
    "\n",
    "# # Backpropogate hidden\n",
    "# dhidden1 = 1 * dtotal[t]\n",
    "# dhidden2 = 1 * dtotal[t]\n",
    "\n",
    "# # Backpropogate inputs\n",
    "# dprevh\n",
    "\n",
    "#     prevh = H[t-1] if t > 0 else h0\n",
    "#     prevc = C[t-1] if t > 0 else c0\n",
    "#     # 32 examples of 27 one hot encoded words\n",
    "#     hidden1[t] = Xb[t] @ WLSTM1 # (32, 27) @ (27, 30) = (32, 30)\n",
    "#     hidden2[t] = prevh @ WLSTM2 # (32, 30)\n",
    "#     total[t] = hidden1[t] + hidden2[t] # (32, 30)\n",
    "\n",
    "#     preact1[t] = total[t] * Fo + bias1 # (32, 30)\n",
    "#     preact2[t] = total[t] * i1 + bias2 # (32, 30)\n",
    "#     preact3[t] = total[t] * i2 + bias3 # (32, 30)\n",
    "#     preact4[t] = total[t] * O + bias4 # (32, 30)\n",
    "    \n",
    "#     act1[t] = torch.sigmoid(preact1[t]) # (32, 30)\n",
    "#     act2[t] = torch.sigmoid(preact2[t]) # (32, 30)\n",
    "#     act3[t] = torch.tanh(preact3[t]) # (32, 30)\n",
    "#     act4[t] = torch.sigmoid(preact4[t]) # (32, 30)\n",
    "\n",
    "#     C[t] = act2[t] * prevc + act1[t] * act4[t] # (32, 30)\n",
    "\n",
    "#     Ct[t] = torch.tanh(C[t]) # (32, 30)\n",
    "#     Hout[t] = Ct[t] * act3[t] # (32, 30)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adee8b7-3d88-40d2-8315-2130a017c390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
