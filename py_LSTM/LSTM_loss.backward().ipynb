{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff91fc80-0bc4-471f-91e9-6c51ac49657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d27627-2fa1-4c6e-bfad-dd87852ae629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n",
      "Character to index mapping: {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "Vocabulary size: 27\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "print(words[:10])\n",
    "\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(f'Character to index mapping: {itos}')\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "\n",
    "# Shuffle the words\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac0e6ea-cbf7-48fa-98d6-9dcf2fe77f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(words):\n",
    "    encoded = []\n",
    "    for w in words:\n",
    "        encoded.extend([stoi[ch] for ch in '.' + w  + '.'])\n",
    "    return encoded\n",
    "\n",
    "encoded = encode_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0bfad2-2aff-4766-82f4-4a8d4b9bc7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 25, 21, 8, 5, 14, 7, 0, 0, 4, 9, 15, 14, 4, 18, 5, 0, 0, 24, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754cc12d-c2ee-4650-8287-0deadf2ac4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(encoded)\n",
    "n1 = int(0.8 * n)\n",
    "block_size = 8\n",
    "batch_size = 32\n",
    "\n",
    "train_seq = encoded[:n1]\n",
    "dev_seq = encoded[n1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc278fca-c090-4e6f-b399-8781f71623a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(seq, block_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(seq) - block_size):\n",
    "        X.append(seq[i:i+block_size])\n",
    "        Y.append(seq[i+1:i+block_size+1])\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    Y = torch.tensor(Y, dtype=torch.float32)\n",
    "    return X, Y\n",
    "\n",
    "Xtr, Ytr = create_pairs(train_seq, block_size)\n",
    "Xdev, Ydev = create_pairs(dev_seq, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1caa97e5-c13d-417f-8c04-620c3685f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25., 21.,  8.,  5., 14.,  7.,  0.,  0.])\n",
      "tensor([21.,  8.,  5., 14.,  7.,  0.,  0.,  4.])\n",
      "Training data shapes - X: torch.Size([208135, 8]), Y: torch.Size([208135, 8])\n",
      "Development data shapes - X: torch.Size([52028, 8]), Y: torch.Size([52028, 8])\n"
     ]
    }
   ],
   "source": [
    "print(Xtr[1])\n",
    "print(Ytr[1])\n",
    "print(f'Training data shapes - X: {Xtr.shape}, Y: {Ytr.shape}')\n",
    "print(f'Development data shapes - X: {Xdev.shape}, Y: {Ydev.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a8cf47-b550-404c-8e7b-8df895e1f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches shape - X: torch.Size([8, 6504, 32]), Y: torch.Size([8, 6504, 32])\n",
      "Development batches shape - X: torch.Size([8, 1625, 32]), Y: torch.Size([8, 1625, 32])\n"
     ]
    }
   ],
   "source": [
    "def split_into_batches(X, Y, batch_size, time_steps):\n",
    "    num_batches = X.size(0) // batch_size\n",
    "    \n",
    "    # Adjust the number of examples to be divisible by batch_size * time_steps\n",
    "    num_examples = num_batches * batch_size\n",
    "    X = X[:num_examples, :]\n",
    "    Y = Y[:num_examples, :]\n",
    "\n",
    "    # Reshape X and Y to have dimensions: (time_steps, num_batches, batch_size)\n",
    "    X = X.view(time_steps, num_batches, batch_size).permute(0, 1, 2)\n",
    "    Y = Y.view(time_steps, num_batches, batch_size).permute(0, 1, 2)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "Xtr_batched, Ytr_batched = split_into_batches(Xtr, Ytr, 32, 8)\n",
    "Xdev_batched, Ydev_batched = split_into_batches(Xdev, Ydev, 32, 8)\n",
    "\n",
    "\n",
    "print(f'Training batches shape - X: {Xtr_batched.shape}, Y: {Ytr_batched.shape}')\n",
    "print(f'Development batches shape - X: {Xdev_batched.shape}, Y: {Ydev_batched.shape}')\n",
    "\n",
    "# (time_steps, num_batches, batch_size)\n",
    "\n",
    "# print(Xtr_batched.shape)\n",
    "\n",
    "# print(Xtr_batched[:, 1, 0:10])\n",
    "# print(\"\\n\")\n",
    "# print(Ytr_batched[:, 1, 0:10])\n",
    "# print(\"\\n\")\n",
    "\n",
    "# print(\"next batch\")\n",
    "# print(Xtr_batched[:, 0, 26:32])\n",
    "# print(\"\\n\")\n",
    "# print(Ytr_batched[:, 0, 26:32])\n",
    "\n",
    "\n",
    "\n",
    "# (8, 1, 32) -> (8, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fddc288-34bc-4c65-bb6e-fa74c5799979",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "hidden_size = 30\n",
    "time_steps = 8\n",
    "input_size = 27\n",
    "\n",
    "# Parameters\n",
    "Fvh = torch.randn(vocab_size, hidden_size)\n",
    "i1vh = torch.randn(vocab_size, hidden_size)\n",
    "i2vh = torch.randn(vocab_size, hidden_size)\n",
    "Ovh = torch.randn(vocab_size, hidden_size)\n",
    "\n",
    "Fhh = torch.randn(hidden_size, hidden_size)\n",
    "i1hh = torch.randn(hidden_size, hidden_size)\n",
    "i2hh = torch.randn(hidden_size, hidden_size)\n",
    "Ohh = torch.randn(hidden_size, hidden_size)\n",
    "\n",
    "bias1 = torch.zeros(hidden_size)\n",
    "bias2 = torch.zeros(hidden_size)\n",
    "bias3 = torch.zeros(hidden_size)\n",
    "bias4 = torch.zeros(hidden_size)\n",
    "\n",
    "output_matrix = torch.randn(hidden_size, vocab_size)\n",
    "\n",
    "# Storage\n",
    "preact1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "preact4 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "\n",
    "act1 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act2 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act3 = torch.zeros(time_steps, batch_size, hidden_size)\n",
    "act4 = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "\n",
    "Cin = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Cout = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Ctout = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "\n",
    "Hin = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "Hout = torch.zeros((time_steps, batch_size, hidden_size))\n",
    "\n",
    "logits = torch.zeros((time_steps, batch_size, vocab_size))\n",
    "\n",
    "c0 = torch.zeros(batch_size, hidden_size)\n",
    "h0 = torch.zeros((batch_size, hidden_size))\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "# To update\n",
    "dFvh = torch.zeros(vocab_size, hidden_size)\n",
    "di1vh = torch.zeros(vocab_size, hidden_size)\n",
    "di2vh = torch.zeros(vocab_size, hidden_size)\n",
    "dOvh = torch.zeros(vocab_size, hidden_size) \n",
    "\n",
    "dFhh = torch.zeros(hidden_size, hidden_size)\n",
    "di1hh = torch.zeros(hidden_size, hidden_size)\n",
    "di2hh = torch.zeros(hidden_size, hidden_size)\n",
    "dOhh = torch.zeros(hidden_size, hidden_size)\n",
    "\n",
    "dbias1 = torch.zeros(hidden_size) # (30)\n",
    "dbias2 = torch.zeros(hidden_size) # (30)\n",
    "dbias3 = torch.zeros(hidden_size) # (30)\n",
    "dbias4 = torch.zeros(hidden_size) # (30)\n",
    "\n",
    "doutput_matrix = torch.randn(hidden_size, vocab_size) # (30, 27)\n",
    "\n",
    "# Placeholders (indexed with t)\n",
    "dlogits = torch.zeros((time_steps, batch_size, vocab_size)) # (30, 27)\n",
    "dhidden1 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "dhidden2 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "dtotal = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "\n",
    "dpreact1 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30) \n",
    "dpreact2 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "dpreact3 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "dpreact4 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "\n",
    "dact1 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30) \n",
    "dact2 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "dact3 = torch.zeros(time_steps, batch_size, hidden_size) # (32, 30)\n",
    "dact4 = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "\n",
    "dC = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "dCt = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "dHin = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "dHout = torch.zeros((time_steps, batch_size, hidden_size)) # (32, 30)\n",
    "dlogits = torch.zeros((time_steps, batch_size, vocab_size)) # (32, 27)\n",
    "\n",
    "dc0 = torch.zeros(batch_size, hidden_size)\n",
    "dh0 = torch.zeros((batch_size, hidden_size))\n",
    "dcn = torch.zeros(batch_size, hidden_size)\n",
    "dhn = torch.zeros((batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07b4b9f4-3e02-4ca0-96d4-b03f928c2d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 7770\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "    Fvh, i1vh, i2vh, Ovh,\n",
    "    Fhh, i1hh, i2hh, Ohh,\n",
    "    bias1, bias2, bias3, bias4,\n",
    "    output_matrix,\n",
    "]\n",
    "\n",
    "# Set requires_grad to True for all parameters\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Print the total number of parameters\n",
    "print(\"Total number of parameters:\", sum(p.numel() for p in parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4944ed27-bdb0-4f4d-aea1-359758da74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1b15766-4d25-43b2-ae0a-dfd12d510093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [32, 30]], which is output 0 of AsStridedBackward0, is at version 32; expected version 31 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     59\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Update parameters using gradients\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(parameters, grads):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [32, 30]], which is output 0 of AsStridedBackward0, is at version 32; expected version 31 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Start with no cell activations, and no hidden activations\n",
    "    h0 = torch.zeros((batch_size, hidden_size))\n",
    "    c0 = torch.zeros((batch_size, hidden_size))\n",
    "    \n",
    "    # Loop over all batches (6504 total)\n",
    "    for batch_num in reversed(range(Xtr.shape[1])):\n",
    "        # Get a batch of random numbers into correct shape\n",
    "        Xb = Xtr_batched[:, batch_num, :] # ( 8, 32)\n",
    "        Xb = Xb.to(torch.long)\n",
    "        Xb = F.one_hot(Xb, 27) # (8, 32, 27)\n",
    "        Xb = Xb / 1.0\n",
    "        Yb = Ytr_batched[batch_num]\n",
    "        Yb = Yb.to(torch.long)\n",
    "    \n",
    "        # Forward propagation\n",
    "        for t in range(time_steps):\n",
    "            if t == 0:\n",
    "                Hin[t] = h0\n",
    "                Cin[t] = c0\n",
    "            else:\n",
    "                Hin[t] = Hout[t-1]\n",
    "                Cin[t] = Cout[t-1]\n",
    "            loss = 0\n",
    "            \n",
    "            preact1[t] = Xb[t] @ Fvh + Hin[t] @ Fhh + bias1 # (32, 27) @ (27, 30) + (32, 30) @ (30, 30) + (30)\n",
    "            preact2[t] = Xb[t] @ i1vh + Hin[t] @ i1hh * bias2 # (32, 27) @ (27, 30) + (32, 30) @ (30, 30) + (30)\n",
    "            preact3[t] = Xb[t] @ i2vh + Hin[t] @ i2hh + bias3 # (32, 27) @ (27, 30) + (32, 30) @ (30, 30) + (30)\n",
    "            preact4[t] = Xb[t] @ Ovh + Hin[t] @ Ohh + bias4 # (32, 27) @ (27, 30) + (32, 30) @ (30, 30) + (30)\n",
    "            \n",
    "            act1[t] = torch.sigmoid(preact1[t]) # (32, 30)\n",
    "            act2[t] = torch.sigmoid(preact2[t]) # (32, 30)\n",
    "            act3[t] = torch.tanh(preact3[t]) # (32, 30)\n",
    "            act4[t] = torch.sigmoid(preact4[t]) # (32, 30)\n",
    "            \n",
    "            Cout[t] = act1[t] * Cin[t] + act2[t] * act3[t] # (32, 30)\n",
    "            if t < time_steps -1: Cin[t+1] = Cout[t]\n",
    "            Ctout[t] = torch.tanh(Cout[t]) # (32, 30)\n",
    "            Hout[t] = Ctout[t] * act4[t] # (32, 30)\n",
    "            if t < time_steps -1: Hin[t+1] = Hout[t] \n",
    "            \n",
    "            \n",
    "            logits[t] = Hout[t] @ output_matrix # (32, 27)\n",
    "            counts = logits.exp()\n",
    "            counts_sum = counts.sum(1, keepdims=True)\n",
    "            counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "            probs = counts * counts_sum_inv\n",
    "            logprobs = probs.log()\n",
    "            loss += -logprobs[t][torch.arange(32), Yb].mean()\n",
    "    \n",
    "        if (batch_num % 100 == 0):\n",
    "            print (loss / time_steps)\n",
    "    \n",
    "        h0 = Hout[0]\n",
    "        c0 = Cout[0]\n",
    "        \n",
    "        # Backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "        # Update parameters using gradients\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "            p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4c78234a-e277-4118-bb33-bea7f86b2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = torch.exp(x - torch.max(x, dim=1, keepdim=True)[0])\n",
    "    return e_x / torch.sum(e_x, dim=1, keepdim=True)\n",
    "\n",
    "def sample_model(start_vector, Fvh, Fhh, i1vh, i1hh, i2vh, i2hh, Ovh, Ohh, bias1, bias2, bias3, bias4, output_matrix):\n",
    "    \"\"\"\n",
    "    Generate a sequence of samples from the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_vector: Initial one-hot encoded vector to start the generation (torch tensor of shape (1, input_size))\n",
    "    - Other parameters: Model weights and biases\n",
    "    \n",
    "    Returns:\n",
    "    - Generated sequence (list of integers)\n",
    "    \"\"\"\n",
    "    input_size = start_vector.shape[1]\n",
    "    hidden_size = Fvh.shape[1]\n",
    "    \n",
    "    # Initialize hidden and cell states\n",
    "    h = torch.zeros((1, hidden_size))\n",
    "    c = torch.zeros((1, hidden_size))\n",
    "    \n",
    "    # Initialize the generated sequence with the index of the start vector\n",
    "    generated_sequence = [torch.argmax(start_vector).item()]\n",
    "    \n",
    "    # Loop until '.' is generated or the maximum sequence length is reached\n",
    "    while generated_sequence[-1] != 0 and len(generated_sequence) <= max_length:\n",
    "        x = start_vector  # Use the provided start vector as input\n",
    "        \n",
    "        preact1 = x @ Fvh + h @ Fhh + bias1\n",
    "        preact2 = x @ i1vh + h @ i1hh + bias2\n",
    "        preact3 = x @ i2vh + h @ i2hh + bias3\n",
    "        preact4 = x @ Ovh + h @ Ohh + bias4\n",
    "        \n",
    "        act1 = torch.sigmoid(preact1)\n",
    "        act2 = torch.sigmoid(preact2)\n",
    "        act3 = torch.tanh(preact3)\n",
    "        act4 = torch.sigmoid(preact4)\n",
    "        \n",
    "        c = act1 * c + act2 * act3\n",
    "        h = torch.tanh(c) * act4\n",
    "        \n",
    "        logits = h @ output_matrix\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        # Sample from the probability distribution to get the next input\n",
    "        next_index = torch.multinomial(probs.squeeze(), 1).item()\n",
    "        \n",
    "        generated_sequence.append(next_index)\n",
    "        \n",
    "        # Update the start vector with the one-hot encoded representation of the next index\n",
    "        start_vector = torch.zeros((1, input_size))\n",
    "        start_vector[0, next_index] = 1\n",
    "        \n",
    "    return [itos[ch] for ch in generated_sequence]\n",
    "\n",
    "# Example usage\n",
    "input_size = 27  # Size of the one-hot encoded vector\n",
    "start_index = 1  # Index representing the starting point (e.g., 'a')\n",
    "start_vector = torch.zeros((1, input_size))\n",
    "start_vector[0, start_index] = 1  # One-hot encode the starting point\n",
    "\n",
    "# Assume Fvh, Fhh, i1vh, i1hh, i2vh, i2hh, Ovh, Ohh, bias1, bias2, bias3, bias4, and output_matrix are already defined\n",
    "\n",
    "max_length = 100  # Maximum length of the generated sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7f6d2bc2-0b8b-4014-a382-629827d57d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axypdouqtzn.\n"
     ]
    }
   ],
   "source": [
    "generated_sequence = sample_model(start_vector, Fvh, Fhh, i1vh, i1hh, i2vh, i2hh, Ovh, Ohh, bias1, bias2, bias3, bias4, output_matrix)\n",
    "print(''.join(generated_sequence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
